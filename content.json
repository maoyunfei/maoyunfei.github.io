{"meta":{"title":"Mao's Blog","subtitle":null,"description":"A Java Programmer","author":"云逸云飞","url":"https://maoyunfei.github.io"},"pages":[{"title":"404","date":"2018-03-05T10:09:20.322Z","updated":"2018-03-05T10:09:20.320Z","comments":true,"path":"/404.html","permalink":"https://maoyunfei.github.io//404.html","excerpt":"","text":"404页面"},{"title":"","date":"2018-03-06T03:41:47.075Z","updated":"2018-03-06T03:41:47.074Z","comments":true,"path":"google7636e2fc7ab7c3e4.html","permalink":"https://maoyunfei.github.io/google7636e2fc7ab7c3e4.html","excerpt":"","text":"google-site-verification: google7636e2fc7ab7c3e4.html"},{"title":"所有分类","date":"2018-03-04T10:17:13.000Z","updated":"2018-03-04T14:03:24.859Z","comments":false,"path":"categories/index.html","permalink":"https://maoyunfei.github.io/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2018-03-04T10:15:48.000Z","updated":"2018-03-04T14:03:24.862Z","comments":false,"path":"tags/index.html","permalink":"https://maoyunfei.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Java并发编程实战———取消与关闭","slug":"java/Java并发编程实战/取消与关闭","date":"2018-12-18T16:00:00.000Z","updated":"2018-12-19T09:58:03.558Z","comments":true,"path":"java/40578055/","link":"","permalink":"https://maoyunfei.github.io/java/40578055/","excerpt":"要使任务和线程能安全、快速、可靠地停止下来，并不是一件容易的事。Java没有提供任何机制来安全地终止线程。但它提供了中断(Interruption)，这是一种协作机制，能够使一个线程终止另一个线程的当前工作。 任务取消如果外部代码能在某个操作正常完成之前将其置入“完成”状态，那么这个操作就称为可取消的。在Java中没有一种安全的抢占式方法来停止线程，因此也就没有安全的抢占方式来停止任务。只有一些协作式的机制，使请求取消的任务和代码都遵循一种协商好的协议。其中一种协作机制能设置某个“已请求取消”标志，而任务将定期地查看该标志。如果设置了这个标记，那么任务将提前结束。12345678910111213141516171819202122232425262728293031323334//使用volatile类型的域来保存取消状态public class PrimeGenerator implements Runnable &#123; private final List&lt;BigInteger&gt; primes = new ArrayList&lt;BigInteger&gt;(); private volatile boolean cancelled; public void run() &#123; BigInteger p = BigInteger.ONE; while (!cancelled) &#123; p = p.nextProbablePrime(); synchronized (this) &#123; primes.add(p); &#125; &#125; &#125; public void cancel () &#123; cancelled = true; &#125; public synchronized List&lt;BigInteger&gt; get() &#123; return new ArrayList&lt;BigInteger&gt;(primes); &#125;&#125;//一个仅允许一秒钟的素数生成器List&lt;BigInteger&gt; aSecondOfPrimes() throws InterruptionException &#123; PrimeGenrator generator = new PrimeGenerator(); new Thread(generator).start(); try &#123; SECONDS.sleep(1); &#125; finally &#123; generator.cancel(); &#125; return generator.get();&#125;","text":"要使任务和线程能安全、快速、可靠地停止下来，并不是一件容易的事。Java没有提供任何机制来安全地终止线程。但它提供了中断(Interruption)，这是一种协作机制，能够使一个线程终止另一个线程的当前工作。 任务取消如果外部代码能在某个操作正常完成之前将其置入“完成”状态，那么这个操作就称为可取消的。在Java中没有一种安全的抢占式方法来停止线程，因此也就没有安全的抢占方式来停止任务。只有一些协作式的机制，使请求取消的任务和代码都遵循一种协商好的协议。其中一种协作机制能设置某个“已请求取消”标志，而任务将定期地查看该标志。如果设置了这个标记，那么任务将提前结束。12345678910111213141516171819202122232425262728293031323334//使用volatile类型的域来保存取消状态public class PrimeGenerator implements Runnable &#123; private final List&lt;BigInteger&gt; primes = new ArrayList&lt;BigInteger&gt;(); private volatile boolean cancelled; public void run() &#123; BigInteger p = BigInteger.ONE; while (!cancelled) &#123; p = p.nextProbablePrime(); synchronized (this) &#123; primes.add(p); &#125; &#125; &#125; public void cancel () &#123; cancelled = true; &#125; public synchronized List&lt;BigInteger&gt; get() &#123; return new ArrayList&lt;BigInteger&gt;(primes); &#125;&#125;//一个仅允许一秒钟的素数生成器List&lt;BigInteger&gt; aSecondOfPrimes() throws InterruptionException &#123; PrimeGenrator generator = new PrimeGenerator(); new Thread(generator).start(); try &#123; SECONDS.sleep(1); &#125; finally &#123; generator.cancel(); &#125; return generator.get();&#125; 中断123456//Thread中的中断方法public class Thread &#123; public void interrupt() &#123; ... &#125; public boolean isInterrupted() &#123; ... &#125; public static boolean interrupted() &#123; ... &#125;&#125;在Thread中包含了中断线程以及查询线程中断状态的方法：interrupt方法能中断目标线程，而isInterrupted方法能返回目标线程的中断状态，静态的interrupted方法将清除当前线程的中断状态，并返回它之前的值，这也是清除中断状态的唯一方法。调用interrupt并不意味着立即停止目标线程正在进行的工作，而只是传递了请求中断的消息。对中断操作的正确理解是：它并不会真正地中断一个正在运行的线程，而只是发出中断请求，然后由线程在下一个合适的时刻中断自己。(这些时刻也被称为取消点)在使用静态的interrupted时应该小心，因为它会清除当前线程的中断状态。如果在调用interrupted时返回了true，那么除非你想屏蔽这个中断，否则必须对它进行处理–可以抛出InterruptedException，或者通过再次调用interrupt来恢复中断状态。通常中断是实现取消的最合理方式。1234567891011121314151617181920212223//通过中断来取消class PrimeProducer extends Thread &#123; private final BlockingQueue&lt;BigInteger&gt; queue; PrimeProducer(BlockingQueue&lt;BigInteger&gt; queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; BigInteger p = BigInteger.ONE; while(!Thread.currentThread().isInterrupted()) &#123; queue.put(p = p.nextProbablePrime()); &#125; &#125; catch (InterruptedException consumed) &#123; /* 允许线程退出 */ &#125; &#125; public void cancel() &#123; interrupt(); &#125;&#125; 中断策略任务代码不应该对其执行所在的线程的中断策略做出假设，执行取消操作的代码也不应该对线程的中断策略做出假设。线程应该只能由其所有者中断，所有者可以将线程的中断策略信息封装到某个合适的取消机制中。由于每个线程拥有各自的中断策略，因此除非你知道中断对该线程的含义，否则就不应该中断这个线程。 响应中断当调用可中断的阻塞函数时，例如Thread.sleep或BlockingQueue.put等，有两种实用策略可用于处理InterruptedException：传递异常，从而使你的方法也成为可中断的阻塞方法。恢复中断状态，从而使调用栈中的上层代码能够对其进行处理。123456//将InterruptedException传递给调用者BlockingQueue&lt;Task&gt; queue;...public Task getNextTask() throws InterruptedException &#123; return queue.take();&#125;1234567891011121314151617//不可取消的任务在退出前恢复中断public Task getNextTask(BlockingQueue&lt;Task&gt; queue) &#123; boolean interrupted = false; try &#123; while(true) &#123; try &#123; return queue.take(); &#125; catch (InterruptedException e) &#123; interrupted = true; &#125; &#125; &#125; finally &#123; if(interrupted) &#123; Thread.currentThread().interrupt(); &#125; &#125;&#125; 通过Future来实现取消Future拥有一个cancel方法，该方法带有一个boolean类型的参数mayInterruptIfRunning，表示取消操作是否成功。(这只是表示任务是否能够接收中断，而不是表示任务是否能够检测并处理中断。) 如果mayInterruptIfRunning为true并且任务当前正在某个线程中运行，那么这个线程能被中断。如果这个参数为false，那么意味着“若任务还没有启动，就不要运行它”，这种方式应该用于那些不处理中断的任务中。如果任务在标准的Executor中运行，并通过它们的Future来取消任务，那么可以设置mayInterruptIfRunning。当尝试取消某个任务时，不宜直接中断线程池，因为你并不知道当中断请求到达时正在运行什么任务–只能通过任务的Future来实现取消。123456789101112131415//通过Future来取消任务public static void timedRun(Runnable r, long timeout, TimeUnit unit) throws InterruptedException &#123; Future&lt;?&gt; task = taskExec.submit(r); try &#123; task.get(timeout, unit); &#125; catch (TimeoutException e) &#123; //接下来任务将被取消 &#125; catch (ExecutionException e) &#123; //如果在任务中抛出了异常，那么重新抛出该异常 throw launderThrowable(e.getCause); &#125; finally &#123; //如果任务已经结束，那么执行取消操作也不会带来任何影响 task.cancel(true); //如果任务正在运行，那么将被中断 &#125;&#125;当Future.get抛出InterruptedException或TimeoutException时，如果你知道不再需要结果，那么就可以调用Future.cancel来取消任务。 停止基于线程的服务正确的封装原则是：除非拥有某个线程，否则不能对该线程进行操控。在线程API中，并没有对线程所有权给出正式的定义：线程由Thread对象表示，并且像其他对象一样可以被自由共享。然而，线程有一个相应的所有者，即创建该线程的类。因此线程池是其工作者线程的所有者，如果要中断这些线程，那么应该使用线程池。与其他封装对象一样，线程的所有权是不可传递的：应用程序可以拥有服务，服务也可以拥有工作者线程，但应用程序并不能拥有工作者线程，因此应用程序不能直接停止工作者线程。相反，服务应该提供生命周期方法来关闭它自己以及它所拥有的线程。这样，当应用程序关闭该服务时，服务就可以关闭所有的线程了。对于持有线程的服务，只要服务的存在时间大于创建线程的方法的存在时间，那么就应该提供生命周期方法。 关闭ExecutorServiceExecutorService提供了两种关闭方法：使用shutdown正常关闭，以及使用shutdownNow强行关闭。在进行强行关闭时，shutdownNow首先关闭当前正在执行的任务，然后返回所有尚未启动的任务清单。 shutdownNow的局限性当通过shutdownNow来强行关闭ExecutorService时，它会尝试取消正在执行的任务，并返回所有已提交但尚未开始的任务。然而，我们无法通过常规方法来找出哪些任务已经开始但尚未结束。 JVM关闭JVM既可以正常关闭，也可以强行关闭。正常关闭的触发方式有多种，包括：当最后一个非守护线程结束时，或者当调用了System.exit时，或者通过其他特定于平台的方法关闭时。虽然可以通过这些标准方法来正常关闭JVM，但也可以通过调用Runtime.halt或者在操作系统中杀死JVM进程来强行关闭JVM。 关闭钩子关闭钩子是指通过Runtime.addShutdownHook注册的但尚未开始的线程。在正常关闭中，JVM首先调用所有已注册的关闭钩子。JVM并不能保证关闭钩子的调用顺序。在关闭应用程序线程时，如果有线程仍然在运行，那么这些线程接下来将与关闭进程并发执行。JVM并不会停止或中断任何在关闭时仍然运行的应用程序线程。当JVM最终结束时，这些线程将被强行结束。如果关闭钩子或终结器没有执行完成，那么正常关闭进程挂起并且JVM必须强行关闭。当被强行关闭时，只是关闭JVM，而不会运行关闭钩子。 守护线程线程分为两种：普通线程和守护线程。在JVM启动时创建的所有线程中，除了主线程以外，其他的线程都是守护线程。当创建一个新线程时，新线程将继承创建它的线程的守护状态，因此在默认情况下，主线程创建的所有线程都是普通线程。普通线程与守护线程之间的差异仅在于当线程退出时发生的操作。当一个线程退出时，JVM会检查其他正在运行的线程，如果这些线程都是守护线程，那么JVM会正常退出操作。当JVM停止时，所有仍然存在的守护线程都将被抛弃–既不会执行finally代码块，也不会执行回卷栈，而JVM只是直接退出。应尽可能少地使用守护线程，守护线程通常不能用来替代应用程序管理程序中各个服务的生命周期。 终结器垃圾回收器对那些定义了finalize方法的对象会进行特殊处理：在回收器释放它们后，调用它们的finalize方法，从而保证一些持久化的资源释放。在大多数情况下，通过使用finally代码块和显式的close方法，能够比使用终结器更好地管理资源。避免使用终结器。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java Concurrency In Practice","slug":"Java-Concurrency-In-Practice","permalink":"https://maoyunfei.github.io/tags/Java-Concurrency-In-Practice/"}]},{"title":"Java并发编程实战———任务执行","slug":"java/Java并发编程实战/任务执行","date":"2018-12-11T16:00:00.000Z","updated":"2018-12-12T08:38:25.180Z","comments":true,"path":"java/ad6f24e8/","link":"","permalink":"https://maoyunfei.github.io/java/ad6f24e8/","excerpt":"在线程中执行任务 串行地执行任务12345678910//串行的Web服务器class SingleThreadWebServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket socket = new ServerSocket(80); while(true) &#123; Socket connection = socket.accept(); handleRequest(connection); &#125; &#125;&#125; 显式地为任务创建线程123456789101112131415在Web服务器中为每个请求启动一个新的线程(不要这样做)class ThreadPerTaskWebServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket socket = new ServerSocket(80); while(true) &#123; final Socket connection = socket.accept(); Runnable task = new Runnable() &#123; public void run() &#123; handleRequest(connection); &#125; &#125; new Thread(task).start(); &#125; &#125;&#125;任务处理过程从主线程中分离出来，使得主循环能够更快地重新等待下一个到来的连接。这使得程序在完成前面的请求之前可以接受新的请求，从而提高响应性。任务可以并行处理，从而能够同时服务多个请求。任务处理代码必须是线程安全的，因为当有多个任务时会并发地调用这段代码。","text":"在线程中执行任务 串行地执行任务12345678910//串行的Web服务器class SingleThreadWebServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket socket = new ServerSocket(80); while(true) &#123; Socket connection = socket.accept(); handleRequest(connection); &#125; &#125;&#125; 显式地为任务创建线程123456789101112131415在Web服务器中为每个请求启动一个新的线程(不要这样做)class ThreadPerTaskWebServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket socket = new ServerSocket(80); while(true) &#123; final Socket connection = socket.accept(); Runnable task = new Runnable() &#123; public void run() &#123; handleRequest(connection); &#125; &#125; new Thread(task).start(); &#125; &#125;&#125;任务处理过程从主线程中分离出来，使得主循环能够更快地重新等待下一个到来的连接。这使得程序在完成前面的请求之前可以接受新的请求，从而提高响应性。任务可以并行处理，从而能够同时服务多个请求。任务处理代码必须是线程安全的，因为当有多个任务时会并发地调用这段代码。 无限制创建线程的不足线程生命周期的开销非常高。 线程的创建与销毁都是有代价的，需要JVM和操作系统提供一些辅助操作。资源消耗。 活跃的线程会消耗系统资源，尤其是内存。如果可运行的线程数量多于可用处理器数量，那么有些线程将闲置。大量闲置的线程会占用许多内存，给垃圾回收器带来压力，而且大量线程在竞争CPU资源时还将产生其他的性能开销。如果你已经拥有足够多的线程使所有CPU保持忙碌状态，那么再创建更多的线程反而会降低性能。稳定性。 在可创建线程的数量上存在一个限制。这个限制值受多个因素影响，包括JVM参数、Thread构造函数中请求的栈大小，以及底层操作系统对线程的限制等。如果破坏了这些限制，那么很可能抛出OutOfMemoryError异常。 Executor框架线程池简化了线程的管理工作，并且java.util.concurrent提供了一种灵活的线程池实现作为Executor框架的一部分。在Java类库中，任务执行的主要抽象不是Thread，而是Executor。123public interface Executor &#123; void execute(Runnable command);&#125;Executor基于生产者-消费者模式，提交任务的操作相当于生产者，执行任务的线程相当于消费者。如果要在程序中实现一个生产者-消费者的设计，那么最简单的方式通常就是使用Executor。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//阻塞队列和Executor实现生产者-消费者模式 // 生产者class Producer implements Runnable &#123; private LinkedBlockingQueue&lt;Object&gt; queue; public Producer(LinkedBlockingQueue&lt;Object&gt; queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; while (true) &#123; try &#123; Object o = new Object(); queue.put(o); System.out.println(\"Producer: \" + o); &#125; catch (InterruptedException e) &#123; System.out.println(\"Producer is interrupted!\"); &#125; &#125; &#125;&#125;// 消费者class Consumer implements Runnable &#123; private LinkedBlockingQueue&lt;Object&gt; queue; public Consumer(LinkedBlockingQueue&lt;Object&gt; queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; while (true) &#123; try &#123; Object o = queue.take(); System.out.println(\"Consumer: \" + o); &#125; catch (InterruptedException e) &#123; System.out.println(\"Consumer is interrupted!\"); &#125; &#125; &#125;&#125;public class ProducerConsumer &#123; public static void main(String[] args) &#123; //阻塞队列 LinkedBlockingQueue&lt;Object&gt; queue = new LinkedBlockingQueue&lt;Object&gt;(10); ExecutorService es = Executors.newFixedThreadPool(6); for (int i = 0; i &lt; 3; i++) &#123; es.execute(new Producer(queue)); es.execute(new Consumer(queue)); &#125; &#125;&#125; 示例：基于Executor的Web服务器1234567891011121314151617class TaskExecutionWebServer &#123; private static final int NTHREADS = 100; private static flnal Executor exec = Executors.newFixedThreadPool(NTHREADS); public static void main(String[] args) throw IOException &#123; ServerSocket socket = new ServerSocket(80); while(true) &#123; final Socket connection = socket.accept(); Runnable task = new Runnable() &#123; public void run() &#123; handleRequest(connection); &#125; &#125; exec.execute(task); &#125; &#125;&#125; 线程池线程池是指管理一组同构工作线程的资源池。通过重用现有的线程而不是创建新线程，可以在处理多个请求时分摊在线程创建和销毁过程中产生的巨大开销。另一个额外的好处是，当请求到达时，工作线程通常已经存在，因此不会由于等待创建线程而延迟任务的执行，从而提高了响应性。通过适当调整线程池的大小，可以创建足够多的线程以便使处理器保持忙绿状态，同时还可以防止过多线程相互竞争资源而使应用程序耗尽内存或失败。类库提供了一个灵活的线程池以及一些有用的默认配置。可以通过调用Executors中的静态工厂方法来创建线程池：newFixedThreadPool。 newFixedThreadPool将创建一个固定长度的线程池，每当提交一个任务时就创建一个线程，直到达到线程池的最大数量，这时线程池的规模将不再变化。newCachedThreadPool。 newCachedThreadPool将创建一个可缓存的线程池，如果线程池的当前规模超过了处理需求时，那么将回收空闲的线程，而当需求增加时，则可以添加新的线程，线程池的规模不存在任何限制。newSingleThreadExecutor。 newSingleThreadExecutor是一个单线程的Executor，它创建单个工作线程来执行任务，如果这个线程异常结束，会创建另一个线程来代替。newSingleThreadExecutor能确保依照任务在队列中的顺序来串行执行。newScheduledThreadPool。 newScheduledThreadPool创建了一个固定长度的线程池，而且以延迟或定时的方式来执行任务。newFixedThreadPool和newCachedThreadPool这两个工厂方法返回通用的ThreadPoolExecutor实例，这些实例可以直接用来构造专门用途的executor。 Executor的生命周期由于Executor以异步方式来执行任务，因此在任何时刻，之前提交的任务的状态不是立即可见的。有些任务可能已经完成，有些可能正在运行，而其他的任务可能在队列中等待执行。Executor是可关闭的(无论采用平缓的方式还是粗暴的方式)，并将在关闭操作中受影响的任务的状态反馈给应用程序。为了解决执行服务的生命周期问题，ExecutorService接口扩展了Executor，添加了一些用于生命周期管理的方法。123456789//ExecutorService中的生命周期管理方法public interface ExecutorService extends Executor &#123; void shutdown(); List&lt;Runnable&gt; shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; ......&#125;ExecutorService的生命周期有3种状态：运行、关闭和已终止。ExecutorService在初始创建时处于运行状态。shutdown方法将执行平缓的关闭过程：不再接受新的任务，同时等待已经提交的任务执行完成–包括那些还未开始执行的任务。shutdownNow方法将执行粗暴的关闭过程：它将尝试取消所有运行中的任务，并且不再启动队列中尚未开始执行的任务。在ExecutorService关闭后提交的任务将由“拒绝执行处理器(Rejected Execution Handler)”来处理，它会抛弃任务，或者使得execute方法抛出一个未检查的RejectedExecutionException。等所有任务都完成后，ExecutorService将转入终止状态。可以调用awaitTermination来等待ExecutorService到达终止状态，或者通过调用isTerminated来轮询ExecutorService是否已经终止。通常在调用awaitTermination之后会立即调用shutdown，从而产生同步地关闭ExecutorService的效果。1234567891011121314151617181920212223242526272829303132333435//支持关闭操作的Web服务器class LifecycleWebServer &#123; private final ExecutorService exec = Executors.newCachedThreadPool(); public void start() throws IOException &#123; ServerSocket socket = new ServerSocket(); while (!exec.isShutdown()) &#123; try &#123; final Socket connection = socket.accept(); exec.execute(new Runnable() &#123; public void run() &#123; handleRequest(connection); &#125; &#125;); &#125; catch (RejectedExecutionException e) &#123; if (!exec.isShutdown()) &#123; log(\"task submission rejected\", e); &#125; &#125; &#125; &#125; public void stop() &#123; exec.shutdown(); &#125; void handleRequest(Socket connection) &#123; Request req = readRequest(connection); if (isShutdownRequest(req)) &#123; stop(); &#125; else &#123; dispatchRequest(req); &#125; &#125;&#125; 延迟任务与周期任务Timer类负责管理延迟任务以及周期任务。然而，Timer存在一些缺陷。Timer在执行所有定时任务时只会创建一个线程。如果某个任务的执行时间过长，那么将破坏其他TimerTask的定时准确性。Timer的另一个问题是，如果TimerTask抛出了一个未检查的异常，那么Timer将表现出糟糕的行为。Timer线程并不捕获异常，因此当TimerTask抛出未检查的异常时将终止定时线程，这种情况下，Timer也不会恢复线程的执行，而是会错误地认为整个Timer都被取消了。因此，已经被调度但尚未执行的TimerTask将不会再执行，新的任务也不能被调度(这个问题称之为“线程泄露”)。123456789101112131415161718//错误的Timer行为public class OutOfTime &#123; public static void main(String[] args) throws Exception &#123; Timer timer = new Timer(); timer.schedule(new ThrowTask(), 1); SECONDS.sleep(1); timer.schedule(new ThrowTask(), 1); SECONDS.sleep(5); &#125; static class ThrowTask extends TimerTask &#123; public void run() &#123; throw new RuntimeException(); &#125; &#125;&#125;//运行一秒结束，并抛出一个异常消息“Timer already cancelled”ScheduledThreadPoolExecutor能正确处理这些表现出错误行为的任务。在Java 5.0之后，很少使用Timer。123456789101112131415161718192021222324252627282930313233343536373839404142public class ScheduledThreadPoolTest &#123; public static void main(String[] args) throws InterruptedException &#123; // 创建大小为5的线程池 ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); for (int i = 0; i &lt; 3; i++) &#123; Task worker = new Task(\"task-\"\\ + i); // 只执行一次 // scheduledThreadPool.schedule(worker, 5, TimeUnit.SECONDS); // 周期性执行，每5秒执行一次 scheduledThreadPool.scheduleAtFixedRate(worker, 0, 5, TimeUnit.SECONDS); &#125; Thread.sleep(10000); System.out.println(\"Shutting down executor...\"); // 关闭线程池 scheduledThreadPool.shutdown(); boolean isDone; // 等待线程池终止 do &#123; isDone = scheduledThreadPool.awaitTermination(1, TimeUnit.DAYS); System.out.println(\"awaitTermination...\"); &#125; while (!isDone); System.out.println(\"Finished all threads\"); &#125;&#125;class Task implements Runnable &#123; private String name; public Task(String name) &#123; this.name = name; &#125; @Override public void run() &#123; System.out.println(\"name = \" + name + \", startTime = \" + new Date()); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"name = \" + name + \", endTime = \" + new Date()); &#125;&#125;如果要构建自己的调度服务，那么可以利用DelayQueue，它实现了BlockingQueue，并为ScheduledThreadPoolExecutor提供调度功能。DelayQueue管理着一组Delayed对象。每个Delayed对象都有一个相应的延迟时间：在DelayQueue中，只有某个元素逾期后，才能从DelayQueue中执行take操作。从DelayQueue中返回的对象将根据它们的延迟时间进行排序。 找出可利用的并行性 携带结果的任务Callable与FutureExecutor框架使用Runnable作为其基本的任务表示形式。Runnable是一种有很大局限的抽象，它不能返回一个值或抛出一个受检查的异常。Callable是一种更好的抽象，它认为调用处将返回一个值，并可能抛出一个异常。Executor执行的任务有4个生命周期阶段：创建、提交、开始和完成。在Executor框架中，已提交但尚未开始的任务可以取消，但对于那些已经开始执行的任务，只有当它们能响应中断时，才能取消。取消一个已经完成的任务不会有任何影响。Future表示一个任务的生命周期，并提供了相应的方法来判断是否已经完成或取消，以及获取任务的结果和取消任务等。get方法的行为取决于任务的状态(尚未开始、正在运行、已完成)。如果任务已经完成，那么get会立即返回或者抛出一个Exception，如果任务没有完成，那么get将阻塞并直到任务完成。如果任务抛出了异常，那么get将该异常封装为ExecutionException并重新抛出。如果任务被取消，那么get将抛出CancellationException。如果get抛出了ExecutionException，那么可以通过getCause来获得被封装的初始异常。123456789101112//Callable与Future接口public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125;public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException, CancellationException; V get(long timeout, TimeUnit unit)&#125; CompletionService：Executor与BlockingQueue如果向Executor提交了一组计算任务，并且希望在计算完成后获得结果，那么可以保留与每个任务关联的Future，然后反复使用get方法，同时将参数timeout指定为0，从而通过轮训来判断任务是否完成。这种方法有些繁琐，还有种更好的方法：完成服务(CompletionService)。CompletionService将Executor和BlockingQueue的功能融合在一起。你可以将Callable任务提交给它来执行，然后使用类似于队列操作的take和poll等方法来获得已完成的结果，而这些结果会在完成时将被封装为Future。ExecutorCompletionService实现了CompletionService，并将计算部分委托给一个Executor。123456789101112131415161718192021222324252627public class CompletionServiceDemo &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(3); CompletionService&lt;Integer&gt; completionService = new ExecutorCompletionService&lt;Integer&gt;(executor); for(int i = 0; i &lt; 10; i++) &#123; final Integer seq = i + 1; completionService.submit(new Callable&lt;Integer&gt;() &#123; public Integer call() throws Exception &#123; Thread.sleep((long)(Math.random() * 1000)); &#125; &#125;); &#125; for(int i = 0; i &lt; 10; i++) &#123; // take 方法等待下一个结果并返回 Future 对象。 // poll 不等待，有结果就返回一个 Future 对象，否则返回 null。 Future&lt;Integer&gt; future = completionService.take(); System.out.print(future.get() + \";\"); &#125; executor.shutdown(); &#125;&#125;//output2;3;4;1;5;7;6;10;8;9; 为任务设置时限在支持时间限制的Future.get中支持这种需求：当结果可用时，它将立即返回，如果在指定时限内没有计算出结果，那么将抛出TimeoutException。当这些任务超时后应该立即停止，从而避免为继续计算一个不再使用的结果而浪费计算资源。要实现这个功能，可以由任务本身来管理它的限定时间，并且在超时后中止执行或取消任务。此时可再次使用Future，如果一个限时的get方法抛出了TimeoutException，那么可以通过Future来取消任务。1234567891011121314151617181920//在指定时间内获取广告信息Page renderPageWithAd() throws InterruptedException &#123; long endNanos = System.nanoTime() + TIME_BUDGET; Future&lt;Ad&gt; f = exec.submit(new FetchAdTask()); //在等待广告的同时显示页面 Page page = renderPageBody(); Ad ad; try &#123; //只等待指定的时间长度 long timeLeft = endNanos - System.nanoTime(); ad = f.get(timeLeft, NANOSECONDS); &#125; cache (ExecutionException e) &#123; ad = DEFAULT_AD; &#125; catch (TimeoutException e) &#123; ad = DEFAULT_AD; f.cancel(true); &#125; page.setAd(ad); return page;&#125;","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java Concurrency In Practice","slug":"Java-Concurrency-In-Practice","permalink":"https://maoyunfei.github.io/tags/Java-Concurrency-In-Practice/"}]},{"title":"Java并发编程实战———基础构建模块","slug":"java/Java并发编程实战/基础构建模块","date":"2018-12-08T16:00:00.000Z","updated":"2018-12-09T07:10:25.711Z","comments":true,"path":"java/11c24b6b/","link":"","permalink":"https://maoyunfei.github.io/java/11c24b6b/","excerpt":"Java平台类库包含了丰富的并发基础构建模块，例如线程安全的容器类以及各种用于协调多个相互协作的线程控制流的同步工具类(Synchronizer)。 同步容器类同步容器类包括Vector和HashTable，还包括由Collections.synchronizedXxx等工厂方法创建的封装器类。同步容器类可以简单地理解为通过synchronized来实现同步的容器。这些类实现线程安全的方式是：将它们的状态封装起来，并对每个公有方法都进行同步，使得每次只有一个线程能访问容器的状态。 同步容器类的问题同步容器类都是线程安全的，但在某些情况下可能需要额外的客户端加锁来保护复合操作。容器上常见的复合操作包括：迭代、跳转以及条件运算。在同步容器类中，这些复合操作在没有客户端加锁的情况下仍然是线程安全的，但当其他线程并发地修改容器时，它们可能会表现出意料之外的行为。","text":"Java平台类库包含了丰富的并发基础构建模块，例如线程安全的容器类以及各种用于协调多个相互协作的线程控制流的同步工具类(Synchronizer)。 同步容器类同步容器类包括Vector和HashTable，还包括由Collections.synchronizedXxx等工厂方法创建的封装器类。同步容器类可以简单地理解为通过synchronized来实现同步的容器。这些类实现线程安全的方式是：将它们的状态封装起来，并对每个公有方法都进行同步，使得每次只有一个线程能访问容器的状态。 同步容器类的问题同步容器类都是线程安全的，但在某些情况下可能需要额外的客户端加锁来保护复合操作。容器上常见的复合操作包括：迭代、跳转以及条件运算。在同步容器类中，这些复合操作在没有客户端加锁的情况下仍然是线程安全的，但当其他线程并发地修改容器时，它们可能会表现出意料之外的行为。12345678910//复合操作非线程安全public static Object getLast(Vector list) &#123; int lastIndex = list.size() - 1; return list.get(lastIndex);&#125;public static void deleteLast(Vector list) &#123; int lastIndex = list.size() - 1; list.remove(lastIndex);&#125;1234567891011121314//加锁实现线程安全public static Object getLast(Vector list) &#123; synchronized (list) &#123; int lastIndex = list.size() - 1; return list.get(lastIndex); &#125;&#125;public static void deleteLast(Vector list) &#123; synchronized (list) &#123; int lastIndex = list.size() - 1; list.remove(lastIndex); &#125;&#125; 迭代器与ConcurrentModificationException对容器类进行迭代的过程中，如果有其他线程并发地修改容器，那么即使是使用迭代器也无法避免在迭代期间对容器加锁。当容器在迭代过程中被修改时，就会抛出一个ConcurrentModificationException异常。同步容器将所有对容器状态的访问都串行化，以实现它们的线程安全性。这种方法的代价是严重降低并发性，当多个线程竞争容器的锁时，吞吐量将严重减低。 并发容器并发容器是针对多个线程并发访问设计的。并发容器提供的迭代器不会抛出ConcurrentModificationException，因此不需要在迭代过程中对容器加锁。ConcurrentHashMap用来替代同步且基于散列的Map，CopyOnWriteArrayList用于在遍历操作为主要操作的情况下代替同步的List。 ConcurrentHashMapConcurrentHashMap在Java 7中使用分段锁，在Java 8中使用CAS来实现并发操作。ConcurrentHashMap返回的迭代器具有弱一致性，弱一致性的迭代器可以容忍并发的修改，当创建迭代器时会遍历已有的元素，并可以在迭代器被构造后将修改反映给容器。对于一些需要在整个Map上进行计算的方法，例如size和isEmpty，这些方法的语义被略微减弱了以反映容器的并发特性。由于size返回的结果在计算时可能已经过期了，它实际上只是一个估计值，因此允许size返回一个近似值而不是一个精确值。在ConcurrentHashMap中没有实现对Map加锁以提供独占访问，在大多数情况下，用ConcurrentHashMap来代替同步Map能进一步提高代码的可伸缩性，只有当应用程序需要加锁Map以进行独占访问时，才应该放弃使用ConcurrentHashMap。 CopyOnWriteArrayListCopyOnWriteArrayList用于替代同步List，在某些情况下它提供了更好的并发性能，并且在迭代期间不需要对容器进行加锁或复制。“写入时复制(Copy-On-Write)”容器的线程安全性在于，只要正确地发布一个事实不可变的对象，那么在访问该对象时就不再需要进一步的同步。在每次修改时，都会创建并重新发布一个新的容器副本，从而实现可变性。“写入时复制”容器的迭代器保留一个指向底层基础数组的引用，这个数组当前位于迭代器的起始位置，由于它不会被修改，因此在对其进行同步时只需确保数组内容的可见性。因此，多个线程可以同时对这个容器进行迭代，而不会彼此干扰或者与修改容器的线程相互干扰。“写入时复制”容器返回的迭代器不会抛出ConcurrentModificationException，并且返回的元素与迭代器创建时的元素完全一致，而不必考虑之后修改操作所带来的影响。每当修改容器时都会复制底层数组，这需要一定的开销，特别是当容器的规模较大时。仅当迭代操作远远多于修改操作时，才应该使用“写入时复制”容器。 同步工具类同步工具类可以是任何一个对象，只要它根据其自身的状态来协调线程的控制流。阻塞队列可以作为同步工具类，其他类型的同步工具类还包括信号量(Semaphore)、栅栏(Barrier)以及闭锁(Latch)。所有的同步工具类都包含一些特定的结构化属性：它们封装了一些状态，这些状态将决定执行同步工具类的线程是继续执行还是等待，此外还提供了一些方法对状态进行操作，以及另一些方法用于高效地等待同步工具类进入到预期状态。 闭锁闭锁是一种同步工具类，可以延迟线程的进度直到其到达终止状态。闭锁可以用来确保某些活动直到其他活动都完成后才继续执行。CountDownLatch是一种灵活的闭锁实现，它可以使一个或多个线程等待一组事件发生。闭锁状态包含一个计数器，该计数器初始化为一个正数，表示需要等待的事件数量。countDown方法递减计数器，表示有一个事件已经发生了，而await方法等待计数器达到零，这表示所有需要等待的事件都已经发生。如果计数器的值非零，那么await会一直阻塞直到计数器为零，或者等待中的线程中断，或者等待超时。1234567891011121314151617181920212223242526272829//在计时测试中使用CountDownLatch来启动和停止线程public class TestHarness &#123; public long timeTasks(int nThreads, final Runnable task) &#123; final CountDownLatch startGate = new CountDownLatch(1); final CountDownLatch endGate = new CountDownLatch(nThreads); for(int i = 0; i &lt; nThreads; i++) &#123; Thread t = new Thread() &#123; public void run() &#123; try &#123; startGate.await(); try &#123; task.run(); &#125; finally &#123; endGate.countDown(); &#125; &#125; catch (InterruptedException ignored) &#123; &#125; &#125; &#125;; t.start(); &#125; long start = System.nanoTime(); startGate.countDown(); endGate.await(); long end = System.nanoTime(); return end - start; &#125;&#125; FutureTaskFutureTask也可以用作闭锁。FutureTask表示的计算是通过Callable来实现的，相当于一种可生成结果的Runnable，并且可以处于以下3种状态：等待运行，正在运行和运行完成。“执行完成”表示计算的所有可能结束方式，包括正常结束、由于取消而结束和由于异常而结束等。Future.get的行为取决于任务的状态。如果任务已经完成，那么get会立即返回结果，否则get将阻塞直到任务进入完成状态，然后返回结果或者抛出异常。FutureTask在Executor框架中表示异步任务，此外还可以用来表示一些时间较长的计算，这些计算可以在使用计算结果之前启动。12345678910111213141516171819202122232425262728293031323334353637//使用FutureTask来提前加载稍后需要的数据public class Preloader &#123; private final FutureTask&lt;ProductInfo&gt; future = new FutureTask&lt;ProductInfo&gt;( new Callable&lt;ProductInfo&gt;() &#123; public ProductInfo call() throws DataLoadException &#123; return loadProductInfo(); &#125; &#125;); private final Thread thread = new Thread(future); public start() &#123; thread.start(); &#125; public ProductInfo get() throws DataLoadException, InterruptException &#123; try &#123; return future.get(); &#125; catch (ExecutionException e) &#123; Throwable cause = e.getCause(); if (cause instanceof DataLoadException)&#123; throw (DataLoadException) cause; &#125;else &#123; throw launderThrowable(cause); &#125; &#125; &#125; //强制将未检查的Throwable转换为RuntimeException public static RuntimeException launderThrowable(Throwable t) &#123; if (t instanceof RuntimeException) &#123; return (RuntimeException) t; &#125; else if (t instanceof Error) &#123; throw (Error) t; &#125; else &#123; throw new IllegalStateException(\"Not unchecked\", t); &#125; &#125;&#125; 信号量Semaphore中管理着一组虚拟的许可(permit)，许可的初始数量可通过构造函数来指定。在执行操作时先要获取许可，并在使用以后释放许可。如果没有许可，那么acquire将阻塞直到有许可(或者直到被中断或者操作超时)。release方法将返回一个许可给信号量。12345678910111213141516171819202122232425262728293031//使用Semaphore为容器设置边界public class BoundedHashSet&lt;T&gt; &#123; private final Set&lt;T&gt; set; private final Semaphore sem; public BoundedHashSet(int bound) &#123; this.set = Collections.synchronizedSet(new HashSet&lt;T&gt;()); asm = new Semaphore(bound); &#125; public boolean add(T o) throws InterruptedException &#123; asm.acquire(); boolean wasAdded = false; try &#123; wasAdded = set.add(o); return wasAdded; &#125; finally &#123; if (!wasAdded) &#123; asm.release(); &#125; &#125; &#125; public boolean remove(Object o) &#123; boolean wasRemoved = set.remove(o); if (wasRemoved) &#123; asm.release(); &#125; return wasRemoved; &#125;&#125; 栅栏栅栏类似于闭锁，它能阻塞一组线程直到某个事件发生。栅栏与闭锁的关键区别在于，所有线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，而栅栏用于等待其他线程。CyclicBarrier可以使一定数量的参与方反复地在栅栏位置汇集，当线程到达栅栏位置时将调用await方法，这个方法将阻塞直到所有线程都到达栅栏位置。如果所有线程都到达栅栏位置，那么栅栏将打开，此时所有线程都被释放，而栅栏被重置以便下次使用。如果对await的调用超时，或者await阻塞的线程被中断，那么栅栏就被认为是打破了，所有阻塞的await调用都将终止并抛出BrokenBarrierException。如果成功地通过栅栏，那么await将为每个线程返回一个唯一的到达索引号。CyclicBarrier还可以使你将一个栅栏操作传递给构造函数，这是一个Runnable，当成功通过栅栏时执行它。CyclicBarrier有两个构造参数，分别是：CyclicBarrier(int parties)创建一个新的CyclicBarrier，它将在给定数量的参与者(线程)处于等待状态时启动，但它不会在启动barrier时执行预定义的操作。CyclicBarrier(int parties, Runnable barrierAction)创建一个新的CyclicBarrier，它将在给定数量的参与者(线程)处于等待状态时启动，并在启动barrier时执行给定的屏障操作，该操作由最后一个进入barrier的线程执行。123456789101112131415161718192021222324252627282930313233343536373839404142//运动会所有选手都就位后才开始class Athlete implements Runnable &#123; private CyclicBarrier cyclicBarrier; private String name; public Athlete(CyclicBarrier cyclicBarrier, String name) &#123; this.cyclicBarrier = cyclicBarrier; this.name = name; &#125; @override public void run() &#123; System.out.println(name + \"就位\")； try &#123; cyclicBarrier.await(); Random random = new Random(); double time = random.nextDouble() + 9; System.out.println(name + \": \" + time); &#125; catch (Exception e) &#123; &#125; &#125;&#125;class Race &#123; private CyclicBarrier cyclicBarrier = new CyclicBarrier(8); public void start() &#123; List&lt;Athlete&gt; athletes = new ArrayList&lt;&gt;(); athleteList.add(new Athlete(cyclicBarrier,\"选手一\")); athleteList.add(new Athlete(cyclicBarrier,\"选手二\")); athleteList.add(new Athlete(cyclicBarrier,\"选手三\")); athleteList.add(new Athlete(cyclicBarrier,\"选手四\")); athleteList.add(new Athlete(cyclicBarrier,\"选手五\")); athleteList.add(new Athlete(cyclicBarrier,\"选手六\")); athleteList.add(new Athlete(cyclicBarrier,\"选手七\")); athleteList.add(new Athlete(cyclicBarrier,\"选手八\")); Executor executor = Executors.newFixedThreadPool(8); for (Athlete athlete : athleteList) &#123; executor.execute(athlete); &#125; &#125;&#125;CountDownLatch是一次性使用的，如果需要可重用的CountDownLatch，考虑使用CyclicBarrier。详细分析可参考Java并发之CyclicBarrier","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java Concurrency In Practice","slug":"Java-Concurrency-In-Practice","permalink":"https://maoyunfei.github.io/tags/Java-Concurrency-In-Practice/"}]},{"title":"Java并发编程实战———ThreadLocal深度解析","slug":"java/Java并发编程实战/ThreadLocal深度解析","date":"2018-12-05T16:00:00.000Z","updated":"2018-12-19T09:53:24.215Z","comments":true,"path":"java/f669ed98/","link":"","permalink":"https://maoyunfei.github.io/java/f669ed98/","excerpt":"ThreadLocal提供了线程的局部变量，每个线程都可以通过set()和get()来对这个局部变量进行操作，但不会和其他线程的局部变量进行冲突，实现了线程的数据隔离。 如何使用ThreadLocal12345678910111213141516public class Main &#123; private ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;&gt;(); public void start() &#123; for(int i=0; i&lt;10; i++) &#123; new Thread(new Runnable() &#123; @override public void run() &#123; threadLocal.set(i); threadLocal.get(); threadLocal.remove(); &#125; &#125;).start(); &#125; &#125;&#125;首先需要创建一个线程共享的ThreadLocal对象，该对象用于存储Integer类型的值，然后在每条线程中调用以下方法操作ThreadLocal:set(obj)：向当前线程中存储数据get()：获取当前线程中的数据remove()：删除当前线程中的数据","text":"ThreadLocal提供了线程的局部变量，每个线程都可以通过set()和get()来对这个局部变量进行操作，但不会和其他线程的局部变量进行冲突，实现了线程的数据隔离。 如何使用ThreadLocal12345678910111213141516public class Main &#123; private ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;&gt;(); public void start() &#123; for(int i=0; i&lt;10; i++) &#123; new Thread(new Runnable() &#123; @override public void run() &#123; threadLocal.set(i); threadLocal.get(); threadLocal.remove(); &#125; &#125;).start(); &#125; &#125;&#125;首先需要创建一个线程共享的ThreadLocal对象，该对象用于存储Integer类型的值，然后在每条线程中调用以下方法操作ThreadLocal:set(obj)：向当前线程中存储数据get()：获取当前线程中的数据remove()：删除当前线程中的数据 ThreadLocal实现原理ThreadLocal并不维护ThreadLocalMap，它只是相当于一个工具包，提供了操作该容器的方法，如get、set、remove等。而ThreadLocal内部类ThreadLocalMap才是存储数据的容器，并且该容器由Thread维护。每一个Thread对象均含有一个ThreadLocalMap类型的成员变量threadLocals，它存储本线程中所有ThreadLocal对象及其对应的值。ThreadLocalMap由一个个Entry对象构成，Entry的代码如下：12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125;Entry继承自WeakReference&lt;ThrealLocal&lt;?&gt;&gt;，一个Entry由ThreadLocal对象和Object构成。由此可见，Entry的key是ThreadLocal对象，并且是一个弱引用。当没指向key的强引用后，该key就会被垃圾收集器回收。ThreadLocal的set和get方法：1234567891011121314151617181920212223242526public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;当执行set方法时，ThreadLocal首先会获取当前线程对象，然后获取当前线程的ThreadLocalMap对象。再以当前ThreadLocal对象为key，将值存储进ThreadLocalMap对象中。get方法执行过程类似。ThreadLocal首先会获取当前线程对象，然后获取当前线程的ThreadLocalMap对象。再以当前ThreadLocal对象为key，获取对应的value。由于每一条线程均含有各自私有的ThreadLocalMap容器，这些容器相互独立互不影响，因此不会存在线程安全性问题，从而也无需使用同步机制来保证多条线程访问容器的互斥性。 ThreadLocal的内存泄露问题在ThreadLocalMap中，只有key是弱引用，value仍然是一个强引用。当某一条线程中的ThreadLocal使用完毕，没有强引用指向它的时候，这个key指向的对象就会被垃圾收集器回收，从而这个key就变成了null；然而，此时value和value指向的对象之间仍然是强引用关系，只要这种关系不解除，value指向的对象永远不会被垃圾收集器回收，从而导致内存泄漏！不过不用担心，ThreadLocal提供了这个问题的解决方案。每次操作set、get、remove操作时，ThreadLocal都会将key为null的Entry删除，从而避免内存泄漏。那么问题又来了，如果一个线程运行周期较长，而且将一个大对象放入ThreadLoalMap后便不再调用set、get、remove方法，此时该仍然可能会导致内存泄漏。这个问题确实存在，没办法通过ThreadLocal解决，而是需要程序员在完成ThreadLocal的使用后要养成手动调用remove的习惯，从而避免内存泄漏。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java Concurrency In Practice","slug":"Java-Concurrency-In-Practice","permalink":"https://maoyunfei.github.io/tags/Java-Concurrency-In-Practice/"}]},{"title":"Java并发编程实战———对象的共享","slug":"java/Java并发编程实战/对象的共享","date":"2018-12-03T16:00:00.000Z","updated":"2018-12-06T06:26:12.801Z","comments":true,"path":"java/27492a68/","link":"","permalink":"https://maoyunfei.github.io/java/27492a68/","excerpt":"可见性为了确保多个线程之间对内存写入操作的可见性，必须使用同步机制。 非原子的64位操作Java内存模型要求，变量的读取操作和写入操作都必须是原子操作，但对于非volatile类型的double和long变量，JVM允许将64位的读操作或写操作分解为两个32位的操作。当读取一个非volatile类型的long变量时，如果对该变量的读操作和写操作在不同的线程中执行，那么很可能会读取到某个值的高32位和另一个值的低32位。因此，即使不考虑失效数据问题，在多线程程序中使用共享且可变的long和double等类型的变量也是不安全的，除非用关键字volatile来声明它们，或者用锁保护起来。","text":"可见性为了确保多个线程之间对内存写入操作的可见性，必须使用同步机制。 非原子的64位操作Java内存模型要求，变量的读取操作和写入操作都必须是原子操作，但对于非volatile类型的double和long变量，JVM允许将64位的读操作或写操作分解为两个32位的操作。当读取一个非volatile类型的long变量时，如果对该变量的读操作和写操作在不同的线程中执行，那么很可能会读取到某个值的高32位和另一个值的低32位。因此，即使不考虑失效数据问题，在多线程程序中使用共享且可变的long和double等类型的变量也是不安全的，除非用关键字volatile来声明它们，或者用锁保护起来。 加锁与可见性加锁的含义不仅仅局限于互斥行为，还包括内存可见性。为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。 volatile变量Java语言提供了一种稍弱的同步机制，即volatile变量，用来确保将变量的更新操作通知到其他线程。当把变量声明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量上的操作与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。当且仅当满足以下所有条件时，才应该使用volatile变量：对变量的写入操作不依赖变量的当前值，或者你能确保只有单个线程更新变量的值。该变量不会与其他状态变量一起纳入不变性条件中，在访问变量时不需要加锁。 线程封闭当访问共享的可变数据时，通常需要使用同步。一种避免使用同步的方式就是不共享数据。如果仅在单线程内访问数据，就不需要同步。这种技术被称为线程封闭，它是实现线程安全性的最简单方式之一。 Ad-hoc线程封闭Ad-hoc线程封闭是指，维护线程封闭性的职责完全由程序实现来承担。Ad-hoc线程封闭是非常脆弱的，因为没有任何一种语言特性，能将对象封闭到目标线程上。 栈封闭栈封闭是线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问对象。局部变量的固有属性之一就是封闭在执行线程中，它们位于执行线程的栈中，其他线程无法访问这个栈。栈封闭比Ad-hoc线程封闭更易于维护，也更加健壮。在维持对象引用的栈封闭性时，程序员需要多做一些工作以确保被引用的对象不会逸出。 ThreadLocal类维持线程封闭性的一种更规范方法是使用ThreadLocal，这个类能使线程中的某个值与保存值的对象关联起来。ThreadLocal提供了get和set等访问接口或方法，这些方法为每个使用该变量线程都存有一份独立的副本，因此get总是返回由当前执行线程在调用set时设置的最新值。123456789private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() &#123; public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL); &#125;&#125;public static Connection getConnection() &#123; return connectionHolder.get();&#125;ThreadLocal变量类似于全局变量，它能降低代码的可重用性，并在类之间引入隐含的耦合性，因此在使用时要格外小心。 不变性满足同步需求的另一种方法是使用不可变对象。如果某个对象在被创建后其状态就不能被修改，那么这个对象就称为不可变对象。不可变对象一定是线程安全的。当满足以下条件时，对象才是不可变的：对象创建以后其状态就不能修改。对象的所有域都是final类型。对象是正确创建的(在对象的创建期间，this引用没有逸出)。 安全地共享对象在并发程序中使用和共享对象时，可以使用一些实用的策略，包括：线程封闭：线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只能由这个线程修改。只读共享：在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程都不能修改它。共享的只读对象包括不可变对象和事实不可变对象。线程安全共享：线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。保护对象：被保护的对象只能通过持有特定的锁来访问。保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java Concurrency In Practice","slug":"Java-Concurrency-In-Practice","permalink":"https://maoyunfei.github.io/tags/Java-Concurrency-In-Practice/"}]},{"title":"Java编程思想———泛型","slug":"java/Java编程思想/泛型","date":"2018-12-01T16:00:00.000Z","updated":"2018-12-03T06:16:09.889Z","comments":true,"path":"java/a9885224/","link":"","permalink":"https://maoyunfei.github.io/java/a9885224/","excerpt":"泛型实现了参数化类型的概念。根据泛型应用的不同，可分为：泛型类123class ClassParameter&lt;T&gt; &#123; public T f(T arg) &#123; return arg; &#125;&#125;泛型接口123interface InterfaceParameter&lt;T&gt; &#123; T f(T arg);&#125;泛型方法123class MethodParameter &#123; public static &lt;T&gt; T f(T arg) &#123; return arg; &#125;&#125;","text":"泛型实现了参数化类型的概念。根据泛型应用的不同，可分为：泛型类123class ClassParameter&lt;T&gt; &#123; public T f(T arg) &#123; return arg; &#125;&#125;泛型接口123interface InterfaceParameter&lt;T&gt; &#123; T f(T arg);&#125;泛型方法123class MethodParameter &#123; public static &lt;T&gt; T f(T arg) &#123; return arg; &#125;&#125; 泛型的擦除12345678910public class ErasedTypeEquivalence &#123; public static void main(String[] args) &#123; Class c1 = new ArrayList&lt;String&gt;().getClass(); Class c2 = new ArrayList&lt;Integer&gt;().getClass(); System.out.println(c1 == c2); &#125;&#125;//outputtrueJava泛型是使用擦除来实现的，这意味着当你在使用泛型时，任何具体的类型信息都被擦除了，你唯一知道的就是你在使用一个对象。因此，List&lt;String&gt;和List&lt;Integer&gt;在运行时事实上是相同的类型。这两种形式都被擦除成它们的原生类型，即List。在基于擦除的实现中，泛型类型被当作第二类类型处理，即不能在某些重要的上下文环境中使用的类型。泛型类型只有在静态类型检查期间才出现，在此之后，程序中的所有泛型类型都将被擦除，替换为它们的非泛型上界。擦除的代价是显著的，泛型不能用于显示地引用运行时类型的操作之中，例如转型、instanceof操作和new表达式。 问题在使用Java泛型时会出现的各类问题。任何基本类型都不能作为类型参数。解决办法是使用基本类型的包装器类及自动装箱机制。ArrayList&lt;Integer&gt;实现参数化接口一个类不能实现同一个泛型接口的两种变体，由于擦除的原因，这两种变体会成为相同的接口。12345interface Payable&lt;T&gt; &#123;&#125;class Employee implements Payable&lt;Employee&gt; &#123;&#125;class Hourly extends Employee implements Payable&lt;Hourly&gt; &#123;&#125;//Hourly无法编译转型和警告使用带有泛型类型参数的转型或instanceof不会有任何效果。重载12345public class UseList&lt;W,T&gt; &#123; void f(List&lt;T&gt; v) &#123;&#125; void f(List&lt;W&gt; v) &#123;&#125;&#125;//无法编译由于擦除的原因，重载方法将产生相同的类型签名。当被擦除的参数不能产生唯一的参数列表时，必须提供明显有区别的方法名：1234public class UseList2&lt;W,T&gt; &#123; void f1(List&lt;T&gt; v) &#123;&#125; void f2(List&lt;W&gt; v) &#123;&#125;&#125;基类劫持了接口1234567class Pet implements Comparable&lt;Pet&gt; &#123; public int compareTo(Pet arg) &#123; return 0; &#125;&#125;public class ComparablePet implements Comparable&lt;ComparablePet&gt; &#123; public int compareTo&lt;ComparablePet arg&gt; &#123; return 0; &#125;&#125;1234class Cat extends ComparablePet implements Comparable&lt;Cat&gt; &#123; //Error: Comparable不能被不同的参数Cat和Pet继承 public int compareTo&lt;Cat arg&gt; &#123; return 0; &#125;&#125; 数组与泛型不能实例化具有参数化类型的数组：1Peel&lt;Banana&gt;[] peels = new Peel&lt;Banana&gt;[10]; //非法擦除会移除参数类型信息，而数组必须知道它们所持有的确切类型，以强制保证类型安全。但是，可以参数化数组本身的类型：123456789101112131415161718class ClassParameter&lt;T&gt; &#123; public T[] f(T[] arg) &#123; return arg; &#125;&#125;class MethodParameter &#123; public static T[] f(T[] arg) &#123; return arg; &#125;&#125;public class ParameterizedArrayType &#123; public static void main(String[] args) &#123; Integer[] ints = &#123; 1, 2, 3, 4, 5 &#125;; Double[] doubles = &#123; 1.1, 2.2, 3.3, 4.4, 5.5 &#125;; Integer[] ints2 = new ClassParameter&lt;Integer&gt;().f(ints); Double[] doubles2 = new ClassParameter&lt;Double&gt;().f(doubles); ints2 = MethodParameter.f(ints); doubles2 = MethodParameter.f(doubles); &#125;&#125;","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———动态代理","slug":"java/Java编程思想/动态代理","date":"2018-11-25T16:00:00.000Z","updated":"2018-12-06T06:27:35.335Z","comments":true,"path":"java/aef2e083/","link":"","permalink":"https://maoyunfei.github.io/java/aef2e083/","excerpt":"什么是代理代理是基本的设计模式之一，给某个对象提供一个代理对象，并由代理对象控制对于原对象的访问，即客户不直接操控原对象，而是通过代理对象间接地操控原对象。通过使用代理，通常有两个优点：可以隐藏委托类的实现。可以实现客户与委托类间的解耦，在不修改委托类代码的情况下能够做一些额外的处理。","text":"什么是代理代理是基本的设计模式之一，给某个对象提供一个代理对象，并由代理对象控制对于原对象的访问，即客户不直接操控原对象，而是通过代理对象间接地操控原对象。通过使用代理，通常有两个优点：可以隐藏委托类的实现。可以实现客户与委托类间的解耦，在不修改委托类代码的情况下能够做一些额外的处理。 静态代理若代理类在程序运行前就已经存在，那么这种代理方式被称为静态代理，这种情况下的代理类通常都是我们在Java代码中定义的。通常情况下，静态代理中的代理类和委托类会实现同一接口或是派生自相同的父类。1234567/*** 委托类和代理类都实现Sell接口*/public interface Sell &#123; void sell(); void ad();&#125;1234567891011/*** 委托类*/public class Vendor inplements Sell &#123; void sell() &#123; System.out.println(\"In sell method\"); &#125; void ad() &#123; System.out.println(\"ad method\"); &#125;&#125;1234567891011121314151617/*** 代理类*/public class Agent inplements Sell &#123; private Vendor vendor; public Agent(Vendor vendor) &#123; this.vendor = vendor; &#125; public void sell() &#123; vendor.sell(); &#125; public void ad() &#123; vendor.ad(); &#125;&#125;通过以上代码可以看出，静态代理可以通过聚合来实现，让代理类持有一个委托类的引用即可。静态代理的局限在于运行前必须编写好代理类。 动态代理代理类在程序运行时创建的代理方式被称为动态代理。这种情况，代理类并不是在Java代码中定义的，而是在运行时根据我们在Java代码中的“指令”动态生成的。动态代理的优势在于可以很方便的对代理类的函数进行统一的处理，而不用修改每个代理类的函数。现在假设我们需要，在执行委托类中的方法之前输出“before”，在执行完毕之后输出“after”。静态代理的实现如下：12345678910111213141516171819public class StaticAgent implements Sell &#123; private Vendor vendor; public StaticAgent(Vendor vendor) &#123; this.vendor = vendor; &#125; public void sell() &#123; System.out.println(\"before\"); vendor.sell(); System.out.println(\"before\"); &#125; public void ad() &#123; System.out.println(\"before\"); vendor.ad(); System.out.println(\"before\"); &#125;&#125; 使用动态代理实现InvocationHandler接口在使用动态代理是，我们需要定义一个位于代理类与委托类之间的中介类，这个中介类被要求实现InvocationHandler接口，这个接口的定义如下：123456/*** 调用处理程序*/public interface InvocationHandler &#123; Object invoke(Object proxy, Method method, Object[] args);&#125;实现了这个接口的中介类叫做“调用处理类”，当我们调用代理类对象的方法时，这个调用会转送到invoke方法中，代理类对象作为proxy参数传入，参数method标识了我们具体调用的是代理类的哪个方法，args为这个方法的参数。这样一来，我们对代理类中的所有方法的调用都会变为对invoke的调用，这样我们可以在invoke方法中添加统一的处理逻辑。中介类的定义12345678910111213141516public class DynamicProxy implements InvocationHandler &#123; //object为委托类对象 private Object object; public DynamicProxy(Object obj) &#123; this.obj = obj; &#125; @override public Object invoke(Object proxy, Method method, Object[] args) &#123; System.out.println(\"before\"); Object result = method.invoke(obj, args); System.out.println(\"after\"); return result; &#125;&#125;通过以上代码可以看出，中介类持有一个委托类对象引用，在invoke方法中调用了委托类对象的相应方法。动态生成代理类12345678910111213public class Main &#123; public static void main(String[] args) &#123; //创建中介类实例 DynamicProxy inter = new DynamicProxy(new Vendor()); //加上这句将会产生一个$Proxy0.class文件，这个文件即为动态生成的代理类文件 System.getProperties.put(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); //获取代理类实例 Sell sell = (Sell)(Proxy.newProxyInstance(Sell.class.getClassLoader(), new Class[] &#123;Sell.class&#125;, inter)); //通过代理类对象调用代理类方法，实际上会转到invoke方法执行。 sell.sell(); sell.ad(); &#125;&#125;调用Proxy类的newProxyInstance方法来获取一个代理类实例。这个代理类实现了我们指定接口并且会把方法调用分发到指定的调用处理器。这个方法的声明如下：1public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException方法的三个参数含义分别如下：* loader：定义类代理类的ClassLoader* interfaces：代理类实现的接口列表* h：调用处理器，也就是上面实现了InvocationHandler接口的类实例 代理模式代理模式最大的特点就是代理类和实际业务类实现同一个接口(或继承同一父类)，代理对象持有一个实际对象的引用，外部调用时操作的是代理对象，而在代理对象的内部实现中又会去调用实际对象的操作。Java动态代理其实内部是通过反射机制来实现的，即已知的一个对象，然后在运行时动态调用其方法，这样在调用前后做一些相应的处理。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———反射：运行时的类信息","slug":"java/Java编程思想/反射","date":"2018-11-24T16:00:00.000Z","updated":"2018-12-06T06:27:35.330Z","comments":true,"path":"java/6d728b5e/","link":"","permalink":"https://maoyunfei.github.io/java/6d728b5e/","excerpt":"如果不知道某个对象的确切类型，RTTI可以告诉你。但是有一个限制：这个类型在编译时必须已知，这样才能使用RTTI识别它。换句话说，在编译时，编译器必须知道所有要通过RTTI来处理的类。反射允许运行中的Java程序获取自身的信息，并且可以操作类或对象的内部属性。Class类和java.lang.reflect类库一起对反射的概念进行了支持，该类库包含了Field、Method以及Constructor类。这些类型的对象是由JVM在运行时创建的，用以表示未知类里对应的成员。这样你就可以使用Constructor创建新的对象，用get()和set()方法读取和修改与Field对象关联的字段，用invoke()方法调用与Method对象关联的方法。另外，还可以调用getFields()、getMethods()和getConstructors()等很便利的方法，以返回表示字段、方法以及构造器的对象的数组。这样，匿名对象的类信息就能在运行时被完全确定下来，而在编译时不需要知道任何事情。","text":"如果不知道某个对象的确切类型，RTTI可以告诉你。但是有一个限制：这个类型在编译时必须已知，这样才能使用RTTI识别它。换句话说，在编译时，编译器必须知道所有要通过RTTI来处理的类。反射允许运行中的Java程序获取自身的信息，并且可以操作类或对象的内部属性。Class类和java.lang.reflect类库一起对反射的概念进行了支持，该类库包含了Field、Method以及Constructor类。这些类型的对象是由JVM在运行时创建的，用以表示未知类里对应的成员。这样你就可以使用Constructor创建新的对象，用get()和set()方法读取和修改与Field对象关联的字段，用invoke()方法调用与Method对象关联的方法。另外，还可以调用getFields()、getMethods()和getConstructors()等很便利的方法，以返回表示字段、方法以及构造器的对象的数组。这样，匿名对象的类信息就能在运行时被完全确定下来，而在编译时不需要知道任何事情。当通过反射与一个未知类型的对象打交道时，JVM只是简单地检查这个对象，看它属于哪个特定的类。在用它做其他事情之前必须先加载那个类的Class对象。因此，那个类的 .class文件对于JVM来说必须是可获取的：要么在本地机器上，要么可以通过网络获取 。所以RTTI和反射之间真正的区别只在于，对RTTI来说，编译器在编译时打开和检查.class文件。而对于反射机制来说，.class文件在编译时是不可获取的，所以是在运行时打开和检查.class文件。 反射的基本运用 获取Class对象方法有三种：使用Class类的forName()静态方法1Class.forName()直接获取某一个对象的class12Class&lt;?&gt; klass = int.class;Class&lt;?&gt; classInt = Integer.TYPE;调用某个对象的getClass()方法12StringBuilder str = new StringBuilder(\"123\");Class&lt;?&gt; klass = str.getClass(); 判断是否为某个类的实例一般地，我们用instanceof关键字来判断是否为某个类的实例。同时我们也可以借助反射中Class对象的isInstance()方法，它是一个native方法。1public native boolean isInstance(Object obj); 创建实例通过反射来生成对象主要有两种方式。使用Class对象的newInstance()方法来创建Class对象对应类的实例。12CLass&lt;?&gt; c = String.class;Object str = c.newInstance();先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建实例。这种方法可以用指定的构造器构造类的实例。1234Class&lt;?&gt; c = String.class;Constructor constructor = c.getConstructor(String.class);Object obj = constructor.newInstance(\"23333\");System.out.println(obj); 获取方法获取某个Class对象的方法集合，主要有以下几个方法。getDeclaredMethods()方法返回类或接口声明的所有方法，包括public、protected、默认访问和private方法，但不包括继承的方法。getMethods()方法返回某个类的所有public方法，包括其继承类的public方法。getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes)方法返回类本身一个特定的方法，其中第一个参数为方法名称，后面的参数为方法的参数对应Class的对象。getMethod(String name, Class&lt;?&gt;... parameterTypes)方法返回类及其父类一个特定的方法。 获取构造器信息获取类构造器主要通过Class类的getConstructor()方法得到Constructor类的一个实例，而Constructor类有一个newInstance(Object... initargs)方法可以创建一个对象实例，此方法可以根据传入的参数来调用相应的Constructor创建对象实例。 获取类的成员变量信息getDeclareFields()：所有已声明的成员变量，不包含父类的成员变量。getFields()：所有public成员变量，包含父类的public成员变量。getDeclareField(String name)方法返回一个类本身特定的成员变量，其中参数为成员变量名称。getField(String name)方法返回一个类及其父类特定的成员变量。 调用方法当我们从类中获取了一个方法后，就可以用invoke()方法来调用这个方法。方法原型为：12public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException 利用反射创建数组数组在Java中是比较特殊的一种类型，它可以赋值给一个Object引用。12345678910public static void testArray() throws ClassNotFoundException &#123; Class&lt;?&gt; klass = Class.forName(\"java.lang.String\"); Object array = Array.newInstance(klass, 10); //赋值 Array.set(array, 0, \"hello\"); Array.set(array, 1, \"world\"); Array.set(array, 2, \"java\"); //取值 System.out.println(Array.get(array, 2));&#125;其中的Array类为java.lang.reflect.Array。我们通过Array.newInstance()创建数组对象，它的原型是：123public static Object newInstance(Class&lt;?&gt; componentType, int length) throws NegativeArraySizeException &#123; return newArray(componentType, length); &#125;而newArray()方法是一个native方法。Array类的set()和get()方法都是native方法。 注意事项由于反射会额外消耗一定的系统资源，因此如果不需要动态地创建一个对象，那么就不需要用反射。另外，反射调用方法时可以忽略访问权限检查，因此可能会破坏封装性而导致安全问题。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———类型信息之Class对象","slug":"java/Java编程思想/类型信息之Class对象","date":"2018-11-23T16:00:00.000Z","updated":"2018-12-14T09:50:29.148Z","comments":true,"path":"java/7884ea50/","link":"","permalink":"https://maoyunfei.github.io/java/7884ea50/","excerpt":"运行时类型信息(Runtime Type Information，RTTI)使得你可以在程序运行时发现和使用类型信息。Java在运行时识别对象和类的信息，主要有两种方式：一种是传统的RTTI，它假定我们在编译时已经知道了所有的类型；另一种是反射机制，它允许我们在运行时发现和使用类的信息。RTTI的形式包含：传统的类型转换，如“(Shape)”，由RTTI确保类型转换的正确性，如果执行了一个错误的类型转换，就会抛出一个ClassCastException异常。代表对象的类型的Class对象。通过查询Class对象可以获取运行时所需的信息。关键字instanceof。它返回一个布尔值，告诉我们对象是不是某个特定类型的实例。","text":"运行时类型信息(Runtime Type Information，RTTI)使得你可以在程序运行时发现和使用类型信息。Java在运行时识别对象和类的信息，主要有两种方式：一种是传统的RTTI，它假定我们在编译时已经知道了所有的类型；另一种是反射机制，它允许我们在运行时发现和使用类的信息。RTTI的形式包含：传统的类型转换，如“(Shape)”，由RTTI确保类型转换的正确性，如果执行了一个错误的类型转换，就会抛出一个ClassCastException异常。代表对象的类型的Class对象。通过查询Class对象可以获取运行时所需的信息。关键字instanceof。它返回一个布尔值，告诉我们对象是不是某个特定类型的实例。 Class对象所有的类都是在对其第一次使用时，动态加载到JVM中的，当程序创建第一个对类的静态成员的引用时，就会加载这个类。这个证明构造函数也是类的静态方法，即使在构造器之前并没有使用static关键字。因此，使用new操作符创建类的新对象也会被当做对类的静态成员的引用。因此，Java程序在它开始运行之前并非被完全加载，其各个部分是在必需时才加载的。类加载器首先检查这个类的CLass对象是否已经加载。如果尚未加载，默认的类加载器就会根据类名查找.class文件。在这个类的字节码被加载时，它们会接受验证，以确保其没有被破坏，并且不包含不良Java代码。一旦某个类的Class对象被载入内存，它就被用来创建这个类的所有对象。123456789101112131415161718192021222324252627282930313233343536class Candy &#123; static &#123; System.out.println(\"Loading Candy\"); &#125;&#125;class Gum &#123; static &#123; System.out.println(\"Loading Gum\"); &#125;&#125;class Cookie &#123; static &#123; System.out.println(\"Loading Cookie\"); &#125;&#125;public class SweetShop &#123; public static void main(String[] args) &#123; System.out.println(\"inside main\"); new Candy(); System.out.println(\"After creating Candy\"); try &#123; Class.forName(\"Gum\"); &#125; catch(ClassNotFoundException e) &#123; System.out.println(\"Couldn't find Gum\"); &#125; System.out.println(\"After Class.forName(\\\"Gum\\\")\"); new Cookie(); System.out.println(\"After creating Cookie\"); &#125;&#125;//outputinside mainLoading CandyAfter creating CandyLoading GumAfter Class.forName(\"Gum\")Loading CookieAfter creating Cookie从输出中可以看到，Class对象仅在需要的时候才被加载，static初始化是在类加载时进行的。 类字面常量Java还提供了另外一种方法来生成对Class对象的引用，即使用类字面常量。如： Gum.class。这样做不仅更简单，而且更安全，因为它在编译时就会受到检查。并且它根除了对forName()方法的调用，所以也更高效。当使用.class来创建对Class对象的引用时，不会自动地初始化该Class对象。为了使用类而做的准备工作实际包含三个步骤：加载。这是由类加载器执行的。该步骤将查找字节码，并从这些字节码中创建一个Class对象。链接。在链接阶段将验证类中的字节码，为静态域分配存储空间，并且如果必需的话，将解析这个类创建的对其他类的所有引用。初始化。如果该类具有超类，则对其初始化，执行静态初始化器和静态代码块。初始化被延迟到了对静态方法(构造器隐式地是静态的)或者非常数静态域进行首次引用时才执行。 泛化的Class引用Class引用总是指向某个Class对象，它可以制造类的实例，并包含可作用于这些实例的所有方法代码。它还包含该类的静态成员，因此，Class引用表示的就是它所指向的对象的确切类型，而该对象便是Class类的一个对象。Java SE5允许你对Class引用所指向的Class对象的类型进行限定，用到了泛型语法。123456789public class GenericClassReferences &#123; public static void main(String[] args) &#123; Class intClass = int.class; Class&lt;Integer&gt; genericIntClass = int.class; genericIntClass = Integer.class; intClass = double.class; // genericIntClass = double.class; // Illegal &#125;&#125; instanceof与Class的等价性在查询类信息时，以instanceof的形式(即以instanceof的形式或isInstance()的形式，它们产生相同的结果)与直接比较Class对象有一个很重要的差别。123456789101112131415161718192021222324252627282930313233343536373839404142package typeinfoclass Base &#123;&#125;class Derived extends Base &#123;&#125;public class FamilyVsExactType &#123; static void test(Object x) &#123; System.out.println(\"Testing x of type \" + x.getClass()); System.out.println(\"x instanceof Base \" + (x instanceof Base)); System.out.println(\"x instanceof Derived \" + (x instanceof Derived)); System.out.println(\"Base.isInstance(x) \" + Base.class.isInstance(x)); System.out.println(\"Derived.isInstance(x) \" + Derived.class.isInstance(x)); System.out.println(\"x.getClass() == Base.class \" + (x.getClass() == Base.class)); System.out.println(\"x.getClass() == Derived.class \" + (x.getClass() == Derived.class)); System.out.println(\"x.getClass().equals(Base.class) \" + x.getClass().equals(Base.class)); System.out.println(\"x.getClass().equals(Derived.class) \" + x.getClass().equals(Derived.class)); &#125; public static void main(String[] args) &#123; test(new Base()); test(new Derived()); &#125;&#125;//outputTesting x of type typeinfo.Basex instanceof Base truex instanceof Derived falseBase.isInstance(x) trueDerived.isInstance(x) falsex.getClass() == Base.class truex.getClass() == Derived.class falsex.getClass().equals(Base.class) truex.getClass().equals(Derived.class) falseTesting x of type typeinfo.Derivedx instanceof Base truex instanceof Derived trueBase.isInstance(x) trueDerived.isInstance(x) truex.getClass() == Base.class falsex.getClass() == Derived.class truex.getClass().equals(Base.class) falsex.getClass().equals(Derived.class) trueinstanceof和isInstance()生成的结果完全一样，equals()和==生成的结果完成一样。instanceof判断某个对象是否是指定类或者指定类的子类。而equals()比较的是实际的Class对象，不考虑继承。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———字符串","slug":"java/Java编程思想/字符串","date":"2018-11-12T16:00:00.000Z","updated":"2018-12-06T06:27:35.314Z","comments":true,"path":"java/5f1ec589/","link":"","permalink":"https://maoyunfei.github.io/java/5f1ec589/","excerpt":"不可变StringString对象是不可变的，String类中每一个看起来会修改String值的方法，实际上都是创建了一个全新的String对象，以包含修改后的字符串内容，而最初的String对象则丝毫未动。1234567891011121314151617public class Immutable &#123; public static String upcase(String s) &#123; return s.toUpperCase(); &#125; public static void main(String[] args) &#123; String q = \"howdy\"; System.out.println(q); String qq = upcase(q); System.out.println(qq); System.out.println(q); &#125;&#125;//outputhowdyHOWDYhowdy","text":"不可变StringString对象是不可变的，String类中每一个看起来会修改String值的方法，实际上都是创建了一个全新的String对象，以包含修改后的字符串内容，而最初的String对象则丝毫未动。1234567891011121314151617public class Immutable &#123; public static String upcase(String s) &#123; return s.toUpperCase(); &#125; public static void main(String[] args) &#123; String q = \"howdy\"; System.out.println(q); String qq = upcase(q); System.out.println(qq); System.out.println(q); &#125;&#125;//outputhowdyHOWDYhowdy 重载 “+” 与StringBuilderString对象是不可变的，不可变性会带来一定的效率问题。为String对象重载的“+”操作符就是一个例子。(用于 “+” 与 “+=” 是Java中仅有的两个重载过的操作符，而Java并不允许程序员重载任何操作符)。虽然编译器已经自动优化，用StringBuilder实现字符串拼接操作来避免生成多余对象，但是还是建议对于复杂的字符串拼接，在代码中主动使用StringBuilder，因为这样效率最高。 无意识的递归Java中的每个类从根本上都是继承自Object，标准容器类自然也不例外。因此容器类都有toString()方法，并且覆写了该方法，使得它生成的String结果能够表达容器自身，以及容器所包含的对象。例如ArrayList.toString()，它会遍历ArrayList中包含的的所有对象，调用每个元素上的toString()方法。如果你希望toString()方法打印出对象的内存地址，也许你会考虑使用this关键词：123456789101112public class InfiniteRecursion &#123; public String toString() &#123; return \"InfiniteRecursion address: \" + this + \"\\n\"; //this导致递归调用 &#125; public static void main(String[] args) &#123; List&lt;InfiniteRecursion&gt; v = new ArrayList&lt;InfiniteRecursion&gt;(); for(int i = 0; i &lt; 10; i++) &#123; v.add(new InfiniteRecursion()); &#125; System.out.println(v); &#125;&#125;当你创建了InfiniteRecursion对象，并将其打印的时候，你会得到一串非常长的异常。如果你将该InfiniteRecursion对象存入一个ArrayList中，然后打印该ArrayList，你也会得到同样的异常。编译器尝试将this转换成一个String是通过调用this上的toString()方法，于是就发生了递归调用。如果你真的想要打印出对象的内存地址，应该调用Object.toString()方法，这才是负责任的方法。所以，你不该使用this，而是应该调用super.toString()方法。 正则表达式正则表达式是一种强大而灵活的文本处理工具。 量词量词描述了一个模式吸收输入文本的方式：贪婪型(默认)：它的特性是一次性地读入整个字符串，如果不匹配就吐掉最右边的一个字符再匹配，直到找到匹配的字符串或字符串的长度为0为止。它的宗旨是读尽可能多的字符，所以当读到第一个匹配时就立刻返回。勉强型(在匹配次数的特殊字符后面加一个问号)：它的特性是从字符串的左边开始，试图不读入字符串中的字符进行匹配，失败，则多读一个字符，再匹配，如此循环，当找到一个匹配时会返回该匹配的字符串，然后再次进行匹配直到字符串结束。占有型：它和贪婪模式很相似，不同点是不匹配它不会往回吐字符再匹配。1234567891011121314151617181920212223242526public class RegexMatches&#123; public static void main( String args[] )&#123; // 按指定模式在字符串查找 String line = \"This order was placed for QT3000! OK?\"; String pattern = \"(\\\\D*)(\\\\d+)(.*)\"; // 创建 Pattern 对象 Pattern r = Pattern.compile(pattern); // 现在创建 matcher 对象 Matcher m = r.matcher(line); if (m.find( )) &#123; System.out.println(\"Found value: \" + m.group(0) ); System.out.println(\"Found value: \" + m.group(1) ); System.out.println(\"Found value: \" + m.group(2) ); System.out.println(\"Found value: \" + m.group(3) ); &#125; else &#123; System.out.println(\"NO MATCH\"); &#125; &#125;&#125;//outputFound value: This order was placed for QT3000! OK?Found value: This order was placed for QTFound value: 3000Found value: ! OK?","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———标准异常","slug":"java/Java编程思想/标准异常","date":"2018-11-10T16:00:00.000Z","updated":"2018-12-06T06:31:37.976Z","comments":true,"path":"java/bac16ae/","link":"","permalink":"https://maoyunfei.github.io/java/bac16ae/","excerpt":"Throwable类被用来表示任何可以作为异常被抛出的类。从Throwable继承可分为两种类型：Error用来表示编译时和系统错误，一般不用关心；Exception是可以被抛出的的基本类型，通常是程序员所关心的。Exception又可以分为受检查的异常和未受检查的异常，未受检查的异常也叫运行时异常，受检查的异常必须要处理。","text":"Throwable类被用来表示任何可以作为异常被抛出的类。从Throwable继承可分为两种类型：Error用来表示编译时和系统错误，一般不用关心；Exception是可以被抛出的的基本类型，通常是程序员所关心的。Exception又可以分为受检查的异常和未受检查的异常，未受检查的异常也叫运行时异常，受检查的异常必须要处理。 常见的Exception和ErrorChecked exceptionsIOExceptionUnchecked exceptions/Runtime exceptionsArrayIndexOutOfBoundsExceptionClassCastExceptionIllegalArgumentExceptionIllegalStateExceptionNullPointerExceptionNumberFormatExceptionErrorsStackOverflowErrorNoClassDefDoundErrorOutOfMemoryError","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———简单的容器分类","slug":"java/Java编程思想/简单的容器分类","date":"2018-11-09T16:00:00.000Z","updated":"2018-12-06T06:31:37.941Z","comments":true,"path":"java/92b4f9c/","link":"","permalink":"https://maoyunfei.github.io/java/92b4f9c/","excerpt":"","text":"从上图可以看出，其实只有四种容器：Map、List、Set和Queue。常用的容器用黑色粗线框表示。点线框表示接口，实线框表示具体的类。带有空心箭头的点线表示一个特定的类实现了一个接口，带有空心箭头的实线表示一个特定的类继承了一个类，实心箭头表示某个类可以生成箭头所指向类的对象。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———内部类","slug":"java/Java编程思想/内部类","date":"2018-10-29T16:00:00.000Z","updated":"2018-12-06T06:27:35.321Z","comments":true,"path":"java/385f254c/","link":"","permalink":"https://maoyunfei.github.io/java/385f254c/","excerpt":"可以将一个类的定义放到另一个类的定义内部，这就是内部类。 链接到外部类当生成一个内部类的对象时，此对象与制造它的外围对象之间就有了一种联系，所以它能访问其外围对象的所有成员，而不需要任何特殊条件。此外，内部类还拥有其外围类的所有元素的访问权。 使用.this与.new如果你需要生成对外部类对象的引用，可以使用外部类的名字后面紧跟.this。","text":"可以将一个类的定义放到另一个类的定义内部，这就是内部类。 链接到外部类当生成一个内部类的对象时，此对象与制造它的外围对象之间就有了一种联系，所以它能访问其外围对象的所有成员，而不需要任何特殊条件。此外，内部类还拥有其外围类的所有元素的访问权。 使用.this与.new如果你需要生成对外部类对象的引用，可以使用外部类的名字后面紧跟.this。123456789101112131415161718192021public class DotThis &#123; void f() &#123; System.out.println(\"DotThis.f()\"); &#125; public class Inner &#123; public DotThis outer() &#123; return DotThis.this; &#125; &#125; public Inner inner() &#123; return new Inner(); &#125; public static void main(String[] args) &#123; DotThis dt = new DotThis(); DotThis.Inner dti = dt.inner(); dti.outer().f(); &#125;&#125;//outputDotThis.f()由外部类对象去创建其某个内部类的对象，必须在new表达式中提供外部对象的引用，这需要使用.new语法。1234567public class DotNew &#123; public class Inner &#123;&#125; public static void main(String[] args) &#123; DotNew dn = new DotNew(); DotNew.Inner dni = dn.new Inner(); &#125;&#125;在拥有外部类对象之前是不可能创建内部类对象的。这是因为内部类对象会暗暗地连接到创建它的外部类对象上。但是，如果创建的是嵌套类（静态内部类），那么它就不需要对外部类对象的引用。 匿名内部类如果定义一个匿名内部类，并且希望它使用一个在其外部定义的对象，那么编译器会要求其参数引用是final的。 无参构造12345678910111213141516171819public class Contents &#123; piblic int i; public int value() &#123; return i; &#125;&#125;public class ParCel7 &#123; public Contents contents() &#123; return new Contents() &#123; //无参构造 private int i = 11; private int value() &#123; return i; &#125; &#125;; &#125; public static void main(String[] args) &#123; Parcel7 p = new Parcel7(); Contents c = p.contents(); &#125;&#125; 有参构造1234567891011121314151617181920212223public class Wrapping &#123; piblic int i; public Wrapping(int x) &#123; return i = x; &#125; public int value() &#123; return i; &#125;&#125;public class Parcel8 &#123; public Wrapping wrapping(int x) &#123; return new Wrapping(x) &#123; //有参构造 public int value() &#123; return super.value() * 47; &#125; &#125; &#125; public static void main(String[] args)&#123; Pracel8 p = new Pracel8(); Wrapping w = p.wrapping(10); &#125;&#125; 带实例初始化123456789101112131415161718192021222324public Parcel10 &#123; public Destination destination(final String dest, final float price) &#123; return new Destination() &#123; private int cost; &#123; cost = Math.round(price); //实例初始化 if(cost &gt; 100)&#123; System.out.println(\"Over budget!\"); &#125; &#125; private String label = dest; //实例初始化 public String readLabel() &#123; return label; &#125; &#125; &#125; public static void main(String[] args)&#123; Parcel10 p = new Parcel10(); Destination d = p.destination(\"Tasmania\", 101.395F); &#125;&#125;//outputOver budget! 嵌套类（静态内部类）如果将内部类声明为static，则称为嵌套类。要创建嵌套类的对象，并不需要其外围类的对象。不能从嵌套类的对象中访问非静态的外围类对象。 接口内部的类因为接口中的任何类都自动地是public和static的，因此接口中的类是嵌套类。1234567891011121314public interface ClassInInterface &#123; void howdy(); class Test implements ClassInInterface &#123; public void howdy() &#123; System.out.println(\"Howdy!\"); &#125; public static void main(String[] args) &#123; new Test().howdy(); &#125; &#125;&#125;//outputHowdy! 从多层嵌套类中访问外部类的成员一个内部类被嵌套多少层并不重要，它能透明地访问所有它所嵌入的外围类的所有成员。123456789101112131415161718192021class MNA &#123; public void f(); class A &#123; private void g() &#123;&#125; public class B &#123; void h() &#123; g(); f(); &#125; &#125; &#125;&#125;public class MultiNestingAccess &#123; public static void main(String[] args) &#123; MNA mna = new MNA(); MNA.A mnaa = mna.new A(); MNA.A.B mnaab = mnaa.new B(); mnaab.h(); &#125;&#125; 内部类的继承12345678910111213class WithInner &#123; class Inner &#123;&#125;&#125;public class InheritInner extends WithInner.Inner &#123; InheritInner(WithInner wi)&#123; //有参构造 wi.super(); //重要 &#125; public static void main(String[] args) &#123; WithInner wi = new WithInner(); InheritInner ii = new InheritInner(wi); &#125;&#125;不能使用默认构造器，必须使用有参构造器，需要传递一个指向外围类对象的引用，同时必须在构造器内使用如下语法：enclosingClassReference.super()，这样才提供了必要的引用。 内部类可以被覆盖吗覆盖内部类就好像它是外围类的一个方法，其实并不起什么作用。123456789101112131415161718192021222324252627class Egg &#123; private Yolk y; protected class Yolk &#123; public Yolk() &#123; System.out.println(\"Egg.Yolk()\"); &#125; &#125; public Egg() &#123; System.out.println(\"New Egg()\"); y = new Yolk(); &#125;&#125;public class BigEgg extends Egg &#123; public class Yolk &#123; public Yolk() &#123; System.out.println(\"BigEgg.Yolk()\"); &#125; &#125; public static void main(String[] args) &#123; new BigEgg(); &#125;&#125;//outputNew Egg()Egg.Yolk()当继承了某个外围类的时候，内部类并没有发生什么特别神奇的变化。这两个内部类是完全独立的两个实体，各自在自己的命名空间内。但是，可以明确地继承某个内部类。123456789101112131415161718192021222324252627282930313233343536373839404142434445class Egg2 &#123; protected class Yolk &#123; public Yolk() &#123; System.out.println(\"Egg2.Yolk()\"); &#125; public void f() &#123; System.out.println(\"Egg2.Yolk.f()\"); &#125; &#125; private Yolk y = new Yolk(); public Egg2() &#123; System.out.println(\"New Egg2()\"); &#125; public void insertYolk(Yolk yy) &#123; y = yy; &#125; public void g() &#123; y.f(); &#125;&#125;public class BigEgg2 extends Egg2 &#123; public class Yolk extends Egg2.Yolk &#123; public Yolk() &#123; System.out.println(\"BigEgg2.Yolk()\"); &#125; public void f() &#123; System.out.println(\"BigEgg2.Yolk.f()\"); &#125; &#125; public BigEgg2() &#123; insertYolk(new Yolk()); &#125; public static void main(String[] args) &#123; Egg2 e2 = new BigEgg2(); e2.g(); &#125;&#125;//outputEgg2.Yolk()New Egg2()Egg2.Yolk()BigEgg2.Yolk()BigEgg2.Yolk.f() 局部内部类可以在代码块或者方法体内创建内部类，叫做局部内部类。局部内部类不能有访问说明符，因为它不是外围类的一部分；但是它可以访问当前代码块内的常量，以及此外围类的所有成员。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657interface Counter &#123; int next();&#125;public class LocalInnerClass &#123; private int count = 0; Counter getCounter(final String name) &#123; //局部内部类 class LocalCounter implements Counter &#123; public LocalCounter() &#123; System.out.println(\"LocalCounter()\"); &#125; public int next() &#123; System.out.println(name); return count++; &#125; &#125; return new LocalCounter(); &#125; Counter getCounter2(final String name) &#123; //匿名内部类 return new Counter() &#123; &#123; System.out.println(\"Counter()\"); &#125; public int next() &#123; System.out.println(name); return count++; &#125; &#125; &#125; public static void main(String[] args) &#123; LocalInnerClass lic = new LocalInnerClass(); Counter c1 = lic.getCount(\"Local inner \"); Counter c2 = lic.getCount2(\"Anonymous inner \"); for(int i = 0; i &lt; 5; i++)&#123; System.out.println(c1.next); &#125; for(int i = 0; i &lt; 5; i++)&#123; System.out.println(c2.next); &#125; &#125;&#125;//outputLocalCounter()Counter()Local inner 0Local inner 1Local inner 2Local inner 3Local inner 4Anonymous inner 5Anonymous inner 6Anonymous inner 7Anonymous inner 8Anonymous inner 9","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———多态","slug":"java/Java编程思想/多态","date":"2018-10-13T16:00:00.000Z","updated":"2018-12-06T06:27:35.340Z","comments":true,"path":"java/73b264e5/","link":"","permalink":"https://maoyunfei.github.io/java/73b264e5/","excerpt":"多态也称作动态绑定、后期绑定或运行时绑定。 方法调用绑定将一个方法调用同一个方法主体关联起来被称作绑定。若在程序执行前进行绑定，叫做前期绑定。在运行时根据对象的类型进行绑定叫做后期绑定。后期绑定也叫做动态绑定或运行时绑定。Java中除了static方法和final方法(private方法属于final方法)之外，其他所有的方法都是后期绑定。","text":"多态也称作动态绑定、后期绑定或运行时绑定。 方法调用绑定将一个方法调用同一个方法主体关联起来被称作绑定。若在程序执行前进行绑定，叫做前期绑定。在运行时根据对象的类型进行绑定叫做后期绑定。后期绑定也叫做动态绑定或运行时绑定。Java中除了static方法和final方法(private方法属于final方法)之外，其他所有的方法都是后期绑定。 缺陷：“覆盖”私有方法只有非private方法才可以被覆盖；但是还需要密切注意覆盖private方法的现象，这时虽然编译器不会报错，但是也不会按照我们所期望的来执行。确切地说，在导出类(子类)中，对于基类中的private方法，最好采用不同的名字。123456789101112131415161718public class PrivateOverride &#123; private void f() &#123; System.out.println(\"private f()\"); &#125; public static void main(String[] args) &#123; PrivateOverride po = new Derived(); po.f(); &#125;&#125;class Derived extends PrivateOverride &#123; public void f() &#123; System.out.println(\"public f()\"); &#125;&#125;//outputprivate f() 缺陷： 域与静态方法任何域访问操作都将由编译器解析，因此不是多态的。1234567891011121314151617181920212223242526272829class Super &#123; public int field = 0; public int getField() &#123; return field; &#125;&#125;class Sub extends Super &#123; public int field = 1; public int getField() &#123; return field; &#125; public int getSuperField() &#123; return super.field; &#125;&#125;public class FieldAccess &#123; public static void main(String[] args) &#123; Super sup = new Sub(); System.out.println(\"sup field = \" + sup.field + \", sup.getField() = \" + sup.getField()); Sub sub = new Sub(); System.out.println(\"sub field = \" + sub.field + \", sub.getField() = \" + sub.getField() + \", sub.getSuperField() = \" + sub.getSuperField()); &#125;&#125;//outputsup.field = 0, sup.getField() = 1sub.field = 1, sub.getField() = 1, sub.getSuperField() = 0只有普通的方法调用可以是多态的，如果某个方法是静态的，它的行为就不具有多态性。1234567891011121314151617181920212223242526272829class StaticSuper &#123; public static String staticGet() &#123; return \"Base staticGet()\"; &#125; public String dynamicGet() &#123; return \"Base dynamicGet()\"; &#125;&#125;class StaticSub extends StaticSuper &#123; public static String staticget() &#123; return \"Derived staticGet()\"; &#125; public String dynamicGet() &#123; return \"Derived dynamicGet()\"; &#125;&#125;public class StaticPolymorphism &#123; public static void main(String[] args) &#123; StaticSuper sup = new StaticSub(); System.out.println(sup.staticGet()); System.out.println(sup.dynamicGet()); &#125;&#125;//outputBase staticGet()Derived dynamicGet() 构造器内部的多态方法的行为在一般的方法内部，动态绑定的调用是在运行时才决定的，因此对象无法知道它是属于方法所在的那个类，还是属于那个类的导出类。如果要调用构造器内部的一个动态绑定方法，就要用到那个方法的被覆盖后的定义。123456789101112131415161718192021222324252627282930313233class Glyph &#123; void draw() &#123; System.out.println(\"Glyph.draw()\") &#125; Glyph() &#123; System.out.println(\"Glyph() before draw()\"); draw(); System.out.println(\"Glyph() after draw()\"); &#125;&#125;class RoundGlyph extends Glyph &#123; private int radius = 1; RoundGlyph(int r) &#123; radius = r; System.out.println(\"RoundGlyph.RoundGlyph(). radius = \" + radius; &#125; void draw() &#123; System.out.println(\"RoundGlyph.draw(). radius = \" + radius; &#125;&#125; public class PolyConstructors &#123; public static void main(String[] args)&#123; new RoundGlyph(5); &#125;&#125; //outputGlyph() before draw()RoundGlyph.draw(). radius = 0Glyph() after draw()RoundGlyph.draw(). radius = 1编写构造器时有一条有效的准则：“用尽可能简单的方法使对象进入正常状态；如果可以的话，避免调用其他方法”。在构造器内唯一能够安全调用的那些方法是基类中的final方法(也适用于private方法，它们自动属于final方法)。这些方法不能被覆盖，因此也就不会出现令人惊讶的问题。 协变返回类型协变返回类型指的是子类中的成员函数的返回值类型不必严格等同于父类中被重写的成员函数的返回值类型，而可以是更 “狭窄” 的类型。Java 5.0添加了对协变返回类型的支持，即子类覆盖基类方法时，返回的类型可以是基类方法返回类型的子类。协变返回类型允许返回更为具体的类型。1234567891011121314151617181920212223242526272829303132333435363738class Grain &#123; public String toString() &#123; return \"Grain\"; &#125;&#125;class Wheat extends Grain &#123; public String toString() &#123; return \"Wheat\"; &#125;&#125;class Mill &#123; Grain process() &#123; return new Grain(); &#125;&#125;class WheatMill extends Mill &#123; Wheat process() &#123; return new Wheat(); &#125;&#125;public class CovariantReturn &#123; public static void main(String[] args) &#123; Mill m = new Mill(); Grain g = m,process(); System.out.println(g); m = new WheatMill(); g = m.process(); System.out.println(g); &#125;&#125;//outputGrainWheat","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———类的继承","slug":"java/Java编程思想/类的继承","date":"2018-09-29T16:00:00.000Z","updated":"2018-12-06T06:31:38.010Z","comments":true,"path":"java/e1123076/","link":"","permalink":"https://maoyunfei.github.io/java/e1123076/","excerpt":"继承语法在创建子类的对象时，Java虚拟机首先执行父类的构造方法，然后再执行子类的构造方法。在多级继承的情况下，将从继承树的最上层的父类开始，依次执行各个类的构造方法，这可以保证子类对象从所有直接或间接父类中继承的实例变量都别正确地初始化。子类的所有构造方法内部，第一行会(隐式)自动先调用父类的无参构造函数(super())如果子类构造方法第一行显式调用了父类构造方法，系统就不再调用父类的无参构造函数子类的构造方法中调用父类的构造函数必须写在第一行，如果父类没有无参构造函数，子类必须在构造方法中显式调用父类的有参构造函数","text":"继承语法在创建子类的对象时，Java虚拟机首先执行父类的构造方法，然后再执行子类的构造方法。在多级继承的情况下，将从继承树的最上层的父类开始，依次执行各个类的构造方法，这可以保证子类对象从所有直接或间接父类中继承的实例变量都别正确地初始化。子类的所有构造方法内部，第一行会(隐式)自动先调用父类的无参构造函数(super())如果子类构造方法第一行显式调用了父类构造方法，系统就不再调用父类的无参构造函数子类的构造方法中调用父类的构造函数必须写在第一行，如果父类没有无参构造函数，子类必须在构造方法中显式调用父类的有参构造函数 继承的初始化顺序‼️ 初始化顺序：父类的静态变量(父类的静态代码块) --&gt; 子类的静态变量(子类的静态代码快) --&gt; 父类的非静态变量(父类的非静态代码块) --&gt; 父类的构造函数 --&gt; 子类的非静态变量（子类的非静态代码块）–&gt; 子类的构造函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.hts.test;public class Test &#123; public static void main(String[] args) &#123; Child c=new Child(); &#125;&#125;class Parent &#123; public static PrintMessage a=new PrintMessage(\"父类静态成员被初始化\"); private PrintMessage b=new PrintMessage(\"父类非静态成员被初始化\"); static&#123; System.out.println(\"父类的静态代码块被执行\"); &#125; &#123; System.out.println(\"父类的非静态代码块被执行\"); &#125; public Parent()&#123; System.out.println(\"父类的构造方法被执行\"); &#125;&#125;class Child extends Parent&#123; public static PrintMessage a1=new PrintMessage(\"子类静态成员被初始化\"); private PrintMessage b1=new PrintMessage(\"子类非静态成员被初始化\"); static &#123; System.out.println(\"子类的静态代码块被执行\"); &#125; &#123; System.out.println(\"子类的非静态代码块被执行\"); &#125; public Child()&#123; System.out.println(\"子类的构造函数被执行\"); &#125;&#125;class PrintMessage&#123; public PrintMessage(String mes)&#123; System.out.println(mes); &#125;&#125;output:父类静态成员被初始化父类的静态代码块被执行子类静态成员被初始化子类的静态代码块被执行父类非静态成员被初始化父类的非静态代码块被执行父类的构造方法被执行子类非静态成员被初始化子类的非静态代码块被执行子类的构造函数被执行","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———访问权限控制","slug":"java/Java编程思想/访问权限控制","date":"2018-09-28T16:00:00.000Z","updated":"2018-12-06T06:31:38.001Z","comments":true,"path":"java/65045805/","link":"","permalink":"https://maoyunfei.github.io/java/65045805/","excerpt":"Java访问权限下表为Java访问控制符的含义和使用情况同一类同一包中的类子类其他包中的类public✔️✔️✔️✔️protected✔️✔️✔️✖️default✔️✔️✖️✖️private✔️✖️✖️✖️public &gt; protected &gt; 同包(default) &gt; private","text":"Java访问权限下表为Java访问控制符的含义和使用情况同一类同一包中的类子类其他包中的类public✔️✔️✔️✔️protected✔️✔️✔️✖️default✔️✔️✖️✖️private✔️✖️✖️✖️public &gt; protected &gt; 同包(default) &gt; private‼️ Java的访问控制是停留在编译层的，也就是它不会在.class文件中留下任何的痕迹，只在编译的时候进行访问控制的检查。其实，通过反射的手段，是可以访问任何包下任何类中的成员或方法的。 利用反射调用私有方法、访问私有属性利用反射，首先是Class对象的获取，之后是Method和Field对象的获取。getMethod()方法返回的是public的Method对象，而getDeclaredMethod()返回的Method对象可以是非public的。Field的方法同理。访问私有属性和方法，在使用前要通过AccessibleObject类（Constructor、 Field和Method类的基类）中的setAccessible()方法来抑制Java访问权限的检查。 实例：调用私有方法1234567public class PrivateClass&#123; private String sayHello(String name) &#123; return \"Hello: \" + name; &#125;&#125;12345678910111213141516171819202122import java.lang.reflect.Method;public class TestPrivate&#123; public static void main(String[] args) throws Exception &#123; PrivateClass p = new PrivateClass(); Class&lt;?&gt; classType = p.getClass(); // 获取Method对象 Method method = classType.getDeclaredMethod(\"sayHello\", new Class[] &#123; String.class &#125;); method.setAccessible(true); // 抑制Java的访问控制检查 // 如果不加上上面这句，将会Error: TestPrivate can not access a member of class PrivateClass with modifiers \"private\" String str = (String) method.invoke(p, new Object[] &#123; \"zhangsan\" &#125;); System.out.println(str); &#125;&#125; 实例：访问私有属性123456789public class PrivateClass2&#123; private String name = \"zhangsan\"; public String getName() &#123; return name; &#125;&#125;1234567891011121314151617import java.lang.reflect.Field;public class TestPrivate2&#123; public static void main(String[] args) throws Exception &#123; PrivateClass2 p = new PrivateClass2(); Class&lt;?&gt; classType = p.getClass(); Field field = classType.getDeclaredField(\"name\"); field.setAccessible(true); // 抑制Java对修饰符的检查 field.set(p, \"lisi\"); System.out.println(p.getName()); &#125;&#125;","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"Java编程思想———初始化与清理","slug":"java/Java编程思想/对象初始化与清理","date":"2018-09-27T16:00:00.000Z","updated":"2018-12-06T06:31:37.967Z","comments":true,"path":"java/a2c6556/","link":"","permalink":"https://maoyunfei.github.io/java/a2c6556/","excerpt":"默认构造器默认构造器(又名无参构造器)是没有形式参数的，它的作用是创建一个“默认对象”。如果你写的类中没有构造器，则编译器会自动帮你创建一个默认构造器。如果已经定义了一个构造器，编译器就不会帮你自动创建默认构造器。","text":"默认构造器默认构造器(又名无参构造器)是没有形式参数的，它的作用是创建一个“默认对象”。如果你写的类中没有构造器，则编译器会自动帮你创建一个默认构造器。如果已经定义了一个构造器，编译器就不会帮你自动创建默认构造器。 在构造器中调用构造器可能为一个类写了多个构造器，有时可能想在一个构造器中调用另一个构造器，以避免重复代码。可用this关键字做到这一点。尽管可以用this调用一个构造器，但却不能调用两个。此外，必须将构造器调用置于最起始处，否则编译会报错。 垃圾回收1234@Overrideprotected void finalize() throws Throwable &#123; super.finalize();&#125;垃圾回收器会特别对待覆盖了finalize()方法的对象。一般情况下，在垃圾回收期间，一个无法触及的对象会立即被销毁。不过，覆盖了finalize()方法的对象会被移动到一个队列(F-Queue)里，一个独立的线程遍历这个队列，调用每一个对象的finalize()方法。在finalize()方法调用结束之后，这些对象才成为真正的垃圾，等待下一轮垃圾回收。一个对象的finalize()方法只会被调用一次，而且finalize()被调用不意味着gc会立即回收该对象，所以有可能调用finalize()后，该对象又不需要被回收了，然后到了真正要被回收的时候，因为前面调用过一次，所以不会调用finalize()，产生问题。不该将finalize()作为通用的清理方法，finalize()是一个用于释放非Java资源的方法。之所以要有finalize()，是由于在分配内存时可能采用了类似C语言中的做法，而非Java中的通常做法。这种情况主要发生在使用“本地方法”的情况下，本地方法是一种在Java中调用非本地代码的方式。 初始化初始化的顺序是先静态对象（如果它们尚未因前面的对象创建过程而被初始化），而后是“非静态”对象。静态初始化动作只进行一次。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Thinking in Java","slug":"Thinking-in-Java","permalink":"https://maoyunfei.github.io/tags/Thinking-in-Java/"}]},{"title":"第一章、分布式架构","slug":"other/第一章、分布式架构","date":"2018-05-30T16:00:00.000Z","updated":"2018-12-06T06:31:38.017Z","comments":true,"path":"distributed/b1bde3f7/","link":"","permalink":"https://maoyunfei.github.io/distributed/b1bde3f7/","excerpt":"从集中式到分布式 集中式的特点所谓的集中式系统就是指由一台或多台主计算机组成中心节点，数据集中存储于这个中心节点中，并且整个系统的所有业务单元都集中部署在这个中心节点上，系统的所有功能均由其集中处理。集中式系统最大的特点就是部署结构简单。由于集中式系统往往基于底层性能卓越的大型主机，因此无需考虑如何对服务进行多个节点的部署，也就不用考虑多个节点之间的分布式协作问题。","text":"从集中式到分布式 集中式的特点所谓的集中式系统就是指由一台或多台主计算机组成中心节点，数据集中存储于这个中心节点中，并且整个系统的所有业务单元都集中部署在这个中心节点上，系统的所有功能均由其集中处理。集中式系统最大的特点就是部署结构简单。由于集中式系统往往基于底层性能卓越的大型主机，因此无需考虑如何对服务进行多个节点的部署，也就不用考虑多个节点之间的分布式协作问题。 分布式的特点分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。严格地讲，同一个分布式系统中的计算机在空间部署上是可以随意分布的，这些计算机可能被放在不同的机柜上，也可能在不同的机房中，甚至分布在不同的城市。无论如何，一个标准的分布式系统在没有任何特定业务逻辑约束的情况下，都会有如下几个特征。分布性分布式系统中的多台计算机都会在空间上随意分布，同时，机器的分布情况也会随时变动。对等性分布式系统中的计算机没有主/从之分，既没有控制整个系统的主机，也没有被控制的从机，组成分布式系统的所有计算机节点都是对等的。副本(replica)是分布式系统最常见的概念之一，指的是分布式系统对数据和服务提供的一种冗余方式。在常见的分布式系统中，为了对外提供高可用的服务，我们往往会对数据和服务进行副本处理。数据副本是指在不同的节点上持久化同一份数据，当某一个节点上存储的数据丢失时，可以从副本上读取到该数据，这是解决分布式系统数据丢失问题最为有效的手段。另一类副本是服务副本，指多个节点提供同样的服务，每个节点都有能力接收来自外部的请求并进行相应的处理。并发性在一个计算机网络中，程序运行过程中的并发性操作是非常常见的行为，例如同一个分布式系统中的多个节点，可能会并发地操作一些共享的资源，诸如数据库或分布式存储等，如何准确并高效地协调分布式并发操作也成为了分布式系统架构个设计中最大的挑战之一。缺乏全局时钟在分布式系统中，很难定义两个事件究竟谁先谁后，原因就是因为分布式系统缺乏一个全局的时钟序列控制。故障总是会发生组成分布式系统的所有计算机，都有可能发生任何形式的故障。一个被大量工程实践所检验过的黄金定理是：任何在设计阶段考虑到的异常情况，一定会在系统实际运行中发生，并且，在系统实际运行过程中，还会遇到很多在设计时未能考虑到的异常故障。所以，除非需求指标允许，在系统设计时不能放过任何异常情况。 分布式环境的各种问题分布式系统体系结构从其出现之初就伴随着诸多的难题和挑战，本节将向读者简要的介绍分布式环境中一些典型的问题。 通信异常从集中式向分布式演变的过程中，必然引入了网络因素，而由于网络本身的不可靠性，因此也引入了额外的问题。分布式系统需要在各个节点之间进行网络通信，因此每次网络通信都会伴随着网络不可用的风险。另外，即使分布式系统各节点之间的网络通信能够正常进行，其延时也会远大于单机操作。 网络分区当网络由于发生异常情况，导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式系统的所有节点中，只有部分节点之间能够进行正常通信，而另一些节点则不能–我们将这个现象称为网络分区，就是俗称的“脑裂”。当网络分区出现时，分布式系统会出现局部小集群，在极端情况下，这些局部小集群会独立完成原本需要整个分布式系统才能完成的功能，包括对数据的事务处理，这就对分布式一致性提出了非常大的挑战。 三态分布式系统的每一次请求与响应，存在特有的“三态”概念，即成功、失败与超时。在传统的单机系统中，应用程序在调用一个函数之后，能够得到一个非常明确的响应：成功或失败。而在分布式系统中，由于网络是不可靠的，虽然在绝大多数情况下，网络通信也能够接收到成功或失败的响应，但是当网络出现异常的情况下，就可能会出现超时现象，通常有以下两种情况：由于网络原因，该请求(消息)并没有被成功地发送到接收方，而是在发生过程就发生了消息丢失现象。该请求(消息)成功的被接收方接收后，并进行了处理，但是在响应反馈给发送方的过程中，发生了消息丢失现象。当出现这样的超时现象时，网络通信的发起方是无法确定当前请求是否被成功处理的。 节点故障节点故障则是分布式环境下另一个比较常见的问题，指的是组成分布式系统的服务器节点出现的宕机或“僵死”现象。通常根据经验来说，每个节点都有可能会出现故障，并且每天都在发生。 从ACID到CAP/BASE ACID事务是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元，狭义上的事务特指数据库事务。一方面，当多个应用程序并发访问数据库时，事务可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。另一方面，事务为数据库操作序列提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持数据一致性的方法。事务具有四个特征，分别是原子性(Atomicity)、一致性(Consistency)、隔离性(Isolation)和持久性(Durability)，简称为事务的ACID特征。 原子性事务的原子性是指事务必须是一个原子的操作序列单元。事务中包含的各项操作在一次执行过程中，只允许出现以下两种状态之一。全部成功执行。全部不执行。任何一项操作失败都将导致整个事务失败，同时其他已经被执行的操作都将被撤销并回滚，只有所有的操作全部成功，整个事务才算是成功完成。 一致性事务的一致性是指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行之前和执行之后，数据库都必须处于一致性状态。也就是说，事务执行的结果必须是使数据库从一个一致性状态转变到另一个一致性状态，因此当数据库只包含成功事务提交的结果时，就能说数据库处于一致性状态。而如果数据库系统在运行过程中发生故障，有些事务尚未完成就被迫中断，这些未完成的事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是不一致的状态。 隔离性事务的隔离性是指在并发环境中，并发的事务是相互隔离的，一个事务的执行不能被其他事务干扰。也就是说，不同的事务并发操纵相同的数据时，每个事务都有各自完整的数据空间，即一个事务内部的操作及使用的数据对其他并发事务是隔离的，并发执行的各个事务之间不能互相干扰。 持久性事务的持久性也被称为永久性，是指一个事务一旦提交，它对数据库中对应数据的状态变更就应该是永久性的。换句话说，一旦某个事务成功结束，那么它对数据库所做的更新就必须被永久保存下来–即使发生系统崩溃或机器宕机等故障，只要数据库能够重新启动，那么一定能够将其恢复到事务成功结束时的状态。 分布式事务分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点之上。通常一个分布式事务中会涉及对多个数据源或业务系统的操作。 CAP和BASE理论在可用性和一致性之间永远无法存在一个两全其美的方案，于是如何构建一个兼顾可用性和一致性的分布式系统成为了无数工程师探讨的难题，出现了诸如CAP和BASE这样的分布式系统经典理论。 CAP定理CAP理论告诉我们，一个分布式系统不可能同时满足一致性(C: Consistency)、可用性(A: Availability)和分区容错性(P: Partition tolerance)这三个基本需求，做多只能同时满足其中的两项。从CAP定理中我们可以看出，一个分布式系统不可能同时满足一致性、可用性和分区容错性这三个需求。另一方面，需要明确的一点是，对于一个分布式系统而言，分区容错性可以说是一个最基本的要求。因为既然是一个分布式系统，那么分布式系统中的组件必然需要被部署到不同的节点，否则也就无所谓分布式系统了，因此必然出现子网络。而对于分布式系统而言，网络问题又是一个必定会出现的异常情况，因此分区容错性也就成为了一个分布式系统必然需要面对和解决的问题。因此系统架构设计师往往需要把精力花在如何根据业务特点在C(一致性)和A(可用性)之间寻求平衡。 BASE理论BASE是Basically Available(基本可用)、Soft state(软状态)和Eventually consistent(最终一致性)三个短语的简写。BASE是对CAP中一致性和可用性权衡的结果，其核心来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性，但每个业务都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。基本可用基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性–但请注意，这绝不等价于系统不可用。以下两个就是“基本可用”的典型例子。响应时间上的损失。功能上的损失。弱状态弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。最终一致性最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证数据的强一致性。总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性是相反的，他完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此具体分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。","categories":[{"name":"分布式","slug":"distributed","permalink":"https://maoyunfei.github.io/categories/distributed/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://maoyunfei.github.io/tags/分布式/"},{"name":"ACID","slug":"ACID","permalink":"https://maoyunfei.github.io/tags/ACID/"},{"name":"CAP","slug":"CAP","permalink":"https://maoyunfei.github.io/tags/CAP/"},{"name":"BASE","slug":"BASE","permalink":"https://maoyunfei.github.io/tags/BASE/"}]},{"title":"Java线程安全与锁优化","slug":"java/jvm/5、Java线程安全与锁优化","date":"2018-05-07T16:00:00.000Z","updated":"2018-12-06T06:31:38.075Z","comments":true,"path":"java/38b1a788/","link":"","permalink":"https://maoyunfei.github.io/java/38b1a788/","excerpt":"线程安全的实现方法 互斥同步互斥同步是常见的一种并发正确性保障手段。同步指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个(或者是一些，使用信号量的时候)线程使用。而互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。","text":"线程安全的实现方法 互斥同步互斥同步是常见的一种并发正确性保障手段。同步指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个(或者是一些，使用信号量的时候)线程使用。而互斥是实现同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。在Java中，最基本的互斥手段就是synchronized关键字，synchronized关键字经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。如果Java程序中的synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根据synchronized修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对象。根据虚拟机规范的要求，在执行monitorenter指令时，首先要尝试获取对象的锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应的，在执行monitorexit指令时会将锁计数器减1，当计数器为0时，锁就被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。在虚拟机规范对monitorenter和monitorexit的行为描述中，有两点是需要特别注意的。首先，synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。其次，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。Java的线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此状态转换需要消耗很多的处理器时间，对于代码简单的同步块，状态转换消耗的时间有可能比用户代码执行的时间还要长。所以synchronized是Java语言中一个重量级的操作，有经验的程序员都会在确实必要的情况下才使用这种操作。而虚拟机本身也会进行一些优化，譬如再通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁的切入到核心态之中。除了synchronized之外，我们还可以使用java.util.concurrent包中的重入锁(ReentrantLock)来实现同步，在基本用法上，ReentrantLock和synchronized很相似，他们都具备一样的线程重入特性，只是代码写法上有些区别，一个表现为API层面的互斥锁(lock()和unlock()方法配合try/finally语句块来完成)，另一个表现为原生语法层面的互斥锁。不过，相比synchronized，ReentrantLock增加了一些高级功能，主要有以下3项：等待可中断、可实现公平锁，以及锁可以绑定多个条件。等待可中断是指当持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁是非公平的，ReentrantLock默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。锁绑定多个条件是指一个ReentrantLock对象可以同时绑定多个Condition对象，而在synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外的添加一个锁，而ReentrantLock则无须这样做，只需要多次调用newCondition()方法即可。 非阻塞同步互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。从处理问题的方式上说，互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施(例如加锁)，那就肯定会出现问题，无论共享数据是否真的会出现竞争，它都要进行加锁、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。随着硬件指令集的发展，我们有了另外一个选择：基于冲突检测的乐观并发策略，通俗地说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施(最常见的补偿措施就是不断地重试，直到成功为止)，这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为非阻塞同步。 锁优化高效并发是从JDK 1.5到JDK 1.6的一个重要改进。实现了各种锁优化技术，如适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁等，这些技术都是为了在线程之间更高效地共享数据，以及解决竞争问题，从而提高程序的执行效率。 自旋锁与自适应自旋如果共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得。我们可以让后面请求锁的线程“稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环(自旋)，这项技术就是所谓的自旋锁。自旋等待不能代替阻塞，且先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自选等待的效果就会非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性能上的浪费。因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程了。自旋次数的默认值是10次，用户可以使用参数-XX:PreBlockSpin来更改。在JDK 1.6中引入了自适应的自旋锁。自适应意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。另外，如果对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的资源预测就会越来越准确。 锁消除锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无需进行。 锁粗化原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小(只在共享数据的实际作用域中才进行同步)，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一对象反复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。 轻量级锁轻量级锁是JDK 1.6之中加入的新型锁机制，它名字中的“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言，因此传统的锁机制就称为“重量级”锁。首先需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。要理解轻量级锁，必须从HotSpot虚拟机的对象(对象头部分)的内存布局开始介绍。HotSpot虚拟机的对象头分为两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码、GC分代年龄等，这部分数据的长度在32位和64位的虚拟机中分别为32bit和64bit，官方称它为“Mark Word”，它是实现轻量级锁和偏向锁的关键。另外一部分用于存储指向方法区对象类型数据的指针，如果是数组对象的话，还会有一个额外的部分用于存储数组长度。对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。轻量级锁能提升程序性能的依据是“对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用CAS操作避免了使用互斥量的开销，但如果存在竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞争的情况下，轻量级锁会比传统的重量级锁更慢。 偏向锁偏向锁也是JDK 1.6中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都不做了。这个锁会偏向于第一个获得它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程将永远不需要再进行同步。偏向锁可以提高带有同步但无竞争的程序性能。它同样是一个带有效益权衡性质的优化，也就是说，它并不一定总是对程序运行有利，如果程序中大多数的锁总是被多个不同的线程访问，那偏向模式就是多余的。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"Linux 查看日志常用命令","slug":"linux/linux command/Linux 查看日志常用命令","date":"2018-04-11T16:00:00.000Z","updated":"2018-12-06T06:31:37.905Z","comments":true,"path":"linux/e6c0563c/","link":"","permalink":"https://maoyunfei.github.io/linux/e6c0563c/","excerpt":"Linux 查看日志常用命令主要有tail、cat、less、more等，下面将一一介绍它们的用法。 tailtail命令可以用来查看一个文件内容。常用的参数-f常用于查阅正在改变的日志文件，常用的参数-n用于从文件的最后n行开始查阅。","text":"Linux 查看日志常用命令主要有tail、cat、less、more等，下面将一一介绍它们的用法。 tailtail命令可以用来查看一个文件内容。常用的参数-f常用于查阅正在改变的日志文件，常用的参数-n用于从文件的最后n行开始查阅。 实例查看日志文件的最后100行1tail -n 100 /var/log/mail.log实时从日志文件中获取所有新添加的行1tail -f /var/log/mail.log提示： 按[ctrl]+[c]来退出tail命令并回到命令行。如果想从日志文件中获取最后1000行，并且它们不适合在shell窗口全部展示，则可以使用命令more来逐行查看它们。1tail -n 1000 /var/log/mail.log | more提示： 按空格转到下一行或者按[ctrl]+[c]来退出。如果想在大文件中搜索特定的词，可以使用grep命令1grep \"tom@anydomain.tld\" /var/log/mail.log catcat命令可以用来查看文件的全部内容。1cat /var/log/mail.log lessless命令可以用来随意浏览文件，而且less在查看之前不会加载整个文件。 语法1less [参数] 文件参数说明：-b &lt;缓冲区大小&gt; 设置缓冲区的大小-e 当文件显示结束后，自动离开-f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件-g 只标志最后搜索的关键词-i 忽略搜索时的大小写-m 显示类似more命令的百分比-N 显示每行的行号-o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来-Q 不使用警告音-s 显示连续空行为一行-S 行过长时间将超出部分舍弃-x &lt;数字&gt; 将&quot;tab&quot;键显示为规定的数字空格/字符串：向下搜索&quot;字符串&quot;的功能?字符串：向上搜索&quot;字符串&quot;的功能n：重复前一个搜索（与 / 或 ? 有关）N：反向重复前一个搜索（与 / 或 ? 有关）b 向后翻一页d 向后翻半页h 显示帮助界面Q 退出less 命令u 向前滚动半页y 向前滚动一行空格键 滚动一页回车键 滚动一行[pagedown]： 向下翻动一页[pageup]： 向上翻动一页 附加备注全屏导航ctrl + F - 向前移动一屏ctrl + B - 向后移动一屏ctrl + D - 向前移动半屏ctrl + U - 向后移动半屏单行导航j - 向前移动一行k - 向后移动一行其它导航G - 移动到最后一行g - 移动到第一行q / ZZ - 退出 less 命令其它有用的命令v - 使用配置的编辑器编辑当前文件h - 显示 less 的帮助文档&amp;pattern - 仅显示匹配模式的行，而不是整个文件标记导航当使用 less 查看大文件时，可以在任何一个位置作标记，可以通过命令导航到标有特定标记的文本位置：ma - 使用 a 标记文本的当前位置'a - 导航到标记 a 处 moremore以一页一页的形式显示，更方便使用者逐页阅读。 语法1more [-dlfpcsu] [-num] [+/pattern] [+linenum] [fileNames..]参数说明：-num 一次显示的行数-d 提示使用者，在画面下方显示 [Press space to continue, ‘q’ to quit.] ，如果使用者按错键，则会显示 [Press ‘h’ for instructions.] 而不是 ‘哔’ 声-l 取消遇见特殊字元 ^L（送纸字元）时会暂停的功能-f 计算行数时，以实际上的行数，而非自动换行过后的行数（有些单行字数太长的会被扩展为两行或两行以上）-p 不以卷动的方式显示每一页，而是先清除萤幕后再显示内容-c 跟 -p 相似，不同的是先显示内容再清除其他旧资料-s 当遇到有连续两行以上的空白行，就代换为一行的空白行-u 不显示下引号 （根据环境变数 TERM 指定的 terminal 而有所不同）+/pattern 在每个文档显示前搜寻该字串（pattern），然后从该字串之后开始显示+num 从第 num 行开始显示fileNames 欲显示内容的文档，可为复数个数 实例逐页显示 testfile 文档内容，如有连续两行以上空白行则以一行空白行显示。1more -s testfile从第 20 行开始显示 testfile 之文档内容。1more +20 testfile 常用操作命令Enter 向下n行，需要定义。默认为1行Ctrl+F 向下滚动一屏空格键 向下滚动一屏Ctrl+B 返回上一屏= 输出当前行的行号：f 输出文件名和当前行的行号V 调用vi编辑器!命令 调用Shell，并执行命令q 退出more","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Spring Cloud Feign 日志设置","slug":"spring/spring cloud/Spring Cloud Feign 日志设置","date":"2018-04-10T16:00:00.000Z","updated":"2018-12-06T06:31:37.961Z","comments":true,"path":"spring/50228a36/","link":"","permalink":"https://maoyunfei.github.io/spring/50228a36/","excerpt":"由于FeignClient封装了restful请求，我们很难看出发出的请求和收到的响应具体是什么。为此我们可以做一些设置来打印出相应的日志。","text":"由于FeignClient封装了restful请求，我们很难看出发出的请求和收到的响应具体是什么。为此我们可以做一些设置来打印出相应的日志。 日志配置第一步，编写FeignClient的configuration类。1234567@Configurationpublic class FeignLogConfiguration &#123; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125;12345@FeignClient(name = \"microservice-provider-user\", configuration = FeignLogConfiguration.class)public interface UserFeignClient &#123; @RequestMapping(value = \"/&#123;id&#125;\", method = RequestMethod.GET) public User findById(@PathVariable(\"id\") Long id);&#125;Feign的日志级别枚举如下：第二步，配置FeignClient所在包的日志级别为DEBUG1234# application.ymllogging: level: com.cloud.study.feign: DEBUG如果你不是在application.yml中配置的日志级别，而是使用logback-spring.xml，同理，在logback-spring.xml中做相应配置：1234# logback-spring.xml&lt;logger name=\"com.cloud.study.feign\" level=\"DEBUG\" additivity=\"false\"&gt; &lt;appender-ref ref=\"Console\"/&gt;&lt;/logger&gt; 日志输出当你配置完以上之后，每次FeignClient的调用都会打印出详细日志，具体如下：","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"},{"name":"Feign","slug":"Feign","permalink":"https://maoyunfei.github.io/tags/Feign/"}]},{"title":"Java并发之AQS详解","slug":"java/Java并发之AQS详解","date":"2018-04-09T16:00:00.000Z","updated":"2018-12-06T06:26:12.740Z","comments":true,"path":"java/362c3925/","link":"","permalink":"https://maoyunfei.github.io/java/362c3925/","excerpt":"谈到并发，不得不谈AbstractQueuedSynchronizer(AQS)。类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock、Semaphore、CountDownLatch等。","text":"谈到并发，不得不谈AbstractQueuedSynchronizer(AQS)。类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock、Semaphore、CountDownLatch等。 AQS数据结构 AQS简介AQS提供了一个基于FIFO队列，可以用于构建锁或者其他相关同步装置的基础框架。该同步器利用了一个int来表示状态，期望它能够成为实现大部分同步需求的基础。使用的方法是继承，子类通过继承同步器并需要实现它的方法来管理其状态，管理的方式就是通过类似acquire和release的方式来操纵状态。然而多线程环境中对状态的操纵必须确保原子性，因此子类对于状态的把握，需要使用这个同步器提供的以下三个方法对状态进行操作：java.util.concurrent.locks.AbstractQueuedSynchronizer.getState()java.util.concurrent.locks.AbstractQueuedSynchronizer.setState(int)java.util.concurrent.locks.AbstractQueuedSynchronizer.compareAndSetState(int, int)AQS定义两种资源共享方式：Exclusive(独占模式，只有一个线程能执行，如ReentrantLock)和Share(共享模式，多个线程可同时执行，如Semaphore/CountDownLatch)。 同步器与锁同步器是实现锁的关键，利用同步器将锁的语义实现，然后在锁的实现中聚合同步器。可以这样理解：锁的API是面向使用者的，它定义了与锁交互的公共行为，而每个锁需要完成特定的操作也是透过这些行为来完成的（比如：可以允许两个线程进行加锁，排除两个以上的线程），但是实现是依托给同步器来完成；同步器面向的是线程访问和资源控制，它定义了线程对资源是否能够获取以及线程的排队等操作。锁和同步器很好的隔离了二者所需要关注的领域，严格意义上讲，同步器可以适用于除了锁以外的其他同步设施上(包括锁)。同步器的开始提到了其实现依赖于一个FIFO队列，那么队列中的元素Node就是保存着线程引用和线程状态的容器，每个线程对同步器的访问，都可以看做是队列中的一个节点。Node的主要包含以下成员变量：1234567Node &#123; int waitStatus; Node prev; Node next; Node nextWaiter; Thread thread;&#125;以上五个成员变量主要负责保存该节点的线程引用，同步等待队列(sync队列)的前驱和后继节点，同时也包括了同步状态。属性名称描述int waitStatus表示节点的状态。其中包含的状态有：1. CANCELLED，值为1，表示当前的线程被取消；2. SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark；3. CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中；4. PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行；5. 值为0，表示当前节点在sync队列中，等待着获取锁。Node prev前驱节点，比如当前节点被取消，那就需要前驱节点和后继节点来完成连接。Node next后继节点。Node nextWaiter存储condition队列中的后继节点。Thread thread入队列时的当前线程。节点成为sync队列和condition队列构建的基础，在同步器中就包含了sync队列。同步器拥有三个成员变量：sync队列的头结点head、sync队列的尾节点tail和状态state。对于锁的获取，请求形成节点，将其挂载在尾部，而锁资源的转移(释放再获取)是从头部开始向后进行。对于同步器维护的状态state，多个线程对其的获取将会产生一个链式的结构。 API说明实现自定义同步器时，需要使用同步器提供的getState()、setState()和compareAndSetState()方法来操纵状态的变迁。方法名称描述protected boolean tryAcquire(int arg)独占方式。尝试获取资源，成功则返回true，失败则返回false。protected boolean tryRelease(int arg)独占方式。尝试释放资源，成功则返回true，失败则返回false。protected int tryAcquireShared(int arg)共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。protected boolean tryReleaseShared(int arg)共享方式。尝试释放资源，成功则返回true，失败则返回false。protected boolean isHeldExclusively()该线程是否正在独占资源。只有用到condition才需要去实现它。实现这些方法必须是非阻塞而且是线程安全的，推荐使用该同步器的父类java.util.concurrent.locks.AbstractOwnableSynchronizer来设置当前的线程。 总结AQS核心是通过一个共享变量来同步状态，变量的状态由子类去维护，而AQS框架做的是：线程阻塞队列的维护线程阻塞和唤醒共享变量的修改都是通过Unsafe类提供的CAS操作完成的。AbstractQueuedSynchronizer类的主要方法是acquire和release，典型的模板方法，下面这4个方法由子类去实现：1234protected boolean tryAcquire(int arg)protected boolean tryRelease(int arg)protected int tryAcquireShared(int arg)protected boolean tryReleaseShared(int arg)acquire方法用来获取锁，返回true说明线程获取成功继续执行，一旦返回false则线程加入到等待队列中，等待被唤醒，release方法用来释放锁。 一般来说实现的时候这两个方法被封装为lock和unlock方法。 参考资料AbstractQueuedSynchronizer的介绍和原理分析Java并发之AQS详解","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"},{"name":"AQS","slug":"AQS","permalink":"https://maoyunfei.github.io/tags/AQS/"},{"name":"并发","slug":"并发","permalink":"https://maoyunfei.github.io/tags/并发/"}]},{"title":"Java并发之CAS原理剖析","slug":"java/Java并发之CAS原理剖析","date":"2018-04-08T16:00:00.000Z","updated":"2018-12-06T06:26:12.859Z","comments":true,"path":"java/64788dff/","link":"","permalink":"https://maoyunfei.github.io/java/64788dff/","excerpt":"CAS(Compare and Swap)，即比较并交换，是实现并发算法常用的一种技术。CAS的思想很简单：三个参数，一个当前内存值V、旧的预期值A、即将更新的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做，并返回false。","text":"CAS(Compare and Swap)，即比较并交换，是实现并发算法常用的一种技术。CAS的思想很简单：三个参数，一个当前内存值V、旧的预期值A、即将更新的值B，当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做，并返回false。 问题一个n++的问题。12345678public class Case &#123; public volatile int n; public void add() &#123; n++; &#125;&#125;n++其实是被拆分成了几个指令：执行getfield拿到原始n；执行iadd进行加1操作；执行putfield写把累加后的值写回n；通过volatile修饰的变量可以保证线程之间的可见性，但并不能保证这3个指令的原子执行，在多线程并发执行下，无法做到线程安全，得到正确的结果。 如何解决在add方法加上synchronized修饰解决。12345678public class Case &#123; public volatile int n; public synchronized void add() &#123; n++; &#125;&#125;但是synchronized属于重量级锁，很多时候会引起性能问题，像synchronized这种独占锁属于悲观锁，它是在假设一定会发生冲突的，那么加锁恰到好处，除此之外，还有乐观锁，乐观锁的含义就是假设没有发生冲突，那么我正好可以进行某项操作，如果要是发生冲突呢，那我就重试直到成功，乐观锁最常见的就是CAS。再来看一段代码：12345678public int a = 1;public boolean compareAndSwapInt(int b) &#123; if (a == 1) &#123; a = b; return true; &#125; return false;&#125;以上代码在并发下执行，结果是无法符合预期的，无法确认a的最终值。同样可以在compareAndSwapInt方法加锁同步，变成一个原子操作，同一时刻只有一个线程能够修改变量a。除了低性能的加锁方案，我们可以使用JDK自带的CAS方案，在CAS中，比较和替换是一组原子操作，不会被外部打断，且在性能上更占优势。下面以AutomicInteger的实现为例，分析一下CAS是如何实现的。123456789101112131415public class AtomicInteger extends Number implements java.io.Serializable &#123; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; public final int get() &#123;return value;&#125;&#125;Unsafe，是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地(native)方法来访问，Unsafe相当于一个后门，基于该类可以直接操作特定内存的数据。变量valueOffset，表示该变量值在内存中的偏移地址，因为Unsafe就是根据内存偏移地址获取数据的。变量value用volatile修饰，保证了多线程之间的内存可见性。看看AutomicInteger如何实现并发下的累加操作：123456789101112public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta);&#125;//unsafe.getAndAddIntpublic final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125;假设线程A和线程B同时执行getAndAdd操作：AutomicInteger里面的value原始值为3，即主内存中AutomicInteger的value为3，根据Java内存模型，线程A和线程B各自持有一份value的副本，值为3。线程A通过getIntVolatile(var1, var2)拿到value值3，这时线程A被挂起。线程B也通过getIntVolatile(var1, var2)方法获取到value值3，运气好，线程B没有被挂起，并执行compareAndSwapInt方法比较内存值也为3，成功修改内存值为2。这时线程A恢复，执行compareAndSwapInt方法比较，发现自己手里的值(3)和内存的值(2)不一致，说明该值已经被其它线程提前修改过了，那只能重新来一遍了。重新获取value值，因为变量value被volatile修饰，所以其它线程对它的修改，线程A总是能够看到，线程A继续执行compareAndSwapInt进行比较替换，直到成功。整个过程中，利用CAS保证了对于value的修改的并发安全，继续深入看看Unsafe类中的compareAndSwapInt方法实现。1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);Unsafe类中的compareAndSwapInt，是一个本地方法，该方法的实现位于unsafe.cpp中。compareAndSwapInt(var1, var2, var5, var5 + var4)其实换成compareAndSwapInt(obj, offset, expect, update)比较清楚，意思就是如果obj内的value和expect相等，就证明没有其他线程改变过这个变量，那么就更新它为update，如果这一步的CAS没有成功，那就采用自旋的方式继续进行CAS操作。 CAS的问题 ABA问题CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。这就是CAS的ABA问题。常见的解决思路是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A-B-A就会变成1A-2B-3A。目前在JDK的automic包里提供了一个类AutomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 循环时间长开销大如果CAS不成功，则会原地自旋，如果长时间自旋会给CPU带来非常大的执行开销。 只能保证一个共享变量的原子操作当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。从Java 1.5开始JDK提供了AutomicReference类来保证引用对象之间的原子性，你可以把多个变量放到一个对象里来进行CAS操作。 总结synchronized属于重量级锁，悲观锁，可以修饰代码块，修饰方法，修饰静态方法。CAS是非阻塞的，轻量级锁，乐观锁。悲观锁机制存在的问题：在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。一个线程持有锁会导致其他所有需要此锁的线程挂起。如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。CAS在竞争激烈的时候会长时间自旋，引起性能问题。 参考资料深入浅出CASJava CAS 原理剖析","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"},{"name":"并发","slug":"并发","permalink":"https://maoyunfei.github.io/tags/并发/"},{"name":"CAS","slug":"CAS","permalink":"https://maoyunfei.github.io/tags/CAS/"}]},{"title":"《高性能Mysql》第五章、创建高性能的索引","slug":"mysql/第五章、创建高性能的索引","date":"2018-04-06T16:00:00.000Z","updated":"2018-12-06T06:31:37.983Z","comments":true,"path":"mysql/141f85cb/","link":"","permalink":"https://maoyunfei.github.io/mysql/141f85cb/","excerpt":"索引是存储引擎用于快速找到记录的一种数据结构。索引对于良好的性能非常关键。尤其是当表中的数据量越来越大时，索引对性能的影响愈发重要。在数据量较小且负载较低时，不恰当的索引对性能的影响可能还不明显，但是当数据量逐渐增大时，性能则会急剧下降。索引优化是对查询性能优化最有效的手段。","text":"索引是存储引擎用于快速找到记录的一种数据结构。索引对于良好的性能非常关键。尤其是当表中的数据量越来越大时，索引对性能的影响愈发重要。在数据量较小且负载较低时，不恰当的索引对性能的影响可能还不明显，但是当数据量逐渐增大时，性能则会急剧下降。索引优化是对查询性能优化最有效的手段。 索引的类型在Mysql中，索引是在存储引擎层而不是服务器层实现的。 所以并没有统一的索引标准：不同存储引擎的索引的工作方式并不一样，也不是所有的存储引擎都支持所有类型的索引。即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。 B-Tree索引当人们谈论索引的时候，如果没有特别指明类型，那多半说的是B-Tree索引，它使用B-Tree数据结构来存储数据。大多数存储引擎都支持这种索引。B-Tree通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同。B-Tree索引能够加快访问数据的速度，因为存储引擎不再需要进行全表扫描来获取需要的数据，取而代之的是从索引的根节点开始进行搜索。B-Tree对索引列是顺序阻止存储的，所以很适合查找范围数据。可以使用B-Tree索引的查询类型。B-Tree索引适用于全键值、键值范围或前缀查找。其中键前缀查找只适用于根据最左前缀的查找。 全值匹配全值匹配指的是和索引中的所有列进行匹配。 匹配最左前缀只匹配索引的第一列。 匹配列前缀只匹配某一列的值得开头部分。 匹配范围值 精确匹配某一列并范围匹配另一列 只访问索引的查询因为索引树中的节点是有序的，所以除了按值查找之外，索引还可以用于查询中的ORDER BY操作。一般来说，如果B-Tree可以按照某种方式查找到值，那么也可以按照这种方式用于排序。所以，如果ORDER BY子句满足前面列出的几种查询类型，则这个索引也可以满足对应的排序需求。 下面是关于B-Tree索引的限制如果不是按照索引的最左列开始查找，则无法使用索引。不能跳过索引中的列。如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找。由以上可见，索引列的顺序是多么重要：这些限制都和索引列的顺序有关。在优化性能的时候，可能需要使用相同的列但顺序不同的索引来满足不同类型的查询需求。 哈希索引哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效。在Mysql中，只有Memory引擎显式支持哈希索引。这也是Memory引擎表的默认索引类型，Memory引擎同时也支持B-Tree索引。 全文索引全文索引是一种特殊类型的索引，它查找的是文本中的关键词，而不是直接比较索引中的值。全文索引和其他几类索引的匹配方式完全不一样。它有许多需要注意的细节，如停用词、词干和复数、布尔搜索等。全文索引更类似于搜索引擎做的事情，而不是简单的WHERE条件匹配。在相同的列上同时创建全文索引和基于值的B-Tree索引不会有冲突，全文索引适用于MATCH AGAINST操作，而不是普通的WHERE条件操作。 索引的优点索引大大减少了服务器需要扫描的数据量。索引可以帮助服务器避免排序和临时表。索引可以将随机I/O变为顺序I/O。 高性能的索引策略正确地创建和使用索引是实现高性能查询的基础。 独立的列“独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数。例如，下面这个查询无法使用actor_id列的索引：1mysql&gt; SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;下面是另一个常见的错误：1mysql&gt; SELECT ... WHERE TO_DATS(CURRENT_DATE) - TO_DAYS(date_col) &lt;= 10; 前缀索引和索引选择性有时候需要索引很长的字符列，这会让索引变得大且慢。通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。但这样也会降低索引的选择性。**索引的选择性是指，不重复的索引值和数据表的记录总数(#T)的比值，范围从1/#T到1之间。索引的选择性越高则查询效率越高，因为选择性高的索引可以让Mysql在查找时过滤掉更多的行。**唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。一般情况下某个列前缀的选择性也是足够高的，足以满足查询性能。对于BLOB、TEXT或者很长的VARCHAR类型的列，必须使用前缀索引，因为Mysql不允许索引这些列的完整长度。在city列上创建长度为7的前缀索引：1mysql&gt; ALTER TABLE sakila.city_demo ADD KEY (city(7))前缀索引是一种能使索引更小、更快的有效办法。但另一方面也有其缺点：Mysql无法使用前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描。 多列索引在多个列上建立独立的单列索引大部分情况下并不能提高Mysql的查询性能。Mysql 5.0和更新版本引入了一种叫“索引合并”(index merge)的策略，一定程度上可以使用表上的多个单列索引来定位指定的行。下面的查询就是使用了两个索引扫描的联合，通过EXPLAIN的Extra列可以看到这点：1234567891011121314mysql&gt; EXPLAIN SELECT film_id, actor_id FROM sakila.film_actorWHERE actor_id = 1 OR film_id = 1************************ 1. row ****************************** id: 1 select_type: SIMPLE table: film_actor type: index_mergepossible_keys: PRIMARY,idx_fk_film_id key: PRIMARY,idx_fk_film_id key_len: 2,2 ref: NULL rows: 29 Extra: Using union(PRIMARY,idx_fk_film_id); Using whereMysql会使用这类技术优化复杂查询，所以某些语句的Extra列中还可以看到嵌套操作。索引合并策略有时候是一种优化的结果，但实际上更多时候说明了表上的索引建得很糟糕：当出现服务器对多个索引做相交操作时(通常有多个AND条件)，通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引。当服务器需要对多个索引做联合操作时(通常有多个OR条件)，通常需要耗费大量CPU和内存资源在算法的缓存、排序和合并操作上。特别是当其中有些索引的选择性不高，需要合并扫描返回的大量数据的时候。更重要的是，优化器不会把这些计算到“查询成本”中，优化器只关心随机页读取。这会使得查询的成本被低估，导致该执行计划还不如直接走全表扫描。这样做不但会消耗更多的CPU和内存资源，还可能会影响查询的并发性，但如果是单独运行这样的查询则往往会忽略对并发性的影响。通常来说，还不如将查询改写成UNION的方式更好。如果在EXPLAIN中看到有索引合并，应该好好检查一下查询和表的结构，看是不是已经是最优的。也可以通过参数optimizer_switch来关闭索引合并功能。也可以使用IGNORE_INDEX提示让优化器忽略掉某些索引。 选择合适的索引列顺序正确的顺序依赖于使用该索引的查询，并且同时需要考虑如何更好地满足排序和分组的需要。在一个多列B-Tree索引中，索引列的顺序意味着索引首先按照最左列进行排序，其次是第二列，等等。所以，索引可以按照升序或者降序进行扫描，以满足精确符合列顺序的ORDER BY、GROUP BY和DISTINCT等子句的查询需求。所以多列索引的列顺序至关重要。对于如何选择索引的列顺序有一个经验法则：将选择性最高的列放到索引最前列。当不需要排序和分组时，将选择性最高的列放在前面通常是很好的。这时候索引的作用只是用于优化WHERE条件的查找。在这种情况下，这样设计的索引确实能够最快地过滤出需要的行，对于在WHERE子句中只使用了索引部分前缀列的查询来说选择性也更高。然而，性能不只是依赖于所有索引列的选择性，也和查询条件的具体值有关，也就是和值的分布有关。可能需要根据那些运行频率最高的查询来调整索引列的顺序，让这种情况下索引的选择性更高。 聚簇索引聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。当表有聚簇索引时，它的数据行实际上存放在索引的叶子页中。因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。InnoDB将通过主键聚集数据，如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。InnoDB只聚集在同一个页面中的记录。包含相邻键值得页面可能会相距甚远。聚簇索引的优点：可以把相关数据保存在一起。数据访问更快。使用覆盖索引扫描的查询可以直接使用页节点中的主键值。聚簇索引的缺点：聚簇索引最大限度地提高了I/O密集型应用的性能，但如果数据全部都放在内存中，则访问的顺序就没那么重要了，聚簇索引也就没什么优势了。插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到InnoDB表中速度最快的方式。但如果不是按照主键顺序加载数据，那么在加载完成后最好使用OPTIMIZE TABLE命令重新组织一下表。更新聚簇索引列的代价很高，因为会强制InnoDB将每个被更新的行移动到新的位置。基于聚簇索引的表在插入新行，或者主键被更新导致需要移动行时，可能面临“页分裂”的问题。当行的主键值要求必须将这一行插入到已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作。页分裂会导致表占用更多的磁盘空间。聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。二级索引(非聚簇索引)可能比想象的要更大，因为在二级索引的叶子节点包含了引用行的主键列。二级索引访问需要两次索引查找，而不是一次。 覆盖索引如果一个索引包含(或者说覆盖)所有需要查询的字段的值，我们就称之为“覆盖索引”。不是所有类型的索引都可以成为覆盖索引。覆盖索引必须要存储索引列的值，而哈希索引、空间索引和全文索引等都不存储索引列的值，所以Mysql只能使用B-Tree索引做覆盖索引。 使用索引扫描来做排序Mysql有两种方式可以生成有序的结果：通过排序操作；或者按索引顺序扫描；如果EXPLAIN出来的type列的值为&quot;index&quot;，则说明Mysql使用了索引扫描来做排序。扫描索引本身是很快的，因为只需要从一条索引记录移动到紧接着的下一条记录。但如果索引不能覆盖查询所需的全部列，那就不得不每扫描一条索引记录就都回表查询一次对应的行。这基本上都是随机I/O，因此按索引顺序读取数据的速度通常要比顺序地全表扫描慢，尤其是在I/O密集型的工作负载时。Mysql可以使用同一个索引既满足排序，有用于查找。只有当索引的列顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向(倒序或正序)都一样时，Mysql才能够使用索引来对结果做排序。如果查询需要关联多张表，则只有当ORDER BY子句引用的字段全部为第一个表时，才能使用索引做排序。ORDER BY子句和查找型查询的限制是一样的：需要满足索引的最左前缀的要求，否则Mysql都需要执行排序操作，而无法利用索引排序。有一种情况下ORDER BY子句可以不满足索引的最左前缀的要求，就是前导列为常量的时候。如果WHERE子句或者JOIN子句中对这些列指定了常量，就可以“弥补”索引的不足。 索引和锁索引可以让查询锁定更少的行。如果你的查询从不访问那些不需要的行，那么就会锁定更少的行，从两个方面来看这对性能都有好处。首先，虽然InnoDB的行锁效率很高，内存使用也很少，但是锁定行的时候仍然会带来额外开销；其次，锁定超过需要的行会增加锁争用并减少并发性。","categories":[{"name":"Mysql","slug":"mysql","permalink":"https://maoyunfei.github.io/categories/mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://maoyunfei.github.io/tags/Mysql/"}]},{"title":"《高性能Mysql》第四章、Schema与数据类型优化","slug":"mysql/第四章、Schema与数据类型优化","date":"2018-04-03T16:00:00.000Z","updated":"2018-12-06T06:31:37.955Z","comments":true,"path":"mysql/5c550ee2/","link":"","permalink":"https://maoyunfei.github.io/mysql/5c550ee2/","excerpt":"良好的逻辑设计和物理设计是高性能的基础，应该根据系统将要执行的查询语句来设计schema，这往往需要权衡各种因素。 选择优化的数据类型Mysql支持的数据类型非常多，选择正确的数据类型对于获得高性能至关重要。不管存储哪种类型的数据，下面几个简单的原则都有助于做出更好的选择。","text":"良好的逻辑设计和物理设计是高性能的基础，应该根据系统将要执行的查询语句来设计schema，这往往需要权衡各种因素。 选择优化的数据类型Mysql支持的数据类型非常多，选择正确的数据类型对于获得高性能至关重要。不管存储哪种类型的数据，下面几个简单的原则都有助于做出更好的选择。更小的通常更好一般情况下，应该尽量使用可以正确存储数据的最小数据类型。简单就好简单数据类型的操作通常需要更少的CPU周期。尽量避免NULL很多表都可包含为NULL(空值)的列，即使应用程序并不需要保存NULL也是如此，这是因为可为NULL是列的默认属性。通常情况下最好指定列为NOT NULL，除非真的需要存储NULL值。在为列选择数据类型时，第一步需要确定合适的大类型：数字、字符串、时间等。下一步是选择具体类型。很多Mysql的数据类型可以存储相同类型的数据，只是存储的长度和范围不一样、允许的精度不同，或者需要的物理空间(磁盘和内存空间)不同。相同大类型的不同子类型数据有时也有一些特殊的行为和属性。 整数类型有两种类型的数字：整数和实数。如果存储整数，可以使用这几种整数类型：TINYINT,SMALLINT,MEDIUMINT,INT,BIGINT。分别使用8，16，24，32，64位存储空间。它们可以存储的值得范围从−2(n−1)-2^{\\left( n-1\\right) }−2(n−1)到2(n−1)−12^{\\left( n-1\\right) }-12(n−1)−1，其中N是存储空间的位数。整数类型有可选的UNSIGNED属性，表示不允许空值，这大致可以使正数的上限提高一倍。 实数类型实数是带有小数部分的数字。然而，它们不只是为了存储小数部分；也可以使用DECIMAL存储比BIGINT还大的整数。Mysql既支持精确类型，也支持不精确类型。FLOAT和DOUBLE类型支持使用标准的浮点运算进行近似计算。DECIMAL类型用于存储精确地小数。浮点和DECIMAL类型都可以指定精度。浮点类型在存储同样范围的值时，通常比DECIMAL使用更少的空间。FLOAT使用4个字节存储。DOUBLE占用8个字节。 字符串类型 VARCHAR和CHAR类型VARCHAR和CHAR是两种最主要的字符串类型。关于两种类型的一些比较。VARCHARVARCHAR类型用于存储可变长字符串，是最常见的字符串数据类型。它比定长类型更节省空间，因为它仅使用必要的空间。**VARCHAR需要使用1或2个额外字节记录字符串的长度：如果列的最大长度小于或等于255字节，则只使用1个字节表示，否则使用2个字节。**假设使用latin1字符集，一个VARCHAR(10)的列需要11个字节的存储空间。VARCHAR(1000)的列则需要1002个字节，因为需要2个字节存储长度信息。下面这些情况下使用VARCHAR是合适的：字符串列的最大长度比平均长度大很多；列的更新更少，所以碎片不是问题；使用了像UTF-8这样复杂的字符集，每个字符都使用不同的字节数进行存储。CHARCHAR类型是定长的：Mysql总是根据定义的字符串长度分配足够的空间。当存储CHAR值时，Mysql会删除所有的末尾空格。CHAR值会根据需要采用空格进行填充以方便比较。**CHAR适合存储很短的字符串，或者所有值都接近同一个长度。对于经常变更的数据，CHAR也比VARCHAR更好，因为定长的CHAR类型不容易产生碎片。对于非常短的列，CHAR比VARCHAR在存储空间上也更有效率。**例如用CHAR(1)来存储只有Y和N的值，如果采用单字节字符集只需要一个字节，但是VARCHAR(1)却需要两个字节，因为还有一个记录长度的额外字节。与CHAR和VARCHAR类似的类型还有BINARY和VARBINARY，它们存储的是二进制字符串。二进制字符串跟常规字符串非常相似，但是二进制字符串存储的是字节码而不是字符。填充也不一样：Mysql填充BINARY采用的是\\0(零字节)而不是空格，在检索时也不会去掉填充值。使用VARCHAR(5)和VARCHAR(200)存储‘hello’的空间开销是一样的。那么使用更短的列有什么优势吗？事实证明有很大优势。更长的列会消耗更多的内存，因为Mysql通常会分配固定大小的内存块来保存内存值。尤其是使用内存临时表进行排序或操作时会特别糟糕。在利用磁盘临时表进行排序时也同样糟糕。所以最好的策略是只分配真正需要的空间。 BLOB和TEXT类型BLOB和TEXT都是为存储很大的数据而设计的字符串数据类型，分别采用二进制和字符方式存储。字符类型是TINYTEXT,SMALLTEXT,TEXT,MEDIUMTEXT,LONGTEXT；对应的二进制类型是TINYBLOB,SMALLBLOB,BLOB,MEDIUMBLOB,LONGBLOB。BLOB是SMALLBLOB的同义词，TEXT是SMALLTEXT的同义词。与其他类型不同，Mysql把每个BLOB和TEXT值当作一个独立的对象处理。存储引擎在存储时通常会做特殊处理。当BLOB和TEXT值太大时，InnoDB会使用专门的外部存储区域来进行存储，此时每个值在行内需要1~4个字节存储指针，然后在外部存储区域存储实际值。BLOB和TEXT家族之间仅有的不同是BLOB类型存储的是二进制数据，没有排序规则或字符集，而TEXT字符有字符集和排序规则。Mysql不能将BLOB和TEXT列全部长度的字符串进行索引，也不能使用这些索引消除排序。 使用枚举(ENUM)代替字符串类型有时候可以使用枚举列代替常用的字符串类型。枚举列可以把一些不重复的字符串存储成一个预定义的集合。 日期和时间类型Mysql可以使用许多类型来保存日期和时间值，例如YEAR和DATE。Mysql能存储的最小时间粒度为秒。但是Mysql也可以使用微秒级的粒度进行临时运算。 DATETIME这个类型能保存大范围的值，从1001年到9999年，精度为秒。它把日期和时间封装到格式为YYYYMMDDHHMMSS的整数中，与时区无关。使用8个字节的存储空间。默认情况下，Mysql以一种可排序的、无歧义的格式显示DATETIME值，例如“2008-01-16 22：37：08”。这是ANSI标准定义的日期和时间表示方法。 TIMESTAMPTIMESTAMP类型保存了从1970年1月1日午夜(格林尼治标准时间)以来的秒数，它和UNIX时间戳相同。TIMESTAMP只使用4个字节的存储空间，因此它的范围比DATETIME小得多：只能表示从1970年到2038年。Mysql提供了FROM_UNIXTIME()函数把Unix时间戳转换为日期，并提供了UNIX_TIMESTAMP()函数把日期转换为Unix时间戳。TIMESTAMP显示的值依赖于时区。Mysql服务器、操作系统，以及客户端连接都有时区设置。TIMESTAMP有DATETIME没有的特殊属性。默认情况下，如果插入时没有指定第一个TIMESTAMP列的值，Mysql则设置这个列的值为当前时间。再更新一条记录时，Mysql默认也会更新第一个TIMESTAMP列的值(除非在UPDATE语句中明确指定了值)。TIMESTAMP列默认为NOT NULL，这也和其他的数据类型不一样。除了特殊行为外，通常也应该尽量使用TIMESTAMP，因为它比DATETIME空间效率更高。 位数据类型Mysql有少数几种存储类型使用紧凑的位存储数据。所有这些位类型，从技术上来说都是字符串类型。 BIT可以使用BIT列在一列中存储一个或多个``true/false值。BIT(1)定义一个包含单个位的字段，BIT(2)存储两个位，依此类推。BIT`列的最大长度是64个位。应该谨慎使用BIT类型。对于大部分应用，最好避免使用这种类型。如果想在一个bit的存储空间中存储一个true/false值，另一个方法是创建一个可以为空的CHAR(0)列。该列可以保存空值(NULL)或者长度为零的字符串(空字符串)。 SET如果需要保存很多true/false值，可以考虑合并这些列到一个SET数据类型，它在Mysql内部是以一系列打包的位的集合来表示的。 选择标识符整数类型整数通常是标识列最好的选择，因为它们很快并且可以使用AUTO_INCREMENT。ENUM和SET类型对于标识列来说，ENUM和SET类型通常是一个糟糕的选择。字符串类型如果可能，应该避免使用字符串类型作为标识列，因为它们很消耗空间，并且通常比数字类型慢。如果存储UUID值，则应该移除“-”符号，或者更好的做法是，用UNHEX()函数转换UUID值为16字节的数字，并且存储在一个BINARY(16)列中。检索时可以通过HEX()函数来格式化为十六进制格式。 Mysql schema设计中的陷阱太多的列太多的关联（一个粗略的经验法则，如果希望执行得快速其并发性好，单个查询最好在12个表以内做关联）全能的枚举（注意防止过度使用枚举）变相的枚举非此发明的NULl（当确实需要表示未知值时也不要害怕使用NULL） 总结尽量避免过度设计使用小而简单的合适数据类型尽量使用相同的数据类型存储相似或相关的值注意可变长字符串，其在临时表和排序时可能导致悲观的按最大长度分配内存尽量使用整型定义标识列避免使用Mysql已经遗弃的特性小心使用ENUM和SET范式是好的，但是反范式有时也是必需的，并且能带来好处ALTER TABLE是让人痛苦的操作，因为在大部分情况下，它都会锁表并且重建整张表","categories":[{"name":"Mysql","slug":"mysql","permalink":"https://maoyunfei.github.io/categories/mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://maoyunfei.github.io/tags/Mysql/"}]},{"title":"《高性能Mysql》第一章、Mysql架构与历史","slug":"mysql/第一章、Mysql架构与历史","date":"2018-03-29T16:00:00.000Z","updated":"2018-12-06T06:31:38.087Z","comments":true,"path":"mysql/9dd2280f/","link":"","permalink":"https://maoyunfei.github.io/mysql/9dd2280f/","excerpt":"Mysql逻辑架构","text":"Mysql逻辑架构 连接管理与安全性每个客户端连接都会在服务器进程中拥有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程只能轮流在某个CPU核心或者CPU中运行。服务器会负责缓存线程，因此不需要为每一个新建的连接创建或者销毁线程。当客户端(应用)连接到Mysql服务器时，服务器需要对其进行认证。认证基于用户名、原始主机信息和密码。一旦客户端连接成功，服务器会继续验证该客户端是否具有执行某个特定查询的权限。 优化与执行Mysql会解析查询，并创建内部数据结构(解析树)，然后对其进行各种优化，包括重写查询、决定表的查询顺序，以及选择合适的索引等。对于Select语句，在解析查询之前，服务器会先检查查询缓存，如果能够在其中找到对应的查询，服务器就不必再执行查询解析、优化和执行的整个过程，而是直接返回查询缓存中的结果集。 并发控制 读写锁读锁是共享的，或者说是相互不阻塞的。写锁是排他的，也就是说一个写锁会阻塞其他的写锁和读锁。在实际的数据库系统中，每时每刻都在发生锁定，当某个用户在修改某一部分数据时，Mysql会通过锁定防止其他用户读取同一数据。大多数时候，Mysql锁的内部管理都是透明的。 锁粒度在给定的资源上，锁定的数据量越少，则系统的并发程度越高，只要相互之间不发生冲突即可。 表锁表锁是Mysql中最基本的锁策略，并且是开销最小的策略。它会锁住整张表。 行级锁行级锁可以最大程度地支持并发处理(同时也带来了最大的锁开销)。行级锁只在存储引擎层实现，而Mysql服务器层没有实现。服务器层完全不了解存储引擎中的锁实现。 事务事务就是一组原子性的SQL查询，或者说一个独立的工作单元。事务内的语句，要么全部执行成功，要么全部执行失败。ACID表示原子性(atomicity)、一致性(consistency)、隔离性(isolation)和持久性(durability)。 隔离级别隔离级别脏读可能性不可重复读可能性幻读可能性加锁读READ UNCOMMITTEDYESYESYESNOREAD COMMITTEDNOYESYESNOREPEATABLE READNONOYESNOSERIALIZABLENONONOYES 死锁死锁是指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象。当多个事务试图以不同的顺序锁定资源时，就可能会产生死锁。多个事务同时锁定同一个资源时，也会产生死锁。为了解决这种问题，数据库系统实现了各种死锁检测和死锁超时机制。InnoDB目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。 事务日志事务日志可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久化到磁盘。事务日志采用的是追加的方式，事务日志持久化以后，内存中被修改的数据在后台可以慢慢地刷回到磁盘。目前大多数存储引擎都是这样实现的，我们通常称之为预写式日志，修改数据需要写两次磁盘。如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写会磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。 Mysql中的事务Mysql提供了两种事务型的存储引擎：InnoDB和NDB Cluster。自动提交 (AUTOCOMMIT)Mysql默认采用自动提交模式。也就是说，如果不是显式地开始一个事务，则每个查询都被当做一个事务执行提交操作。 多版本并发控制 (MVCC)MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。MVCC的实现，是通过保存数据在某个时间点的快照来实现的。也就是说，不管需要执行多长时间，每个事务看到的数据都是一致的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。MVCC只在REPEATABLE READ和READ COMMITED两个隔离级别下工作。其他两个隔离级别都和MVCC不兼容，因为READ UNCOMMITED总是读取最新的数据行，而不是符合当前事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁。 Mysql的存储引擎可以使用SHOW TABLE STATUS命令显示表的相关信息(在Mysql 5.0以后的版本中，也可以查询INFORMATION_SCHEMA中对应的表)。 InnoDB存储引擎InnoDB是Mysql的默认事务型引擎，也是最重要、使用最广泛的存储引擎。 MyISAM存储引擎MyISAM提供了大量的特性，包括全文索引、压缩、空间函数等，但MyISAM不支持事务和行级锁，而且有一个缺陷是崩溃后无法安全恢复。对于只读的数据，或者表比较小、可以忍受修复操作，则依然可以继续使用MyISAM。 选择合适的存储引擎除非需要用到某些InnoDB不具备的特性，并且没有其他办法可以替代，否则都应该优先选择InnoDB引擎。 转换表的引擎有多种方法可以将表的存储引擎转换成另外一种引擎，每种方法都有其优缺点。如果转换表的存储引擎，将会失去和原引擎相关的所有特性。ALTER TABLE下面的语句将mytable的引擎修改为InnoDB:1mysql&gt; ALTER TABLE mytable ENGINE = InnoDB;上述语法可以适用于任何存储引擎，但是需要执行很长时间。导入与导出使用mysqldump工具将数据导出到文件，然后修改文件中CREATE TABLE语句的存储引擎选项。创建和查询(CREATE和SELECT)先创建一个新的存储引擎表，然后利用INSERT...SELECT语法来导数据：123mysql&gt; CREATE TABLE innodb_table LIKE myisam_table;mysql&gt; ALTER TABLE innodb_table ENGINE=InnoDB;mysql&gt; INSERT INTO innodb_table SELECT * FROM myisam_table;","categories":[{"name":"Mysql","slug":"mysql","permalink":"https://maoyunfei.github.io/categories/mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://maoyunfei.github.io/tags/Mysql/"}]},{"title":"使用Dockerfile创建镜像","slug":"docker/使用Dockerfile创建镜像","date":"2018-03-28T16:00:00.000Z","updated":"2018-12-06T06:26:12.808Z","comments":true,"path":"docker/90b80d3a/","link":"","permalink":"https://maoyunfei.github.io/docker/90b80d3a/","excerpt":"Dockerfile是一个文本格式的配置文件，用户可以使用Dockerfile来快速创建自定义的镜像。 基础结构Dockerfile由一行行命令语句组成，并且支持以#开头的注释行。一般而言，Dockerfile分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。其中，一开始必须指明所基于的镜像名称，接下来一般是说明维护者信息。后面则是镜像操作指令，例如RUN指令，RUN指令将对镜像执行跟随指令。每运行一条RUN指令，镜像就添加一层，并提交。最后是CMD指令，用来指定运行容器时的操作命令。","text":"Dockerfile是一个文本格式的配置文件，用户可以使用Dockerfile来快速创建自定义的镜像。 基础结构Dockerfile由一行行命令语句组成，并且支持以#开头的注释行。一般而言，Dockerfile分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。其中，一开始必须指明所基于的镜像名称，接下来一般是说明维护者信息。后面则是镜像操作指令，例如RUN指令，RUN指令将对镜像执行跟随指令。每运行一条RUN指令，镜像就添加一层，并提交。最后是CMD指令，用来指定运行容器时的操作命令。 指令说明指令说明FROM指定所创建镜像的基础镜像MAINTAINER指定维护者信息RUN运行命令CMD指定容器启动时默认执行的命令LABEL指定生成镜像的元数据标签信息EXPOSE声明镜像内服务所监听的端口ENV指定环境变量ADD复制指定的路径下的内容到容器中的路径下，可以为URL；如果为tar文件，会自动解压到路径下COPY复制本地主机的路径下的内容到镜像中的路径下；一般情况下推荐使用COPY，而不是ADDENTRYPOINT指定镜像的默认入口VOLUME创建数据卷挂载点USER指定运行容器时的用户名或UIDWORKDIR配置工作目录ARG指定镜像内使用的参数ONBUILD配置当所创建的镜像作为其他镜像的基础镜像时，所执行的创建操作指令STOPSIGNAL容器退出的信号值HEALTHCHECK如何进行监控检查SHELL指定使用shell时的默认shell类型 FROM格式为FROM &lt;image&gt;或FROM &lt;image&gt;:&lt;tag&gt;或FROM &lt;image&gt;@&lt;digest&gt;。 MAINTAINER格式为MAINTAINER &lt;name&gt;。例如：1MAINTAINER image_creator@docker.com RUN格式为RUN &lt;command&gt;或RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]。注意后一个指令会被解析为Json数组，因此必须用双引号。前者默认将在shell终端中运行命令，即/bin/sh -c；后者则使用exec执行，不会启动shell环境。当命令较长时可以使用\\来换行。例如：123RUN apt-get update \\ &amp;&amp; apt-get install -y libsnappy-dev zlib1g-dev libbz2-dev \\ &amp;&amp; rm -rf /var/cache/apt CMD支持三种格式：CMD [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]使用exec执行，是推荐使用的方式CMD command param1 param2在/bin/sh中执行，提供给需要交互的应用CMD [&quot;param1&quot;, &quot;param2&quot;]提供给ENTRYPOINT的默认参数每个Dockerfile只能有一条CMD命令。如果指定了多条命令，只有最后一条会被执行。如果用户启动容器时手动指定了运行的命令(作为run的参数)，则会覆盖掉CMD指定的命令。 LABEL格式为LABEL &lt;key&gt;=value &lt;key&gt;=value &lt;key&gt;=value ...。例如：1LABEL version=\"1.0\" EXPOSE格式为EXPOSE &lt;port&gt; [&lt;port&gt;...]。例如：1EXPOSE 22 80 8443注意，该指令只是起到声明作用，并不会自动完成端口映射。 ENV格式为ENV &lt;key&gt;&lt;value&gt;或ENV &lt;key&gt;=&lt;value&gt;...。例如：12ENV PG_MAJOR 9.3ENV PG_VERSION 9.3.4 ADD格式为ADD &lt;src&gt; &lt;dest&gt;。例如：1ADD *.c /code/ COPY格式为COPY &lt;src&gt; &lt;dest&gt;。当使用本地目录为源目录时，推荐使用COPY。 ENTRYPOINT支持两种格式：ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;](exec调用执行)ENTRYPOINT command param1 param2(shell中执行)每个Dockerfile中只能有一个ENTRYPOINT，当指定多个时，只有最后一个有效。在运行时，可以被--entrypoint参数覆盖掉。 VOLUME格式为VOLUME [&quot;/data&quot;]。可以从本地主机或其他容器挂载数据卷，一般用来存放数据库和需要保存的数据等。 USER格式为USER daemon。 WORKDIR格式为WORKDIR /path/to/workdir。可以使用多个WORKDIR指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如：1234WORKDIR /aWORKDIR bWORKDIR cRUN pwd则最终路径为/a/b/c。 ARG格式为ARG &lt;name&gt;[=&lt;default value&gt;]。在执行docker build命令时才以--build-arg&lt;varname&gt;=&lt;value&gt;格式传入。 ONBUILD格式为ONBUILD [INSTRUCTION]。 STOPSIGNAL格式为STOPSIGNAL signal。 HEALTHCHECK支持两种格式：HEALTHCHECK [OPTION] CMD command(根据执行命令返回值是否为0来判断)HEALTHCHECK NONE(禁止镜像中的健康检查)OPTION支持：--interval=DURATION(默认为：30s)：过多久检查一次--timeout=DURATION(默认为：30s)：每次检查等待结果的超时--retries=N(默认为：3)：如果失败了，重试几次才最终确认失败 SHELL格式为SHELL [&quot;executable&quot;, &quot;parameters&quot;]。默认值为[&quot;/bin/bash&quot;, &quot;-c&quot;]。 创建镜像格式为docker build [选项] 内容路径。该命令将读取指定路径下的Dockerfile，并将该路径下的所有内容发送给Docker服务端，由服务端来创建镜像。因此除非生成镜像需要，否则一般建议放置Dockerfile的目录为空目录。有两点经验：如果使用非内容路径下的Dockerfile，可以使用-f选项。要指定生成镜像的标签信息，可以使用-t选项。例如：1docker build -t build_repo/first_image /tmp/docker_builder/ 使用.dockerignore文件可以通过.dockerignore文件来让Docker忽略匹配模式路径下的目录和文件。例如：12345# comment */tmep* */*/temp* tmp? ~*","categories":[{"name":"Docker","slug":"docker","permalink":"https://maoyunfei.github.io/categories/docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://maoyunfei.github.io/tags/Docker/"}]},{"title":"Docker端口映射与容器互联","slug":"docker/Docker端口映射与容器互联","date":"2018-03-25T16:00:00.000Z","updated":"2018-12-06T06:26:12.819Z","comments":true,"path":"docker/ef9116e4/","link":"","permalink":"https://maoyunfei.github.io/docker/ef9116e4/","excerpt":"除了通过网络访问外，Docker还提供了两个很方便的功能来满足服务访问的基本需求：一个是允许映射容器内应用的服务端口到本地宿主主机；另一个是互联机制实现多个容器间通过容器名来快速访问。 端口映射实现访问容器 从外部访问容器应用在启动容器时，如果不指定对应的参数，在容器外是无法通过网络访问容器内的网络应用和服务的。当容器中运行一些网络应用，要让外部访问这些应用时，可以通过-P或-p参数来指定端口映射。当使用-P(大写)标记时，Docker会随机映射一个49000~49900的端口到内部容器开放的网络端口。-p(小写)可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有IP:HostPort:ContainerPort | IP::ContainerPort | HostPort:ContainerPort。","text":"除了通过网络访问外，Docker还提供了两个很方便的功能来满足服务访问的基本需求：一个是允许映射容器内应用的服务端口到本地宿主主机；另一个是互联机制实现多个容器间通过容器名来快速访问。 端口映射实现访问容器 从外部访问容器应用在启动容器时，如果不指定对应的参数，在容器外是无法通过网络访问容器内的网络应用和服务的。当容器中运行一些网络应用，要让外部访问这些应用时，可以通过-P或-p参数来指定端口映射。当使用-P(大写)标记时，Docker会随机映射一个49000~49900的端口到内部容器开放的网络端口。-p(小写)可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有IP:HostPort:ContainerPort | IP::ContainerPort | HostPort:ContainerPort。 映射所有接口地址使用HostPort:ContainerPort默认会绑定所有接口上的所有地址，多次使用-p标记可以绑定多个端口。1docker run -d -p 5000:5000 -p 3000:80 training/webapp python app.py 映射到指定地址的指定端口可以使用IP:HostPort:ContainerPort格式指定映射使用一个特定地址。1docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py 映射到指定地址的任意端口可以使用IP::ContainerPort格式绑定指定地址任意端口到容器端口，本地主机会自动分配一个端口。1docker run -d -p 127.0.0.1::5000 training/webapp python app.py 查看映射端口配置使用docker port命令可以查看当前映射的端口配置，也可以查看到绑定的地址：1docker port nostalgic_morse 5000注意： 容器有自己的内部网络和IP地址，使用docker inspect + 容器ID可以获取容器的具体信息。 互联网机制实现便捷互访容器的互联是一种让多个容器中应用进行快速交互的方式。它会在源和接收容器之间创建连接关系，接收容器可以通过容器名快速访问到源容器，而不用指定具体的IP地址。 自定义容器命名连接系统依据容器的名称来执行，因此首先需要定义一个好记的容器名，虽然创建容器时系统会默认分配一个名字。使用--name标记可以为容器自定义命名：1docker run -d -P --name web training/webapp python app.py注意： 容器的名称是唯一的。如果已经命名了一个叫web的容器，当要再次使用web这个名称的时候，需要先用docker rm来删除之前创建的同名容器。 容器互联使用--link参数可以让容器之间安全地进行交互。--link参数的格式为--link name:alias，其中name是要连接的容器名称，alias是这个连接的别名。新建一个web容器，并将它连接到db容器：1docker run -d -P --name web --link db:db training/webapp python app.py使用docker ps可以看到db容器的names列有db，也有web/db，这表示web容器连接到db容器，这允许web容器访问db容器的信息。Docker相当于在两个互联的容器之间创建了一个虚机通道，而且不用映射它们的端口到宿主机上。 docker通过两种方式来为容器公开连接信息更新环境变量更新/etc/hosts文件使用env命令来查看web容器的环境变量：1234567$ docker run -rm --name web --link db:db training/webapp env...DB_NAME=/web2/dbDB_PORT=tcp://172.17.0.5:5432DB_PORT_5000_TCP=tcp://172.17.0.5:5432DB_PORT_5000_TCP_PROTO=tcp...其中DB_开头的环境变量是供web容器连接db容器使用的，前缀采用大写的连接别名。除了环境变量之外，Docker还添加host信息到父容器的/etc/hosts文件。下面是父容器web的hosts文件：12345$ docker run -rm --name web --link db:db training/webapp /bin/bash$ cat /etc/hosts172.17.0.7 aed84ee21bde...172.17.0.5 db这里有两个hosts信息，第一个是web容器，web容器用自己的id作为默认主机名，第二个是db容器的IP和主机名。用户可以连接多个子容器到父容器。","categories":[{"name":"Docker","slug":"docker","permalink":"https://maoyunfei.github.io/categories/docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://maoyunfei.github.io/tags/Docker/"}]},{"title":"查找给定值的k个最接近的元素","slug":"algorithms/查找给定值的k个最接近的元素","date":"2018-03-19T16:00:00.000Z","updated":"2018-12-06T06:26:12.752Z","comments":true,"path":"algorithms/bf55dfa7/","link":"","permalink":"https://maoyunfei.github.io/algorithms/bf55dfa7/","excerpt":"查找给定值的k个最接近的元素给定一个有序数组arr[]和一个值X，在arr[]中找到与X最接近的k个元素。请注意，如果元素存在于数组中，则不应该输出，只需要其他最接近的元素。算法思路：首先用二分搜索找到最接近X的交叉点（交叉点之前的元素小于或等于X，之后的元素大于或等于X）。这一步需要O(log⁡n)O\\left( \\log n\\right)O(logn)次。一旦我们找到交叉点，我们可以比较交叉点两侧的元素来打印k个最接近的元素。这一步需要O(k)O\\left( k\\right)O(k)次。","text":"查找给定值的k个最接近的元素给定一个有序数组arr[]和一个值X，在arr[]中找到与X最接近的k个元素。请注意，如果元素存在于数组中，则不应该输出，只需要其他最接近的元素。算法思路：首先用二分搜索找到最接近X的交叉点（交叉点之前的元素小于或等于X，之后的元素大于或等于X）。这一步需要O(log⁡n)O\\left( \\log n\\right)O(logn)次。一旦我们找到交叉点，我们可以比较交叉点两侧的元素来打印k个最接近的元素。这一步需要O(k)O\\left( k\\right)O(k)次。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 // Java program to find k closest elements to a given valuepublic class KClosest &#123; /* Function to find the cross over point (the point before which elements are smaller than or equal to x and after which greater than x)*/ int findCrossOver(int arr[], int low, int high, int x) &#123; // Base cases if (arr[high] &lt;= x) // x is greater than all return high; if (arr[low] &gt; x) // x is smaller than all return low; // Find the middle point int mid = (low + high) / 2; /* low + (high - low)/2 */ /* If x is same as middle element, then return mid */ if (arr[mid] &lt;= x &amp;&amp; arr[mid + 1] &gt;= x) return mid; /* If x is greater than arr[mid], then either arr[mid + 1] is ceiling of x or ceiling lies in arr[mid+1...high] */ if (arr[mid] &lt; x) return findCrossOver(arr, mid + 1, high, x); return findCrossOver(arr, low, mid - 1, x); &#125; // This function prints k closest elements to x in arr[]. // n is the number of elements in arr[] void printKclosest(int arr[], int x, int k, int n) &#123; // Find the crossover point int l = findCrossOver(arr, 0, n - 1, x); int r = l + 1; // Right index to search int count = 0; // To keep track of count of elements // already printed // If x equals to arr[l], then reduce left index while (l &gt;= 0 &amp;&amp; arr[l] == x) l--; // If x equals to arr[r], then increase right index while (r &lt; n &amp;&amp; arr[r] == x) r++; // Compare elements on left and right of crossover // point to find the k closest elements while (l &gt;= 0 &amp;&amp; r &lt; n &amp;&amp; count &lt; k) &#123; if (x - arr[l] &lt; arr[r] - x) System.out.print(arr[l--] + \" \"); else System.out.print(arr[r++] + \" \"); count++; &#125; // If there are no more elements on right side, then // print left elements while (count &lt; k &amp;&amp; l &gt;= 0) &#123; System.out.print(arr[l--] + \" \"); count++; &#125; // If there are no more elements on left side, then // print right elements while (count &lt; k &amp;&amp; r &lt; n) &#123; System.out.print(arr[r++] + \" \"); count++; &#125; &#125; /* Driver program to check above functions */ public static void main(String args[]) &#123; KClosest ob = new KClosest(); int arr[] = &#123;1, 2, 2, 2, 5, 6&#125;; int n = arr.length; int x = 2, k = 2; ob.printKclosest(arr, x, k, n); &#125;&#125;时间复杂度：O(log⁡n+k)O\\left( \\log n+k\\right)O(logn+k)","categories":[{"name":"Algorithms","slug":"algorithms","permalink":"https://maoyunfei.github.io/categories/algorithms/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://maoyunfei.github.io/tags/算法/"}]},{"title":"排序算法","slug":"algorithms/排序算法","date":"2018-03-18T16:00:00.000Z","updated":"2018-12-06T06:26:12.757Z","comments":true,"path":"algorithms/735e5788/","link":"","permalink":"https://maoyunfei.github.io/algorithms/735e5788/","excerpt":"选择排序（Selection Sort）选择排序算法通过重复查找未排序部分的最小元素（考虑升序）并将其放在开头来排序数组。算法在给定数组中维护两个子数组。已经排序好的子数组剩下未排序的子数组在选择排序的每一次迭代中，挑选未排序子数组中的最小元素（考虑升序），并将其移至排序后的子数组中。","text":"选择排序（Selection Sort）选择排序算法通过重复查找未排序部分的最小元素（考虑升序）并将其放在开头来排序数组。算法在给定数组中维护两个子数组。已经排序好的子数组剩下未排序的子数组在选择排序的每一次迭代中，挑选未排序子数组中的最小元素（考虑升序），并将其移至排序后的子数组中。123456789101112131415161718192021222324252627282930313233343536373839404142// Java program for implementation of Selection Sortclass SelectionSort&#123; void sort(int arr[]) &#123; int n = arr.length; // One by one move boundary of unsorted subarray for (int i = 0; i &lt; n-1; i++) &#123; // Find the minimum element in unsorted array int min_idx = i; for (int j = i+1; j &lt; n; j++) if (arr[j] &lt; arr[min_idx]) min_idx = j; // Swap the found minimum element with the first element int temp = arr[min_idx]; arr[min_idx] = arr[i]; arr[i] = temp; &#125; &#125; // Prints the array void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i]+\" \"); System.out.println(); &#125; // Driver code to test above public static void main(String args[]) &#123; SelectionSort ob = new SelectionSort(); int arr[] = &#123;64,25,12,22,11&#125;; ob.sort(arr); System.out.println(\"Sorted array\"); ob.printArray(arr); &#125;&#125;时间复杂度：O(n2)O\\left( n^{2}\\right)O(n2) 冒泡排序（Bubble Sort）冒泡排序通过反复交换相邻元素（如果顺序错误）来工作。123456789101112131415161718192021222324252627282930313233343536// Java program for implementation of Bubble Sortclass BubbleSort&#123; void bubbleSort(int arr[]) &#123; int n = arr.length; for (int i = 0; i &lt; n-1; i++) for (int j = 0; j &lt; n-i-1; j++) if (arr[j] &gt; arr[j+1]) &#123; // swap temp and arr[i] int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; &#125; &#125; /* Prints the array */ void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i] + \" \"); System.out.println(); &#125; // Driver method to test above public static void main(String args[]) &#123; BubbleSort ob = new BubbleSort(); int arr[] = &#123;64, 34, 25, 12, 22, 11, 90&#125;; ob.bubbleSort(arr); System.out.println(\"Sorted array\"); ob.printArray(arr); &#125;&#125;优化实现： 即使数组已经有序，上述函数也会运行O(n2)O\\left( n^{2}\\right)O(n2)时间。如果内部循环没有引起任何交换，可以通过停止算法来优化它。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// Optimized java implementation of Bubble sort class GFG &#123; // An optimized version of Bubble Sort static void bubbleSort(int arr[], int n) &#123; int i, j, temp; boolean swapped; for (i = 0; i &lt; n - 1; i++) &#123; swapped = false; for (j = 0; j &lt; n - i - 1; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; // swap arr[j] and arr[j+1] temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; swapped = true; &#125; &#125; // IF no two elements were // swapped by inner loop, then break if (swapped == false) break; &#125; &#125; // Function to print an array static void printArray(int arr[], int size) &#123; int i; for (i = 0; i &lt; size; i++) System.out.print(arr[i] + \" \"); System.out.println(); &#125; // Driver program public static void main(String args[]) &#123; int arr[] = &#123; 64, 34, 25, 12, 22, 11, 90 &#125;; int n = arr.length; bubbleSort(arr, n); System.out.println(\"Sorted array: \"); printArray(arr, n); &#125;&#125;时间复杂度：O(n2)O\\left( n^{2}\\right)O(n2) 插入排序（Insertion Sort）1234// Sort an arr[] of size ninsertionSort(arr, n)Loop from i = 1 to n-1.……a) Pick element arr[i] and insert it into sorted sequence arr[0…i-1]123456789101112131415161718192021222324252627282930313233343536373839404142434445// Java program for implementation of Insertion Sortclass InsertionSort&#123; /*Function to sort array using insertion sort*/ void sort(int arr[]) &#123; int n = arr.length; for (int i=1; i&lt;n; ++i) &#123; int key = arr[i]; int j = i-1; /* Move elements of arr[0..i-1], that are greater than key, to one position ahead of their current position */ while (j&gt;=0 &amp;&amp; arr[j] &gt; key) &#123; arr[j+1] = arr[j]; j = j-1; &#125; arr[j+1] = key; &#125; &#125; /* A utility function to print array of size n*/ static void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i] + \" \"); System.out.println(); &#125; // Driver method public static void main(String args[]) &#123; int arr[] = &#123;12, 11, 13, 5, 6&#125;; InsertionSort ob = new InsertionSort(); ob.sort(arr); printArray(arr); &#125;&#125;时间复杂度：O(n2)O\\left( n^{2}\\right)O(n2) 链表的插入排序12341) Create an empty sorted (or result) list2) Traverse the given list, do following for every node.......a) Insert current node in sorted way in sorted or result list.3) Change head of given linked list to head of sorted (or result) list. 归并排序（Merge Sort）——分治思想12345678910MergeSort(arr[], l, r)If r &gt; l 1. Find the middle point to divide the array into two halves: middle m = (l+r)/2 2. Call mergeSort for first half: Call mergeSort(arr, l, m) 3. Call mergeSort for second half: Call mergeSort(arr, m+1, r) 4. Merge the two halves sorted in step 2 and 3: Call merge(arr, l, m, r)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/* Java program for Merge Sort */class MergeSort&#123; // Merges two subarrays of arr[]. // First subarray is arr[l..m] // Second subarray is arr[m+1..r] void merge(int arr[], int l, int m, int r) &#123; int[] tmp = new int[r - l + 1]; int i = l, j = m, k = 0; while (i &lt; m &amp;&amp; j &lt;= r) &#123; if (arr[i] &lt;= arr[j]) &#123; tmp[k] = arr[i]; k++; i++; &#125; else &#123; tmp[k] = arr[j]; j++; k++; &#125; &#125; while (i &lt; m) &#123; tmp[k] = arr[i]; i++; k++; &#125; while (j &lt;= r) &#123; tmp[k] = arr[j]; j++; k++; &#125; &#125; // Main function that sorts arr[l..r] using // merge() void sort(int arr[], int l, int r) &#123; if (l &lt; r) &#123; // Find the middle point int m = (l+r)/2; // Sort first and second halves sort(arr, l, m); sort(arr , m+1, r); // Merge the sorted halves merge(arr, l, m, r); &#125; &#125; /* A utility function to print array of size n */ static void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i] + \" \"); System.out.println(); &#125; // Driver method public static void main(String args[]) &#123; int arr[] = &#123;12, 11, 13, 5, 6, 7&#125;; System.out.println(\"Given Array\"); printArray(arr); MergeSort ob = new MergeSort(); ob.sort(arr, 0, arr.length-1); System.out.println(\"\\nSorted array\"); printArray(arr); &#125;&#125;时间复杂度：O(nlog⁡n)O\\left( n\\log n\\right)O(nlogn) 链表的归并排序12345678910MergeSort(headRef)1) If head is NULL or there is only one element in the Linked List then return.2) Else divide the linked list into two halves. FrontBackSplit(head, &amp;a, &amp;b); /* a and b are two halves */3) Sort the two halves a and b. MergeSort(a); MergeSort(b);4) Merge the sorted a and b and update the head pointer using headRef. *headRef = SortedMerge(a, b);一下代码巧妙的使用两个指针移动来寻找中间节点，第一个指针每次移动一格，第二个指针每次移动两格，当第二个指针到达末尾时，第一个指针恰好到达中点。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136// Java program to illustrate merge sorted// of linkedList public class linkedList &#123; node head = null; // node a,b; static class node &#123; int val; node next; public node(int val) &#123; this.val = val; &#125; &#125; node sortedMerge(node a, node b) &#123; node result = null; /* Base cases */ if (a == null) return b; if (b == null) return a; /* Pick either a or b, and recur */ if (a.val &lt;= b.val) &#123; result = a; result.next = sortedMerge(a.next, b); &#125; else &#123; result = b; result.next = sortedMerge(a, b.next); &#125; return result; &#125; node mergeSort(node h) &#123; // Base case : if head is null if (h == null || h.next == null) &#123; return h; &#125; // get the middle of the list node middle = getMiddle(h); node nextofmiddle = middle.next; // set the next of middle node to null middle.next = null; // Apply mergeSort on left list node left = mergeSort(h); // Apply mergeSort on right list node right = mergeSort(nextofmiddle); // Merge the left and right lists node sortedlist = sortedMerge(left, right); return sortedlist; &#125; // Utility function to get the middle of the linked list node getMiddle(node h) &#123; //Base case if (h == null) return h; node fastptr = h.next; node slowptr = h; // Move fastptr by two and slow ptr by one // Finally slowptr will point to middle node while (fastptr != null) &#123; fastptr = fastptr.next; if(fastptr!=null) &#123; slowptr = slowptr.next; fastptr=fastptr.next; &#125; &#125; return slowptr; &#125; void push(int new_data) &#123; /* allocate node */ node new_node = new node(new_data); /* link the old list off the new node */ new_node.next = head; /* move the head to point to the new node */ head = new_node; &#125; // Utility function to print the linked list void printList(node headref) &#123; while (headref != null) &#123; System.out.print(headref.val + \" \"); headref = headref.next; &#125; &#125; public static void main(String[] args) &#123; linkedList li = new linkedList(); /* * Let us create a unsorted linked lists to test the functions Created * lists shall be a: 2-&gt;3-&gt;20-&gt;5-&gt;10-&gt;15 */ li.push(15); li.push(10); li.push(5); li.push(20); li.push(3); li.push(2); System.out.println(\"Linked List without sorting is :\"); li.printList(li.head); // Apply merge Sort li.head = li.mergeSort(li.head); System.out.print(\"\\n Sorted Linked List is: \\n\"); li.printList(li.head); &#125;&#125; 堆排序（Heap Sort）堆排序是基于Binary Heap数据结构的基于比较的排序算法。它类似于我们首先找到最大元素然后和最后位置交换的选择排序。我们对剩下的元素重复相同的过程。 什么是Binary HeapBinary Heap是一个完整二叉树，其中项以特殊顺序存储，使得父节点中的值比其两个子节点中的值更大（或更小）。前者称为最大堆，后者称为最小堆。堆可以用二叉树或数组表示。用数组表示Binary Heap，如果父节点存储在索引i处，则左边的孩子索引为2 * i + 1，右边的孩子索引为2 * i + 2（假设索引从0开始）。按升序排序的堆排序算法：根据输入数据构建一个最大堆。此时，最大的元素存储在堆的根。将它和堆的最后一项交换，然后将堆的大小减1。最后，heapify树的根。在堆大小大于1的情况下重复上述步骤。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// Java program for implementation of Heap Sortpublic class HeapSort&#123; public void sort(int arr[]) &#123; int n = arr.length; // Build heap (rearrange array) for (int i = n / 2 - 1; i &gt;= 0; i--) heapify(arr, n, i); // One by one extract an element from heap for (int i=n-1; i&gt;=0; i--) &#123; // Move current root to end int temp = arr[0]; arr[0] = arr[i]; arr[i] = temp; // call max heapify on the reduced heap heapify(arr, i, 0); &#125; &#125; // To heapify a subtree rooted with node i which is // an index in arr[]. n is size of heap void heapify(int arr[], int n, int i) &#123; int largest = i; // Initialize largest as root int l = 2*i + 1; // left = 2*i + 1 int r = 2*i + 2; // right = 2*i + 2 // If left child is larger than root if (l &lt; n &amp;&amp; arr[l] &gt; arr[largest]) largest = l; // If right child is larger than largest so far if (r &lt; n &amp;&amp; arr[r] &gt; arr[largest]) largest = r; // If largest is not root if (largest != i) &#123; int swap = arr[i]; arr[i] = arr[largest]; arr[largest] = swap; // Recursively heapify the affected sub-tree heapify(arr, n, largest); &#125; &#125; /* A utility function to print array of size n */ static void printArray(int arr[]) &#123; int n = arr.length; for (int i=0; i&lt;n; ++i) System.out.print(arr[i]+\" \"); System.out.println(); &#125; // Driver program public static void main(String args[]) &#123; int arr[] = &#123;12, 11, 13, 5, 6, 7&#125;; int n = arr.length; HeapSort ob = new HeapSort(); ob.sort(arr); System.out.println(\"Sorted array is\"); printArray(arr); &#125;&#125;时间复杂度：O(nlog⁡n)O\\left( n\\log n\\right)O(nlogn) 堆排序的应用对几乎排好序的（或K个排好序的）数组进行排序。求数组中的k个最大（或最小）元素。 快速排序（QuickSort）——分治思想快排选择一个元素作为枢轴（pivot），并将给定的数组根据选取的枢轴分区。有许多选择枢轴不同的方式。始终选择第一个元素作为枢轴。总是选择最后一个元素作为枢轴。选择一个随机元素作为枢轴。选择中位数为枢轴。1234567891011121314151617181920212223public static void quickSort(int[] arr)&#123; qsort(arr, 0, arr.length-1);&#125;private static void qsort(int[] arr, int low, int high)&#123; if (low &lt; high)&#123; int pivot=partition(arr, low, high); //将数组分为两部分 qsort(arr, low, pivot-1); //递归排序左子数组 qsort(arr, pivot+1, high); //递归排序右子数组 &#125;&#125;private static int partition(int[] arr, int low, int high)&#123; int pivot = arr[low]; //枢轴记录 while (low&lt;high)&#123; while (low&lt;high &amp;&amp; arr[high]&gt;=pivot) --high; arr[low]=arr[high]; //交换比枢轴小的记录到左端 while (low&lt;high &amp;&amp; arr[low]&lt;=pivot) ++low; arr[high] = arr[low]; //交换比枢轴小的记录到右端 &#125; //扫描完成，枢轴到位 arr[low] = pivot; //返回的是枢轴的位置 return low;&#125;时间复杂度：O(nlog⁡n)O\\left( n\\log n\\right)O(nlogn)当最左元素或者最右元素被选为枢轴时，最坏情况发生在以下情形：数组已经是相同的顺序。数组已经是相反的顺序。所有元素都相等。所以尽量选择随机元素或者中间的元素或者中位数作为枢轴来避免最坏情况。 Shell Sort（希尔排序）希尔排序基本思想为在直接插入排序的思想下设置一个最小增量dk,刚开始dk设置为n/2。进行插入排序，随后再让dk=dk/2,再进行插入排序，直到dk为1时完成最后一次插入排序，此时数组完成排序。1234567891011121314151617181920212223242526272829public static void shell_sort(int array[],int lenth)&#123; int temp = 0; int incre = lenth; while(true)&#123; incre = incre/2; for(int k = 0;k&lt;incre;k++)&#123; //根据增量分为若干子序列 for(int i=k+incre;i&lt;lenth;i+=incre)&#123; for(int j=i;j&gt;k;j-=incre)&#123; if(array[j]&lt;array[j-incre])&#123; temp = array[j-incre]; array[j-incre] = array[j]; array[j] = temp; &#125;else&#123; break; &#125; &#125; &#125; &#125; if(incre == 1)&#123; break; &#125; &#125;&#125;最坏时间复杂度为O(n2)O\\left( n^{2}\\right)O(n2)；最优时间复杂度为O(n)O\\left( n\\right)O(n)；平均时间复杂度为O(n1.3)O\\left( n^{1.3}\\right)O(n1.3)。辅助空间O(1)O\\left(1\\right)O(1)。稳定性：不稳定。希尔排序的时间复杂度与选取的增量有关，选取合适的增量可减少时间复杂度。","categories":[{"name":"Algorithms","slug":"algorithms","permalink":"https://maoyunfei.github.io/categories/algorithms/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://maoyunfei.github.io/tags/算法/"}]},{"title":"Reactive Programming","slug":"spring/Reactive Programming","date":"2018-03-15T02:00:00.000Z","updated":"2018-12-06T06:31:37.912Z","comments":true,"path":"spring/e777c82f/","link":"","permalink":"https://maoyunfei.github.io/spring/e777c82f/","excerpt":"前段时间，Spring 5的发布给我们带来了WebFlux模块，其主要核心是Reactive Programming。在介绍WebFlux之前，我们需要一些背景知识。 Reactive StreamsReactive Streams的目的是为非阻塞的异步流处理提供一个标准。","text":"前段时间，Spring 5的发布给我们带来了WebFlux模块，其主要核心是Reactive Programming。在介绍WebFlux之前，我们需要一些背景知识。 Reactive StreamsReactive Streams的目的是为非阻塞的异步流处理提供一个标准。一些相关资料：Reactive宣言Reactive Streams的JVM规范 Reactive Streams定义的JVM规范如下：处理可能无限数量的元素按顺序处理在组件之间异步传递元素具有强制性的非阻塞的backpressure Reactive Streams规范由以下两部分组成：API: 定义要实现的类型，并实现不同类型之间的交互操作。Technology Compatibility Kit (TCK): 用于实现一致性测试的标准测试套件。只要符合API要求并通过TCK中的测试，实现就可以自由地实现规范未涵盖的其他功能。 API组件Publisher: 发布者将数据发送给一个或多个订阅者。123public interface Publisher&lt;T&gt; &#123; public void subscribe(Subscriber&lt;? super T&gt; s);&#125;Subscriber: 订阅者将自己订阅发布者，指出发布者可以发送多少数据并处理数据。123456public interface Subscriber&lt;T&gt; &#123; public void onSubscribe(Subscription s); public void onNext(T t); public void onError(Throwable t); public void onComplete();&#125;Subscription: 在发布者方面，订阅将被创建，其将与订阅者共享。1234public interface Subscription &#123; public void request(long n); public void cancel();&#125;Processor: 处理器可以用于位于发布者和订阅者之间，这样就可以进行数据转换。12public interface Processor&lt;T, R&gt; extends Subscriber&lt;T&gt;, Publisher&lt;R&gt; &#123;&#125;Reactive Streams规范被包含在Java 9的Flow API中。 RxJava项目RxJava使用观察者模式，构建了一种异步且基于事件的实现，并且提供了处理数据流的丰富操作，是Reactive Streams的主流实现之一。RxJava 2提供了几个基本类：io.reactivex.Flowable: 返回N个元素，支持Reactive Streams和backpressure。io.reactivex.Observable: 返回N个元素，不支持backpressure。io.reactivex.Single: 返回1个元素或者error。io.reactivex.Completable: 没有元素，只有完成和error信号。io.reactivex.Maybe: 返回0个元素，1个元素或者error。 Reactor项目Reactor是基于Reactive Streams规范提供的一个Reactive库，是Reactive Streams的另一主流实现。Reactor提供两种类型：Mono: 实现了Publisher，返回0或1个元素。Flux: 实现了Publisher，返回N个元素。API练习项目：Reactive Programming with Reactor 3Reactor API Hands-on Spring WebFluxSpring WebFlux是完全非阻塞的，支持Reactive Streams的back pressure，可以运行在例如Netty、Undertow和Servlet 3.1+容器上。Spring Framework内部采用Reactor来支持响应式编程。在应用层，用户也可以选择使用Spring提供的对RxJava的全面支持。更多WebFlux的用法请查看官方文档。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Reactive","slug":"Reactive","permalink":"https://maoyunfei.github.io/tags/Reactive/"},{"name":"WebFlux","slug":"WebFlux","permalink":"https://maoyunfei.github.io/tags/WebFlux/"}]},{"title":"字符、字节与编码","slug":"other/字符、字节与编码","date":"2018-03-14T16:00:00.000Z","updated":"2018-12-06T06:31:37.971Z","comments":true,"path":"other/6d07e1bc/","link":"","permalink":"https://maoyunfei.github.io/other/6d07e1bc/","excerpt":"字符与编码的发展 从计算机对多国语言的支持角度看，大致可以分为三个阶段：系统内码说明系统阶段一ASCII计算机刚开始只支持英语，其它语言不能够在计算机上存储和显示。英文 DOS阶段二ANSI编码(本地化)为使计算机支持更多语言，通常使用 0x80~0xFF 范围的 2 个字节来表示 1 个字符。比如：汉字 ‘中’ 在中文操作系统中，使用 [0xD6,0xD0] 这两个字节存储。不同的国家和地区制定了不同的标准，由此产生了 GB2312, BIG5, JIS 等各自的编码标准。这些使用 2 个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码。在简体中文系统下，ANSI 编码代表 GB2312 编码，在日文操作系统下，ANSI 编码代表 JIS 编码。不同 ANSI 编码之间互不兼容，当信息在国际间交流时，无法将属于两种语言的文字，存储在同一段 ANSI 编码的文本中。中文 DOS，中文 Windows 95/98，日文 Windows 95/98阶段三UNICODE(国际化)为了使国际间信息交流更加方便，国际组织制定了 UNICODE 字符集，为各种语言中的每一个字符设定了统一并且唯一的数字编号，以满足跨语言、跨平台进行文本转换、处理的要求。Windows NT/2000/XP，Linux，Java","text":"字符与编码的发展 从计算机对多国语言的支持角度看，大致可以分为三个阶段：系统内码说明系统阶段一ASCII计算机刚开始只支持英语，其它语言不能够在计算机上存储和显示。英文 DOS阶段二ANSI编码(本地化)为使计算机支持更多语言，通常使用 0x80~0xFF 范围的 2 个字节来表示 1 个字符。比如：汉字 ‘中’ 在中文操作系统中，使用 [0xD6,0xD0] 这两个字节存储。不同的国家和地区制定了不同的标准，由此产生了 GB2312, BIG5, JIS 等各自的编码标准。这些使用 2 个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码。在简体中文系统下，ANSI 编码代表 GB2312 编码，在日文操作系统下，ANSI 编码代表 JIS 编码。不同 ANSI 编码之间互不兼容，当信息在国际间交流时，无法将属于两种语言的文字，存储在同一段 ANSI 编码的文本中。中文 DOS，中文 Windows 95/98，日文 Windows 95/98阶段三UNICODE(国际化)为了使国际间信息交流更加方便，国际组织制定了 UNICODE 字符集，为各种语言中的每一个字符设定了统一并且唯一的数字编号，以满足跨语言、跨平台进行文本转换、处理的要求。Windows NT/2000/XP，Linux，Java 字符串在内存中的存放方法：在 ASCII 阶段，单字节字符串使用一个字节存放一个字符（SBCS）。比如，“Bob123” 在内存中为：在使用 ANSI 编码支持多种语言阶段，每个字符使用一个字节或多个字节来表示（MBCS），因此，这种方式存放的字符也被称作多字节字符。比如，“中文123” 在中文 Windows 95 内存中为7个字节，每个汉字占2个字节，每个英文和数字字符占1个字节：在 UNICODE 被采用之后，计算机存放字符串时，改为存放每个字符在 UNICODE 字符集中的序号。目前计算机一般使用 2 个字节（16 位）来存放一个序号（DBCS），因此，这种方式存放的字符也被称作宽字节字符。比如，字符串 “中文123” 在 Windows 2000 下，内存中实际存放的是 5 个序号：一共占 10 个字节。 字符，字节，字符串理解编码的关键，是要把字符的概念和字节的概念理解准确。这两个概念容易混淆，我们在此做一下区分：概念描述举例字符人们使用的记号，抽象意义上的一个符号。‘1’, ‘中’, ‘a’, ‘$’, ‘￥’, ……字节计算机中存储数据的单元，一个8位的二进制数，是一个很具体的存储空间。0x01, 0x45, 0xFA, ……ANSI字符串在内存中，如果“字符”是以 ANSI 编码形式存在的，一个字符可能使用一个字节或多个字节来表示，那么我们称这种字符串为 ANSI 字符串或者多字节字符串。“中文123”（占7字节）UNICODE字符串在内存中，如果“字符”是以在 UNICODE 中的序号存在的，那么我们称这种字符串为 UNICODE 字符串或者宽字节字符串。L&quot;中文123&quot;（占10字节）由于不同 ANSI 编码所规定的标准是不相同的，因此，对于一个给定的多字节字符串，我们必须知道它采用的是哪一种编码规则，才能够知道它包含了哪些“字符”。而对于 UNICODE 字符串来说，不管在什么环境下，它所代表的“字符”内容总是不变的。 字符集与编码各个国家和地区所制定的不同 ANSI 编码标准中，都只规定了各自语言所需的“字符”。比如：汉字标准（GB2312）中没有规定韩国语字符怎样存储。这些 ANSI 编码标准所规定的内容包含两层含义：使用哪些字符。也就是说哪些汉字，字母和符号会被收入标准中。所包含“字符”的集合就叫做“字符集”。规定每个“字符”分别用一个字节还是多个字节存储，用哪些字节来存储，这个规定就叫做“编码”。各个国家和地区在制定编码标准的时候，“字符的集合”和“编码”一般都是同时制定的。因此，平常我们所说的“字符集”，比如：GB2312, GBK, JIS 等，除了有“字符的集合”这层含义外，同时也包含了“编码”的含义。“UNICODE 字符集” 包含了各种语言中使用到的所有“字符”。用来给 UNICODE 字符集编码的标准有很多种，比如：UTF-8, UTF-7, UTF-16, UnicodeLittle, UnicodeBig 等。 常用的编码简介在这里，我们根据编码规则的特点，把所有的编码分成三类：分类编码标准说明单字节字符编码ISO-8859-1最简单的编码规则，每一个字节直接作为一个 UNICODE 字符。比如，[0xD6, 0xD0] 这两个字节，通过 iso-8859-1 转化为字符串时，将直接得到 [0x00D6, 0x00D0] 两个 UNICODE 字符，即 “ÖÐ”。反之，将 UNICODE 字符串通过 iso-8859-1 转化为字节串时，只能正常转化 0~255 范围的字符。ANSI编码GB2312,BIG5,Shift_JIS,ISO-8859-2……把 UNICODE 字符串通过 ANSI 编码转化为“字节串”时，根据各自编码的规定，一个 UNICODE 字符可能转化成一个字节或多个字节。反之，将字节串转化成字符串时，也可能多个字节转化成一个字符。比如，[0xD6, 0xD0] 这两个字节，通过 GB2312 转化为字符串时，将得到 [0x4E2D] 一个字符，即 ‘中’ 字。“ANSI 编码”的特点：1. 这些“ANSI 编码标准”都只能处理各自语言范围之内的 UNICODE 字符。2. “UNICODE 字符”与“转换出来的字节”之间的关系是人为规定的。UNICODE 编码UTF-8,UTF-16,UnicodeBig……与“ANSI 编码”类似的，把字符串通过 UNICODE 编码转化成“字节串”时，一个 UNICODE 字符可能转化成一个字节或多个字节。与“ANSI 编码”不同的是：1. 这些“UNICODE 编码”能够处理所有的 UNICODE 字符。2. “UNICODE 字符”与“转换出来的字节”之间是可以通过计算得到的。我们实际上没有必要去深究每一种编码具体把某一个字符编码成了哪几个字节，我们只需要知道**“编码”的概念就是把“字符”转化成“字节”** 就可以了。对于“UNICODE 编码”，由于它们是可以通过计算得到的，因此，在特殊的场合，我们可以去了解某一种“UNICODE 编码”是怎样的规则。 Java中的字符与字节类型或操作Java字符char字节byteANSI字符串byte[]UNICODE字符串String字节串→字符串string = new String(bytes,&quot;encoding&quot;)字节串→字节串bytes = string.getBytes(&quot;encoding&quot;)以上需要注意: Java 中的 char 代表一个 “UNICODE 字符（宽字节字符）”","categories":[{"name":"其他","slug":"other","permalink":"https://maoyunfei.github.io/categories/other/"}],"tags":[{"name":"编码","slug":"编码","permalink":"https://maoyunfei.github.io/tags/编码/"}]},{"title":"Docker数据管理","slug":"docker/Docker数据管理","date":"2018-03-12T16:00:00.000Z","updated":"2018-12-06T06:26:12.823Z","comments":true,"path":"docker/c2e250ea/","link":"","permalink":"https://maoyunfei.github.io/docker/c2e250ea/","excerpt":"容器中管理数据主要有两种：数据卷：容器内数据直接映射到本地主机环境；数据卷容器：使用特定容器维护数据卷。 数据卷数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于Linux中的mount操作。数据卷可以提供很多有用的特性，如下所示：","text":"容器中管理数据主要有两种：数据卷：容器内数据直接映射到本地主机环境；数据卷容器：使用特定容器维护数据卷。 数据卷数据卷是一个可供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于Linux中的mount操作。数据卷可以提供很多有用的特性，如下所示：数据卷可以在容器之间共享和重用，容器间传递数据将变得高效方便；对数据卷内数据的修改会立马生效，无论容器内操作还是本地操作；对数据卷的更新不会影响镜像，解耦了应用和数据；卷会一直存在，直到没有容器使用，可以安全地卸载它。 在容器内创建一个数据卷在用docker run命令时，可以使用-v来创建一个数据卷。从此重复使用-v可以创建多个数据卷。使用training/webapp创建一个web容器，并创建一个数据卷挂载到容器的/webapp目录。1docker run -d -P --name web -v /webapp training/webapp python app.py 挂载一个主机目录作为数据卷(推荐)使用-v标记也可以指定挂载本地的已有目录到容器中去作为数据卷。1docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py本地目录的路径必须是绝对路径，如果目录不存在，docker会自动创建。docker挂载数据卷的默认权限是读写(rw)，用户也可以通过ro指定为只读：1docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py 数据卷容器如果用户需要在多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载。创建一个数据卷容器，并在其中创建一个数据卷挂载到/dbdata:1docker run -it -v /dbdata --name dbdata ubuntu查看/dbdata目录：12$ lsbin boot dbdata dev src tec ...创建db1和db2两个容器，并从dbdata容器挂载数据卷：12docker run -it --volumes-from dbdata --name db1 ubuntudocker run -it --volumes-from dbdata --name db2 ubuntu此时，容器db1和db2都挂载同一个数据卷到相同的/dbdata目录。三个容器任何一方在该目录下的写入，其他容器都可以看见。可以多次使用--volomus-from参数来从多个容器加载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。1docker run -d --name db3 --volumes-from db1 training/postgres注意： 使用--volumes-from参数所挂载的数据卷的容器自身并不需要保持在运行状态。如果删除了挂载的容器，数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时显式使用docker rm -v命令来指定同时删除关联的数据卷。","categories":[{"name":"Docker","slug":"docker","permalink":"https://maoyunfei.github.io/categories/docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://maoyunfei.github.io/tags/Docker/"}]},{"title":"搜索算法","slug":"algorithms/搜索算法","date":"2018-03-11T16:00:00.000Z","updated":"2018-12-06T06:26:12.730Z","comments":true,"path":"algorithms/401ea1e/","link":"","permalink":"https://maoyunfei.github.io/algorithms/401ea1e/","excerpt":"Linear Search(线性搜索)问题： 给定一个有n个元素的数组，写一个函数在数组中搜索给定元素。","text":"Linear Search(线性搜索)问题： 给定一个有n个元素的数组，写一个函数在数组中搜索给定元素。Java实现1234567891011121314151617class LinearSearch&#123; // This function returns index of element x in arr[] static int search(int arr[], int n, int x) &#123; for (int i = 0; i &lt; n; i++) &#123; // Return the index of the element if the element // is found if (arr[i] == x) return i; &#125; // return -1 if the element is not found return -1; &#125;&#125;时间复杂度：O(n)O\\left( n\\right)O(n) Binary Search(二分查找)问题： 给定一个有n个元素的有序数组，写一个函数在数组中搜索给定元素。Java实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Java implementation of recursive Binary Searchclass BinarySearch&#123; // Returns index of x if it is present in arr[l.. // r], else return -1 int binarySearch(int arr[], int l, int r, int x) &#123; if (r&gt;=l) &#123; int mid = l + (r - l)/2; // If the element is present at the // middle itself if (arr[mid] == x) return mid; // If element is smaller than mid, then // it can only be present in left subarray if (arr[mid] &gt; x) return binarySearch(arr, l, mid-1, x); // Else the element can only be present // in right subarray return binarySearch(arr, mid+1, r, x); &#125; // We reach here when element is not present // in array return -1; &#125; // Driver method to test above public static void main(String args[]) &#123; BinarySearch ob = new BinarySearch(); int arr[] = &#123;2,3,4,10,40&#125;; int n = arr.length; int x = 10; int result = ob.binarySearch(arr,0,n-1,x); if (result == -1) System.out.println(\"Element not present\"); else System.out.println(\"Element found at index \" + result); &#125;&#125;时间复杂度：O(log⁡n)O\\left( \\log n\\right)O(logn)适用场景：有序 Jump Search(跳跃搜索)Jump Search是用于有序数组的搜索算法。基本思想是通过以固定步长向前跳跃或跳过一些元素来代替搜索所有元素来检查更少的元素(而不是线性搜索)。例如，假设我们有一个大小为n的数组arr[]和大小为m的块（将被跳转）。然后我们搜索索引arr [0]，arr[m]，arr[2m] … …arr[km]等等。一旦我们找到了间隔(arr[km] &lt; x &lt;arr [(k + 1)m])，我们就从索引km开始执行线性搜索操作来查找元素x。什么是最佳跳跃步长?在最坏的情况下，我们必须进行n/m跳转，并且如果最后一次选中的值大于要搜索的元素，我们将对线性搜索进行m-1比较。因此，最坏情况下的比较总数将是((n/m)+ m-1)。当m =√n时，函数的值((n/m)+m-1)最小。因此，最好的步长是m=√n。Java实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// Java program to implement Jump Search.public class JumpSearch&#123; public static int jumpSearch(int[] arr, int x) &#123; int n = arr.length; // Finding block size to be jumped int step = (int)Math.floor(Math.sqrt(n)); // Finding the block where element is // present (if it is present) int prev = 0; while (arr[Math.min(step, n)-1] &lt; x) &#123; prev = step; step += (int)Math.floor(Math.sqrt(n)); if (prev &gt;= n) return -1; &#125; // Doing a linear search for x in block // beginning with prev. while (arr[prev] &lt; x) &#123; prev++; // If we reached next block or end of // array, element is not present. if (prev == Math.min(step, n)) return -1; &#125; // If element is found if (arr[prev] == x) return prev; return -1; &#125; // Driver program to test function public static void main(String [ ] args) &#123; int arr[] = &#123; 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610&#125;; int x = 55; // Find the index of 'x' using Jump Search int index = jumpSearch(arr, x); // Print the index where 'x' is located System.out.println(\"\\nNumber \" + x + \" is at index \" + index); &#125;&#125;时间复杂度：O(n)O\\left( \\sqrt {n}\\right)O(n​)适用场景：有序Binary Search优于Jump Search，但Jump Search有一个优势，即我们只返回一次(Binary Search可能需要高达O(Log n)个跳转)。因此，在跳回成本高昂的系统中，我们使用Jump Search。 Interpolation Search(插值搜索)给定一个有n个均匀分布值值的有序数组，编写一个函数来搜索数组中的特定元素。插值搜索是对二分搜索的改进，其中排序数组中的值均匀分布。二分查找总是对中间元素进行检查。插值搜索可能会根据正在搜索的值进入不同的位置。例如，如果搜索的值更接近最后一个元素，则插值搜索可能会从结尾开始搜索。要找到要搜索的位置，它使用以下公式。12345678公式的想法当要搜索的元素更接近arr[hi]，则返回较大的pos值，如果要搜索的元素更接近[lo]，则返回较小的pos值。pos = lo + [(x-arr[lo])*(hi-lo)/(arr[hi]-arr[Lo])]arr[] ==&gt; Array where elements need to be searchedx ==&gt; Element to be searchedlo ==&gt; Starting index in arr[]hi ==&gt; Ending index in arr[]Java实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// Java program to implement interpolation searchclass InterpolationSearch&#123; // Array of items on which search will // be conducted. static int arr[] = new int[]&#123;10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 33, 35, 42, 47&#125;; // If x is present in arr[0..n-1], then returns // index of it, else returns -1. public static int interpolationSearch(int x) &#123; // Find indexes of two corners int lo = 0, hi = (arr.length - 1); // Since array is sorted, an element present // in array must be in range defined by corner while (lo &lt;= hi &amp;&amp; x &gt;= arr[lo] &amp;&amp; x &lt;= arr[hi]) &#123; // Probing the position with keeping // uniform distribution in mind. int pos = lo + (((hi-lo) / (arr[hi]-arr[lo]))*(x - arr[lo])); // Condition of target found if (arr[pos] == x) return pos; // If x is larger, x is in upper part if (arr[pos] &lt; x) lo = pos + 1; // If x is smaller, x is in lower part else hi = pos - 1; &#125; return -1; &#125; // Driver method public static void main(String[] args) &#123; int x = 18; // Element to be searched int index = interpolationSearch(x); // If element was found if (index != -1) System.out.println(\"Element found at index \" + index); else System.out.println(\"Element not found.\"); &#125;&#125;时间复杂度：O(log⁡log⁡n)O\\left( \\log \\log n\\right)O(loglogn)适用场景：有序、均匀分布 Exponential Search(指数搜索)指数搜索涉及两个步骤：(1)查找元素存在的范围；(2)在上面找到的范围中进行二分查找。如何找到元素可能存在的范围？这个想法是从子数组大小1开始，比较它的最后一个元素和x，然后尝试大小2，然后是4，直到子数组的最后一个元素不会更大。 一旦我们找到了一个索引i（在重复了i次之后），我们知道该元素必须存在于i / 2和i之间（为什么是i / 2？因为我们在以前的迭代中找不到更大的值）Java实现123456789101112131415161718192021222324252627282930313233343536// Java program to find an element x in a// sorted array using Exponential search.import java.util.Arrays;class ExponentialSearch&#123; // Returns position of first ocurrence of // x in array public static int exponentialSearch(int arr[], int n, int x) &#123; // If x is present at firt location itself if (arr[0] == x) return 0; // Find range for binary search by // repeated doubling int i = 1; while (i &lt; n &amp;&amp; arr[i] &lt;= x) i = i*2; // Call binary search for the found range. return Arrays.binarySearch(arr, i/2, Math.min(i, n), x); &#125; // Driver method public static void main(String args[]) &#123; int arr[] = &#123;2, 3, 4, 10, 40&#125;; int x = 10; int result = exponentialSearch(arr, arr.length, x); System.out.println((result &lt; 0) ? \"Element is not present in array\" : \"Element is present at index \" + result); &#125;&#125;时间复杂度：O(log⁡n)O\\left( \\log n\\right)O(logn)适用场景：有序当目标元素更靠近开始位置时，Exponential Search优于Binary Search。","categories":[{"name":"Algorithms","slug":"algorithms","permalink":"https://maoyunfei.github.io/categories/algorithms/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://maoyunfei.github.io/tags/算法/"}]},{"title":"Docker容器相关命令","slug":"docker/Docker容器相关命令","date":"2018-03-07T16:00:00.000Z","updated":"2018-12-06T06:26:12.746Z","comments":true,"path":"docker/fab65d8b/","link":"","permalink":"https://maoyunfei.github.io/docker/fab65d8b/","excerpt":"Docker容器的常用命令如下，详细信息也可以查看官方文档。 新建并启动容器使用docker run命令可以新建并启动一个容器。命令格式：1docker run [OPTIONS] IMAGE [COMMAND] [ARG...]","text":"Docker容器的常用命令如下，详细信息也可以查看官方文档。 新建并启动容器使用docker run命令可以新建并启动一个容器。命令格式：1docker run [OPTIONS] IMAGE [COMMAND] [ARG...]参数：参数默认值说明-d后台运行-P随机端口映射-p指定端口映射 (格式：-p hostPort:containerPort)--network指定网络模式示例：1docker run java /bin/echo 'Hello World'1docker run -d -p 91:80 nginx**提醒：**使用docker run命令创建容器时，会先检查本地是否存在指定镜像。如果本地不存在该名称的镜像，Docker就会自动从Docker Hub下载镜像并启动一个Docker容器。 列出容器使用docker ps命令列出运行中的容器。命令格式：1docker ps [options]参数：参数默认值说明--all , -afalse列出所有容器(包括未运行的)--filter , -f根据条件过滤--last , -n-1显示最近创建的n个容器(无论状态)--no-truncfalse不截断输出--quite , -qfalse静默模式，只显示容器ID--size , -sfalse显示总文件大小示例：1docker ps -n 101docker ps -a -q 停止容器使用docker stop命令可以停止容器。命令格式：1docker stop [options] CONTAINER [CONTAINER...]参数：参数默认值说明--time , -t10杀死容器前等待其停止的时间，单位是秒示例：12docker stop 784fd3b294d7docker stop nginx 强行停止容器使用docker kill命令强行停止容器命令格式：1docker kill [options] CONTAINER [CONTAINER...]参数：参数默认值说明--siginal , -sKILL向容器发送信号示例：12docker kill 784fd3b294d7docker kill nginx 启动已停止容器使用docker start命令可以启动已停止的容器。命令格式：1docker start [options] CONTAINER [CONTAINER...]示例：12docker start 784fd3b294d7docker start nginx 重启容器使用docker restart命令可以重启容器。实际上是先执行了docker stop命令，然后再执行docker start命令。命令格式：1docker restart [options] CONTAINER [CONTAINER...]参数：参数默认值说明--time , -t10杀死容器前等待其停止的时间，单位是秒示例：12docker restart 784fd3b294d7docker restart nginx 进入容器有多种方式进入容器，最简单的方式是使用docker exec命令。命令格式：1docker exec -it 容器ID /bin/bash示例：1docker exec -it 784fd3b294d7 /bin/bash 删除容器使用docker rm命令可以删除容器。命令格式：1docker rm [options] CONTAINER [CONTAINER...]参数：参数默认值说明--force , -ffalse通过SIGKILL信号强制删除正在运行中的容器--link , -lfalse删除容器间的网络连接--volumes , -vfalse删除与容器关联的卷示例：12docker rm 784fd3b294d7docker rm -f nginx删除所有的容器:1docker rm -f $&#123;docker ps -a -q&#125;","categories":[{"name":"Docker","slug":"docker","permalink":"https://maoyunfei.github.io/categories/docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://maoyunfei.github.io/tags/Docker/"}]},{"title":"Docker镜像相关命令","slug":"docker/Docker镜像相关命令","date":"2018-03-06T16:00:00.000Z","updated":"2018-12-06T06:26:12.783Z","comments":true,"path":"docker/7dd9962d/","link":"","permalink":"https://maoyunfei.github.io/docker/7dd9962d/","excerpt":"Docker镜像的常用命令如下，详细信息也可以查看官方文档。 搜索镜像使用docker search命令可以搜索远端仓库共享的镜像，默认是Docker Hub中的镜像。命令格式：1docker search [options] TERM","text":"Docker镜像的常用命令如下，详细信息也可以查看官方文档。 搜索镜像使用docker search命令可以搜索远端仓库共享的镜像，默认是Docker Hub中的镜像。命令格式：1docker search [options] TERM参数：参数默认值说明--automatedfalse仅显示自动构建的镜像--filter , -f根据指定条件过滤--limit25搜索结果的最大条数--no-truncfalse输出信息不截断显示--stars , -s0仅显示star大于指定星级的镜像，0表示输出所有镜像示例：1docker search nginx1docker search -s 10 nginx 下载镜像使用docker pull命令直接从Docker Hub下载镜像。命令格式：1docker pull [options] NAME[:TAG]其中，NAME是镜像仓库的名称，TAG是镜像的标签。通常情况下，描述一个镜像需要包括“名称+标签”信息。参数：参数默认值说明--all-tags , -afalse下载所有标签的镜像--disable-content-trustfalse忽略镜像内容校验示例：1docker pull nginx如果不指定TAG，默认下载镜像的最新版本。1docker pull myregistry.com/nginx:tag1 列出镜像使用docker images命令可以列出本机上已有镜像的基本信息。命令格式：1docker images [options] [REPOSITORY[:TAG]]参数：参数默认值说明--all , -afalse列出所有镜像(包括隐藏中间层镜像)--digestsfalse显示摘要信息--filter , -f显示满足条件的镜像--format使用Go语言模板文件展示镜像--no-truncfalse输出信息不截断显示--quite , -qfalse只显示镜像ID示例：123456docker imagesdocker images nginxdocker images nginx:tag1docker images --digestsdocker images --filter \"dangling=true\"docker images --format \"table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Repository&#125;&#125;\\t&#123;&#123;.Tag&#125;&#125;\" 添加标签使用docker tag命令为本地镜像添加新的标签命令格式：1docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]示例：123docker tag 0e5574283393 fedora/httpd:version1.0docker tag httpd fedora/httpd:version1.0docker tag httpd:test fedora/httpd:version1.0.test 删除镜像使用docker rmi命令可以删除指定镜像。命令格式：1docker rmi [options] IMAGE [IMAGE...]参数：参数默认值说明--force, -ffalse强制删除--no-prunefalse不移除该镜像的过程镜像，默认移除示例：12docker rmi nginxdocker rmi $&#123;ID&#125;删除所有镜像:1docker rmi $(docker images) 构建镜像通过Dockerfile构建镜像。命令格式：1docker build [options] path | url | -参数：参数默认值说明--file, -f指定Dockerfile的名称，默认是‘PATH/Dockerfile’--no-prunefalse不移除该镜像的过程镜像，默认移除","categories":[{"name":"Docker","slug":"docker","permalink":"https://maoyunfei.github.io/categories/docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://maoyunfei.github.io/tags/Docker/"}]},{"title":"Java 8新特性之Date/Time API","slug":"java/Java 8新特性之Date:Time API","date":"2018-03-02T16:00:00.000Z","updated":"2018-12-06T06:26:12.853Z","comments":true,"path":"java/7dd3efa4/","link":"","permalink":"https://maoyunfei.github.io/java/7dd3efa4/","excerpt":"在Java 8以前，日期和时间处理一直被广大java程序员抱怨太难用，首先是java.util和java.sql中，都包含Date类，如果要处理由java.text.DateFormat类处理。同时java.util.Date中既包含了日期，又包含了时间，所以java 8新的日期和时间库，很好的解决了以前日期和时间类的很多弊端。并且也借鉴了第三方库joda很多的优点。 对比旧的日期APIJava.timejava.util.Calendar以及Date流畅的API不流畅的API实例不可变实例可变线程安全非线程安全","text":"在Java 8以前，日期和时间处理一直被广大java程序员抱怨太难用，首先是java.util和java.sql中，都包含Date类，如果要处理由java.text.DateFormat类处理。同时java.util.Date中既包含了日期，又包含了时间，所以java 8新的日期和时间库，很好的解决了以前日期和时间类的很多弊端。并且也借鉴了第三方库joda很多的优点。 对比旧的日期APIJava.timejava.util.Calendar以及Date流畅的API不流畅的API实例不可变实例可变线程安全非线程安全 新API介绍 1、主要的类:java.time包下的类：123456789Instant：时间戳 Duration：持续时间，时间差 LocalDate：只包含日期，比如：2016-10-20 LocalTime：只包含时间，比如：23:12:10 LocalDateTime：包含日期和时间，比如：2016-10-20 23:14:21 Period：时间段 ZoneOffset：时区偏移量，比如：+8:00 ZonedDateTime：带时区的时间 Clock：时钟，比如获取目前美国纽约的时间以及java.time.format包下的类：1DateTimeFormatter：时间格式化 2、主要的类的值的格式: 3、通过例子来看如何使用java8新的日期时间库 (1) 获取今天的日期1234LocalDate todayDate = LocalDate.now();System.out.println(\"今天的日期：\"+todayDate);//结果今天的日期：2016-10-20 (2) 指定日期，进行相应操作123456789101112131415161718192021222324252627//取2016年10月的第1天LocalDate firstDay = oneday.with(TemporalAdjusters.firstDayOfMonth());System.out.println(firstDay); //取2016年10月的第1天，另外一种写法LocalDate firstDay2 = oneday.withDayOfMonth(1);System.out.println(firstDay2); //取2016年10月的最后1天，不用考虑大月，小月，平年，闰年LocalDate lastDay = oneday.with(TemporalAdjusters.lastDayOfMonth());System.out.println(lastDay); //当前日期＋1天LocalDate tomorrow = oneday.plusDays(1);System.out.println(tomorrow);//判断是否为闰年boolean isLeapYear = tomorrow.isLeapYear();System.out.println(isLeapYear);//运行结果2016-10-202016-10-012016-10-012016-10-312016-10-21true (3) 生日检查或者账单日检查123456789101112开发过程中，经常需要为过生日的用户送上一些祝福，例如，用户的生日为1990-10-12，如果今天是2016-10-12，那么今天就是用户的生日(按公历/身份证日期来算)，那么通过java8新的日期库，我们该如何来进行判断？在java 8中，可以使用MonthDay，该类不包含年份信息，当然还有一个类是YearMonthLocalDate birthday = LocalDate.of(1990, 10, 12);MonthDay birthdayMd = MonthDay.of(birthday.getMonth(), birthday.getDayOfMonth());MonthDay today = MonthDay.from(LocalDate.of(2016, 10, 12)); System.out.println(today.equals(birthdayMd));//结果true (4) 获取当前的时间12345678910111213141516时间主要是使用LocalTime，该类不包含日期，只有时间信息//获取当前的时间LocalTime nowTime = LocalTime.now(); //结果14:29:40.558 //如果不想显示毫秒LocalTime nowTime2 = LocalTime.now().withNano(0); //14:43:14 //指定时间LocalTime time = LocalTime.of(14, 10, 21); //14:10:21LocalTime time2 = LocalTime.parse(\"12:00:01\"); // 12:00:01 //当前时间增加2小时LocalTime nowTimePlus2Hour = nowTime.plusHours(2); //16:47:23.144//或者LocalTime nowTimePlus2Hour2 = nowTime.plus(2, ChronoUnit.HOURS); (5) 日期前后比较12345比较2个日期哪个在前，哪个在后，java8 LocalDate提供了2个方法，isAfter(),isBeforeLocalDate today = LocalDate.now();LocalDate specifyDate = LocalDate.of(2015, 10, 20);System.out.println(today.isAfter(specifyDate)); //true (6) 处理不同时区的时间12345678910111213141516java8中，将日期、时间，时区都很好的进行了分离。//查看当前的时区ZoneId defaultZone = ZoneId.systemDefault();System.out.println(defaultZone); //Asia/Shanghai //查看美国纽约当前的时间ZoneId america = ZoneId.of(\"America/New_York\");LocalDateTime shanghaiTime = LocalDateTime.now();LocalDateTime americaDateTime = LocalDateTime.now(america);System.out.println(shanghaiTime); //2016-11-06T15:20:27.996System.out.println(americaDateTime); //2016-11-06T02:20:27.996 ，可以看到美国与北京时间差了13小时 //带有时区的时间ZonedDateTime americaZoneDateTime = ZonedDateTime.now(america);System.out.println(americaZoneDateTime); //2016-11-06T02:23:44.863-05:00[America/New_York] (7) 比较两个日期之前时间差123456789101112131415161718在项目中，经常需要比较两个日期之间相差几天，或者相隔几个月，我们可以使用java8的Period来进行处理。LocalDate today = LocalDate.now();LocalDate specifyDate = LocalDate.of(2015, 10, 2);Period period = Period.between(specifyDate, today);System.out.println(period.getDays()); //4System.out.println(period.getMonths()); //1System.out.println(specifyDate.until(today, ChronoUnit.DAYS)); //401//输出结果41401我们可以看到，我们使用Period类比较天数，但它返回的值，并不是2个日期之间总共的天数差，而是一个相对天数差，比如5月1日和10月2日，他比较的是仅仅2个天之间的差，那1号和2号，相差1天，而实际上，因为中间相差了好几个月，所以真正的天数差肯定不是1天，所以我们可以使用until，并指明精度单位是days，就可以计算真正的天数差了。 (8) 日期时间格式解析、格式化12345678910111213141516在java8之前，我们进行时间格式化主要是使用SimpleDateFormat，而在java8中，主要是使用DateTimeFormatter，java8中，预定义了一些标准的时间格式，我们可以直接将时间转换为标准的时间格式：String specifyDate = \"20151011\";DateTimeFormatter formatter = DateTimeFormatter.BASIC_ISO_DATE;LocalDate formatted = LocalDate.parse(specifyDate,formatter); System.out.println(formatted); //输出2015-10-11当然，很多时间标准的时间格式可能也不满足我们的要求，我们需要转为自定义的时间格式DateTimeFormatter formatter2 = DateTimeFormatter.ofPattern(\"YYYY MM dd\");System.out.println(formatter2.format(LocalDate.now()));//结果2015 10 11 (9) java8 时间类与Date类的相互转化1234567891011121314151617181920212223在转换中，我们需要注意，因为java8之前Date是包含日期和时间的，而LocalDate只包含日期，LocalTime只包含时间，所以与Date在互转中，势必会丢失日期或者时间，或者会使用起始时间。如果转LocalDateTime，那么就不存在信息误差。//Date与Instant的相互转化Instant instant = Instant.now();Date date = Date.from(instant);Instant instant2 = date.toInstant(); //Date转为LocalDateTimeDate date2 = new Date();LocalDateTime localDateTime2 = LocalDateTime.ofInstant(date2.toInstant(), ZoneId.systemDefault()); //LocalDateTime转DateLocalDateTime localDateTime3 = LocalDateTime.now();Instant instant3 = localDateTime3.atZone(ZoneId.systemDefault()).toInstant();Date date3 = Date.from(instant);//LocalDate转Date//因为LocalDate不包含时间，所以转Date时，会默认转为当天的起始时间，00:00:00LocalDate localDate4 = LocalDate.now();Instant instant4 = localDate4.atStartOfDay().atZone(ZoneId.systemDefault()).toInstant();Date date4 = Date.from(instant);","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java 8","slug":"Java-8","permalink":"https://maoyunfei.github.io/tags/Java-8/"}]},{"title":"Java 8新特性之函数式接口和Lambda表达式","slug":"java/Java 8新特性之函数式接口和Lambda表达式","date":"2018-03-01T16:00:00.000Z","updated":"2018-12-06T06:26:12.827Z","comments":true,"path":"java/c8f73c32/","link":"","permalink":"https://maoyunfei.github.io/java/c8f73c32/","excerpt":"面向对象并不坏，但它给程序带来了很多冗长的内容。例如，假设我们要创建一个Runnable的实例。通常我们使用下面的匿名类来完成它：","text":"面向对象并不坏，但它给程序带来了很多冗长的内容。例如，假设我们要创建一个Runnable的实例。通常我们使用下面的匿名类来完成它：123456Runnable r = new Runnable() &#123; @Override public void run() &#123; System.out.println(\"My Runnable\"); &#125; &#125;;如果你看看上面的代码，实际使用的部分是 run() 方法中的代码。其余所有的代码是因为Java程序的结构化方式。Java 8函数式接口和Lambda表达式通过删除大量的样板代码，帮助我们编写更少、更简洁的代码。 函数式接口具有一个抽象方法的接口称为函数式接口。添加了@FunctionalInterface注解，以便我们可以将接口标记为函数式接口。使用它不是强制性的，但最好的做法是将它与函数式接口一起使用，以避免意外添加额外的方法。如果接口使用@FunctionalInterface注解进行注释，并且我们尝试使用多个抽象方法，则会引发编译器错误。Java 8函数式接口的主要好处是我们可以使用lambda表达式来实例化它们，避免使用笨重的匿名类实现。Java 8 Collections API已被重写，并引入了新的Stream API，它使用了许多函数式接口。 Java 8在java.util.function包中定义了很多函数式接口。一些有用的java 8函数式接口如Consumer、Supplier、Function和Predicate。java.lang.Runnable是使用单一抽象方法 run() 的函数式接口的一个很好的例子。 下面的代码片段为函数式接口提供了一些指导：1234567891011121314151617181920212223242526272829303132333435363738394041424344interface Foo &#123; boolean equals(Object obj); &#125;// Not functional because equals is already an implicit member (Object class)interface Comparator&lt;T&gt; &#123; boolean equals(Object obj); int compare(T o1, T o2);&#125;// Functional because Comparator has only one abstract non-Object methodinterface Foo &#123; int m(); Object clone();&#125;// Not functional because method Object.clone is not publicinterface X &#123; int m(Iterable&lt;String&gt; arg); &#125;interface Y &#123; int m(Iterable&lt;String&gt; arg); &#125;interface Z extends X, Y &#123;&#125;// Functional: two methods, but they have the same signatureinterface X &#123; Iterable m(Iterable&lt;String&gt; arg); &#125;interface Y &#123; Iterable&lt;String&gt; m(Iterable arg); &#125;interface Z extends X, Y &#123;&#125;// Functional: Y.m is a subsignature &amp; return-type-substitutableinterface X &#123; int m(Iterable&lt;String&gt; arg); &#125;interface Y &#123; int m(Iterable&lt;Integer&gt; arg); &#125;interface Z extends X, Y &#123;&#125;// Not functional: No method has a subsignature of all abstract methodsinterface X &#123; int m(Iterable&lt;String&gt; arg, Class c); &#125;interface Y &#123; int m(Iterable arg, Class&lt;?&gt; c); &#125;interface Z extends X, Y &#123;&#125;// Not functional: No method has a subsignature of all abstract methodsinterface X &#123; long m(); &#125;interface Y &#123; int m(); &#125;interface Z extends X, Y &#123;&#125;// Compiler error: no method is return type substitutableinterface Foo&lt;T&gt; &#123; void m(T arg); &#125;interface Bar&lt;T&gt; &#123; void m(T arg); &#125;interface FooBar&lt;X, Y&gt; extends Foo&lt;X&gt;, Bar&lt;Y&gt; &#123;&#125;// Compiler error: different signatures, same erasure Lambda表达式由于在函数式接口中只有一个抽象函数，因此在将该lambda表达式应用于该方法时不会出现混淆。 Lambda表达式的语法是 (argument) -&gt; (body)。现在来看看如何使用lambda表达式写上面的匿名Runnable:1Runnable r1 = () -&gt; System.out.println(\"My Runnable\");让我们试着了解上面的lambda表达式中发生了什么。Runnable是一个函数式接口，这就是为什么我们可以使用lambda表达式来创建它的实例。由于 run() 方法没有参数，我们的lambda表达式也没有参数。就像if-else块一样，我们可以避免大括号({})，因为我们在方法体中只有单个语句。对于多个语句，我们必须像使用其他方法一样使用花括号。 为什么我们需要Lambda表达式 1、减少代码行数使用lambda表达式的一个明显优势是代码量减少了，我们已经看到，我们可以轻松地使用lambda表达式而不是使用匿名类来创建函数接口的实例。 2、顺序和并行执行支持使用lambda表达式的另一个好处是我们可以从Stream API顺序和并行操作支持中受益。为了解释这一点，我们举一个简单的例子，我们需要编写一个方法来测试一个数字是否是素数。12345678//Traditional approachprivate static boolean isPrime(int number) &#123; if(number &lt; 2) return false; for(int i=2; i&lt;number; i++)&#123; if(number % i == 0) return false; &#125; return true;&#125;上述代码的问题在于它本质上是顺序的，如果数字非常大，那么它将花费大量时间。代码的另一个问题是有太多的退出点使其可读性差。123456//Declarative approachprivate static boolean isPrime(int number) &#123; return number &gt; 1 &amp;&amp; IntStream.range(2, number).noneMatch( index -&gt; number % index == 0);&#125;为了提高可读性，我们也可以编写如下的方法。1234567private static boolean isPrime(int number) &#123; IntPredicate isDivisible = index -&gt; number % index == 0; return number &gt; 1 &amp;&amp; IntStream.range(2, number).noneMatch( isDivisible);&#125; 3、将行为传递给方法我们来看看如何使用lambda表达式来传递一个方法的行为。假设我们必须编写一个方法来对列表中的数字求和，如果它们符合给定的条件。我们可以使用Predicate并编写如下的方法。123456public static int sumWithCondition(List&lt;Integer&gt; numbers, Predicate&lt;Integer&gt; predicate) &#123; return numbers.parallelStream() .filter(predicate) .mapToInt(i -&gt; i) .sum(); &#125;使用示例：123456//sum of all numberssumWithCondition(numbers, n -&gt; true)//sum of all even numberssumWithCondition(numbers, i -&gt; i%2==0)//sum of all numbers greater than 5sumWithCondition(numbers, i -&gt; i&gt;5) 4、使用惰性求值效率更高使用lambda表达式的另一个优点是惰性求值(lazy evaluation)。假设我们需要编写一个方法来找出3到11范围内的最大奇数并返回它的平方。通常我们会为此方法编写如下代码：123456789private static int findSquareOfMaxOdd(List&lt;Integer&gt; numbers) &#123; int max = 0; for (int i : numbers) &#123; if (i % 2 != 0 &amp;&amp; i &gt; 3 &amp;&amp; i &lt; 11 &amp;&amp; i &gt; max) &#123; max = i; &#125; &#125; return max * max; &#125;上面的程序总是按顺序运行，但我们可以使用Stream API来实现这一点，并获得Laziness-seeking的好处。我们来看看如何使用Stream API和lambda表达式以函数式编程方式重写此代码。123456789101112131415161718192021public static int findSquareOfMaxOdd(List&lt;Integer&gt; numbers) &#123; return numbers.stream() .filter(NumberTest::isOdd) //Predicate is functional interface and .filter(NumberTest::isGreaterThan3) // we are using lambdas to initialize it .filter(NumberTest::isLessThan11) // rather than anonymous inner classes .max(Comparator.naturalOrder()) .map(i -&gt; i * i) .get(); &#125; public static boolean isOdd(int i) &#123; return i % 2 != 0; &#125; public static boolean isGreaterThan3(int i)&#123; return i &gt; 3; &#125; public static boolean isLessThan11(int i)&#123; return i &lt; 11; &#125;","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java 8","slug":"Java-8","permalink":"https://maoyunfei.github.io/tags/Java-8/"}]},{"title":"Java 8新特性之接口的默认方法和静态方法","slug":"java/Java 8新特性之接口的默认方法和静态方法","date":"2018-02-28T16:00:00.000Z","updated":"2018-12-06T06:26:12.794Z","comments":true,"path":"java/6376aac3/","link":"","permalink":"https://maoyunfei.github.io/java/6376aac3/","excerpt":"Java 8接口新特性包括接口中的静态方法和默认方法。在Java 8之前，我们只能在接口中使用方法声明。但是从Java 8开始，我们可以在接口中使用默认方法和静态方法。","text":"Java 8接口新特性包括接口中的静态方法和默认方法。在Java 8之前，我们只能在接口中使用方法声明。但是从Java 8开始，我们可以在接口中使用默认方法和静态方法。 默认方法为了在java接口中创建一个默认方法，我们需要在方法签名中使用“default”关键字。例如，12345678public interface Interface1 &#123; void method1(String str); default void log(String str)&#123; System.out.println(\"I1 logging::\"+str); &#125;&#125;注意到 log(String str) 是Interface1中的默认方法。现在当一个类实现Interface1时，并不强制为接口的默认方法提供实现。这个特性将帮助我们扩展接口和其他方法，我们所需要的只是提供一个默认实现。另一个接口定义如下：123456789public interface Interface2 &#123; void method2(); default void log(String str)&#123; System.out.println(\"I2 logging::\"+str); &#125;&#125;我们知道Java不允许我们继承多个类，因为它会导致“钻石问题”，因为编译器无法决定使用哪个超类方法。使用默认方法，&quot;钻石问题&quot;也会出现在接口上。因为如果一个类同时实现了Interface1和Interface2并且没有实现通用的默认方法，编译器无法决定选择哪一个。(备注：The diamond problem)实现多个接口是Java不可或缺的组成部分，可以在核心Java类以及大多数企业应用程序和框架中找到它。所以为了确保这个问题不会发生在接口中，必须为通用的接口默认方法提供实现。因此，如果一个类正在实现上述两个接口，它将不得不为 log() 方法提供实现，否则编译器将抛出编译时错误。一个同时实现Interface1和Interface2的简单类如下：12345678910111213141516public class MyClass implements Interface1, Interface2 &#123; @Override public void method2() &#123; &#125; @Override public void method1(String str) &#123; &#125; @Override public void log(String str)&#123; System.out.println(\"MyClass logging::\"+str); Interface1.print(\"abc\"); &#125;&#125; 有关java接口默认方法的重点：Java 8接口的默认方法将帮助我们扩展接口，而不用担心会破坏实现类。Java 8接口默认方法弥合了接口和抽象类之间的差异。Java 8接口的默认方法将帮助我们避免utility类，比如所有的Collections类方法都可以在接口本身中提供。Java接口的默认方法将帮助我们去除基础实现类，我们可以提供默认的实现，实现类可以选择重写哪一个。在接口中引入默认方法的主要原因之一是增强Java 8中的Collections API以支持lambda表达式。如果层次结构中的任何类具有相同签名的方法，则默认方法变得不相关。默认方法不能从java.lang.Object中覆盖方法。推理非常简单，这是因为Object是所有java类的基类。所以即使我们把Object类的方法定义为接口中的默认方法，也是无用的，因为总是使用Object类的方法。这就是为什么要避免混淆，我们不能有覆盖Object类方法的默认方法。Java接口默认方法也被称为Defender方法或虚拟扩展方法。 静态方法接口静态方法和默认方法类似，除了我们不能在实现类中override它们。这个特性有助于我们避免在实现类中由于不好的实现导致的不当结果。12345678910111213public interface MyData &#123; default void print(String str) &#123; if (!isNull(str)) System.out.println(\"MyData Print::\" + str); &#125; static boolean isNull(String str) &#123; System.out.println(\"Interface Null Check\"); return str == null ? true : \"\".equals(str) ? true : false; &#125;&#125;现在来看一个实现类，该类具有 isNull() 方法，但实现效果较差。1234567891011121314public class MyDataImpl implements MyData &#123; public boolean isNull(String str) &#123; System.out.println(\"Impl Null Check\"); return str == null ? true : false; &#125; public static void main(String args[])&#123; MyDataImpl obj = new MyDataImpl(); obj.print(\"\"); obj.isNull(\"abc\"); &#125;&#125;注意 isNull(String str) 是一种简单的类方法，它不会覆盖接口方法。例如，如果我们将@Override注释添加到 isNull() 方法，则会导致编译器错误。现在，当我们运行应用程序时，我们得到以下输出:12Interface Null CheckImpl Null Check如果我们将接口方法从静态变为默认，我们将得到以下输出:123Impl Null CheckMyData Print::Impl Null CheckJava接口静态方法仅对接口方法可见，如果我们从 MyDataImpl 类中移除 isNull() 方法，我们将无法将其用于 MyDataImpl 对象。像其他静态方法一样，我们可以使用类名调用接口静态方法。例如：1boolean result = MyData.isNull(\"abc\"); 有关java接口静态方法的重点：Java接口的静态方法是接口的一部分，我们不能用它来实现类对象。Java接口静态方法适用于提供utility方法，例如空检查，集合排序等。Java接口静态方法通过不允许实现类override它们来帮助我们提供安全性。我们不能为Object类方法定义接口静态方法，因为“这个静态方法不能从Object隐藏实例方法”，我们会得到编译器错误。这是因为它在java中是不允许的，因为Object是所有类的基类，我们不能有一个类级静态方法和另一个具有相同签名的实例方法。我们可以使用java接口的静态方法来移除Collections等utility类，并将它的所有静态方法移到相应的接口中，这很容易找到和使用。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java 8","slug":"Java-8","permalink":"https://maoyunfei.github.io/tags/Java-8/"}]},{"title":"聊聊JVM的年轻代","slug":"java/jvm/【收录】聊聊JVM的年轻代","date":"2018-02-09T16:00:00.000Z","updated":"2018-12-06T06:31:37.917Z","comments":true,"path":"java/24b8c8d9/","link":"","permalink":"https://maoyunfei.github.io/java/24b8c8d9/","excerpt":"本文章来源于并发编程网堆内存模型大致如下：","text":"本文章来源于并发编程网堆内存模型大致如下： 1. 为什么会有年轻代我们先来屡屡，为什么需要把堆分代？不分代不能完成他所做的事情么？其实不分代完全可以，分代的唯一理由就是优化GC性能。你先想想，如果没有分代，那我们所有的对象都在一块，GC的时候我们要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而我们的很多对象都是朝生夕死的，如果分代的话，我们把新创建的对象放到某一地方，当GC的时候先把这块存“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。 2. 年轻代中的GCHotSpot JVM把年轻代分为了三部分：1个Eden区和2个Survivor区（分别叫from和to）。默认比例为 8:1:1 ( 设置较大的Eden空间和较小的Survivor空间是合理的，大大提高了内存的使用率，缓解了复制算法的缺点 )。一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理,直接分配到老年代),这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。因为年轻代中的对象基本都是朝生夕死的(80%以上)，所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。 3. 一个对象的这一辈子我是一个普通的java对象，我出生在Eden区，在Eden区我还看到和我长的很像的小兄弟，我们在Eden区中玩了挺长时间。有一天Eden区中的人实在是太多了，我就被迫去了Survivor区的“From”区，自从去了Survivor区，我就开始漂了，有时候在Survivor的“From”区，有时候在Survivor的“To”区，居无定所。直到我18岁的时候，爸爸说我成人了，该去社会上闯闯了。于是我就去了年老代那边，年老代里，人很多，并且年龄都挺大的，我在这里也认识了很多人。在年老代里，我生活了20年(每次GC加一岁)，然后被回收。 4. 有关年轻代的JVM参数-XX:NewSize和-XX:MaxNewSize用于设置年轻代的大小，建议设为整个堆大小的1/3或者1/4,两个值设为一样大。-XX:SurvivorRatio用于设置Eden和其中一个Survivor的比值，这个值也比较重要。-XX:+PrintTenuringDistribution这个参数用于显示每次Minor GC时Survivor区中各个年龄段的对象的大小。-XX:InitialTenuringThreshol和-XX:MaxTenuringThreshold用于设置晋升到老年代的对象年龄的最小值和最大值，每个对象在坚持过一次Minor GC之后，年龄就加1。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"Java内存模型","slug":"java/jvm/4、Java内存模型","date":"2018-02-08T16:00:00.000Z","updated":"2018-12-06T06:31:37.922Z","comments":true,"path":"java/91e798bc/","link":"","permalink":"https://maoyunfei.github.io/java/91e798bc/","excerpt":"Java虚拟机规范中试图定义一种Java内存模型(Java Memory Model, JMM)来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。","text":"Java虚拟机规范中试图定义一种Java内存模型(Java Memory Model, JMM)来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。 主内存与工作内存Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。这里的变量与Java编程中所说的变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。Java内存模型规定了所有的变量都存储在主内存(Main Memory)中。每条线程还有自己的工作内存(Working Memory)，线程的工作内存中保存了该被线程使用到的变量的主内存副本拷贝，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如下：这里所讲的主内存、工作内存与Java内存区域中的Java堆、栈、方法区并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来，那从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分数据。从更低层次上说，主内存就直接对应于物理硬件的内存，而为了获取更好的运行速度，虚拟机可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是工作内存。 内存间的交互操作关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的(对于double和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外)。lock(锁定)：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。unlock(解锁)：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。read(读取)：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的load动作使用。load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。use(使用)：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。assign(赋值)：作用于工作内存的变量，它把一个从执行引擎收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。store(存储)：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。write(写入)：作用于工作内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。 对于volatile型变量的特殊规则关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制。当一个变量定义为volatile之后，它将具备两个特性，第一是保证此变量对所有线程的可见性，这里的可见性是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。虽然volatile变量在各个线程中是一致的，但是Java里面的运算并非原子操作，所以volatile变量的运算在并发下不能保证安全性。由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通过加锁(使用synchronized或java.util.concurrent中的原子类)来保证原子性。运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。变量不需要与其他的状态变量共同参与不变约束。使用volatile变量的第二个语义是禁止指令重排序优化。 选用volatile的意义大多数场景下volatile的总开销要比锁低，我们在volatile与锁之中选择的唯一依据仅仅是volatile的语义能否满足使用场景的需求。 对long和double型变量的特殊规则Java内存模型要求lock、unlock、read、load、assign、use、store、write这8个操作都具有原子性，但是对于64位的数据结构(long和double)，在模型中特别定义了一条相对宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现选择可以不保证64位数据结构的load、store、read和write这4个操作的原子性，这点就是所谓的long和double的非原子协定。 原子性、可见性与有序性原子性：可见性：有序性： 先行发生原则程序次序规则：管程锁定规则：volatile变量规则：线程启动规则：线程终止规则：线程中断规则：对象终极规则：传递性：","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"垃圾收集算法","slug":"java/jvm/3、垃圾收集算法","date":"2018-02-07T16:00:00.000Z","updated":"2018-12-06T06:31:38.093Z","comments":true,"path":"java/ba66848b/","link":"","permalink":"https://maoyunfei.github.io/java/ba66848b/","excerpt":"在Java运行时区域中，程序计数器、虚拟机栈、本地方法栈3个区域随线程的而生，随线程而灭，因此这几个区域的内存分配和回收都具有确定性，在这几个区域内就不需要多考虑回收的问题，因此方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间才能知道会创建哪些对象，这部分内存的分配都是动态的，垃圾收集器所关注的是这部分内存。","text":"在Java运行时区域中，程序计数器、虚拟机栈、本地方法栈3个区域随线程的而生，随线程而灭，因此这几个区域的内存分配和回收都具有确定性，在这几个区域内就不需要多考虑回收的问题，因此方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆和方法区则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间才能知道会创建哪些对象，这部分内存的分配都是动态的，垃圾收集器所关注的是这部分内存。 1、判断对象是否“存活” 1.1 引用计数法给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值减1；任何时刻计数器为0的对象就是不可能再被使用的。引用计数法的实现简单，判定效率也高，但是主流的Java虚拟机里面没有选用其来管理内存，最主要原因是它很难解决对象之间相互循环引用的问题。 1.2 可达性分析算法这个算法的基本思想就是通过一系列的“GC Roots”对象作为起始点，从这些节点开始向下搜索。搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时(从图论来说，从GC Roots到这个对象不可达)，则证明此对象是不可用的。 在Java语言中，可作为GC Roots的对象包括下面几种：虚拟机栈(栈帧中的本地变量表)中引用的对象。方法区中类静态属性引用的对象。方法区中常量引用的对象。本地方法栈中JNI(Native方法)引用的对象。 1.3 四种引用类型引入分为强引用、软引用、弱引用、虚引用4种。强引用(Strong Reference)StringBuilder builder = new StringBuilder();强引用是默认引用类型，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。弱引用(Weak Reference)WeakReference&lt;StringBuilder&gt; weakBuilder = new WeakReference&lt;StringBuilder&gt;(builder);弱引用不是默认引用类型，如果需要使用弱引用，则要明确使用WeakReference类。弱引用用来描述非必需的对象。当内存中的对象只被弱引用时，它将可以被垃圾回收。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。软引用(Soft Reference)SoftReference&lt;StringBuilder&gt; softBuilder = new SoftReference&lt;StringBuilder&gt;(builder);软引用不是默认引用类型，如果需要使用软引用，则要明确使用SoftReference类。软引用用来描述一些还有用但是非必需的对象。对于软引用关联的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。虚引用(Phantom Reference)PhantomReference&lt;StringBuilder&gt; phantomBuilder = new PhantomReference&lt;StringBuilder&gt;(builder);虚引用不是默认引用类型，如果需要使用虚引用，则要明确使用PhantomReference类。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用的唯一目的就是能在这个对象呗收集器回收时收到一个系统通知。 1.4 两次标记过程如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那么它将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。 当对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为“没有必要执行”。如果这个对象被判定为有必要执行finalize()方法，那么这个对象将会放置在一个叫做F-Queue的队列之中，并在稍后由一个由虚拟机自动建立的、低优先级的Finalizer线程去执行它。 这里所谓的“执行”是指虚拟机会触发这个方法，但并不承诺会等待它运行结束，这样做的原因是，如果一个对象在finalize()方法中执行缓慢，或者发生了死循环，将很可能会导致F-Queue队列中其他对象永久处于等待，甚至导致整个内存回收系统崩溃。finalize()方法是对象逃脱死亡命运的最后一次机会，稍后GC将对F-Queue中的对象进行第二次小规模标记，如果对象重新与引用链上任何一个对象建立关联，那么第二次标记时它将被移除出“即将回收”的集合；如果对象这时候还没有逃脱，那基本上它就真的被回收了。注意： 任何一个对象的finalize()方法都只会被系统自动调用一次，如果对象面临下一次回收，它的finalize()方法不会被再次执行。 1.5 回收方法区方法区的垃圾收集主要回收两部分内容：废弃常量和无用的类。 例如常量池中的字面值常量没有任何对象引用它，并且也没有其他地方引用了这个字面量，则这个变量就是废弃变量。类需要满足3个条件才能算是无用的类：(1)该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例；(2)加载该类的ClassLoader已经被回收；(3)该类对应的java.lang.Class对象没有在任何其他地方被引用，无法在任何地方通过反射访问该类的方法。虚拟机可以对废弃常量和无用的类进行回收，但并不是一定会回收，是否回收，由虚拟机提供的相关参数进行控制。 2、垃圾收集算法 2.1 标记-清除算法算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它的主要不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片。 2.2 复制算法它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可。实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。现在的商业虚拟机都采用这种收集算法来回收新生代。 2.3 标记-整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低，所以一般不能用于老年代。根据老年代的特点，提出了“标记-整理”算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清除掉端边界以外的内存。 2.4 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”算法，根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清除”或者“标记-整理”算法来进行回收。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"HotSpot虚拟机对象探秘","slug":"java/jvm/2、HotSpot虚拟机对象(创建、内存布局、定位)探秘","date":"2018-02-06T16:00:00.000Z","updated":"2018-12-06T06:31:37.888Z","comments":true,"path":"java/41b66951/","link":"","permalink":"https://maoyunfei.github.io/java/41b66951/","excerpt":"以常用的虚拟机HotSpot和常用的内存区域Java堆为例，深入探讨HotSpot虚拟机在Java堆中对象分配、布局和访问全过程。","text":"以常用的虚拟机HotSpot和常用的内存区域Java堆为例，深入探讨HotSpot虚拟机在Java堆中对象分配、布局和访问全过程。 1. 对象的创建（1）虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。（2）在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类加载完成后便可完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”(Bump the Pointer)。如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间分配给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”(Free List)。选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。因此，在使用Serial、ParNew等带Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器是，通常采用空闲列表。（3）除如何划分可用空间外，还有另一个需要考虑的问题是对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案，一种是对分配空间的动作进行同步处理——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性；另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲(Thread Local Allocation Buffer，TLAB)。哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并重新分配新的TLAB时，才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX:+/-UseTLAB参数来设定。（4）内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值(不包括对象头)，如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。（5）接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例，如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头(Object Header)之中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。（6）在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚刚开始——&lt;init&gt;方法还没有执行，所有的字段都还为零。所以，一般来说，执行new指令之后会接着执行&lt;init&gt;方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 2. 对象的内存布局在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头(Header)、实例数据(Instance Data)和对齐填充(Padding)。HotSpot虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码(HashCode)、GC分待年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身。另外，如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据，因为虚拟机可以通过普通Java对象的元数据信息确定Java对象的大小，但是从数组的元数据中缺无法确定数据的大小。接下来的实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。无论是从父类继承下来的，还是在子类中定义的，都需要记录起来。这部分的存储顺序会受到虚拟机分配策略参数和字段在Java源码中定义顺序的影响。第三部分对齐填充并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。由于HotSpot VM的自动内存管理系统要求对象起始地址必须是8字节的整数倍，换句话说，就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的整数倍，因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 3. 对象的访问定位Java程序需要通过栈上的reference数据来操作堆上的具体对象。由于reference类型在Java虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，所以对象访问方式也是取决于虚拟机实现而定的。目前主流的访问方式有使用句柄和直接指针两种。（1）如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与数据类型各自的具体地址信息。（2）如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象地址。这两种对象访问方式各有优势，使用句柄来访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而reference本身不需要修改。使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。Sun HotSpot虚拟机是使用直接指针访问方式进行对象访问的。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"运行时数据区域","slug":"java/jvm/1、运行时数据区域","date":"2018-02-05T16:00:00.000Z","updated":"2018-12-06T06:31:37.896Z","comments":true,"path":"java/20fd51d6/","link":"","permalink":"https://maoyunfei.github.io/java/20fd51d6/","excerpt":"Java虚拟机定义了程序执行期间使用的各种运行时数据区域。有的区域随着虚拟机的启动而存在并随着虚拟机的退出而销毁。有的数据区域是每个线程所独有的，随着线程的创建而创建并随着线程的退出而销毁。","text":"Java虚拟机定义了程序执行期间使用的各种运行时数据区域。有的区域随着虚拟机的启动而存在并随着虚拟机的退出而销毁。有的数据区域是每个线程所独有的，随着线程的创建而创建并随着线程的退出而销毁。 1.1 程序计数器（program counter register）程序计数器是一块较小的内存区域，它可以看作是当前线程所执行的字节码的行号指示器。为了线程切换后能恢复到正确的执行位置，每个线程都需要有一个独立的程序计数器。位于线程私有内存。如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为Undefined。此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 1.2 Java虚拟机栈(JVM Stack)每一个Java虚拟机线程都有一个私有的Java虚拟机栈，与线程同时创建。Java虚拟机栈用于存储帧(frame)。每个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储局部变量表、操作数栈、动态链接、方法出口等信息。当方法执行完成的时候，帧就被销毁了，无论方法是正常返回还是抛出未捕获的异常而中断。每一个方法从调用直至执行完成的过程，就对应一个栈帧在虚拟机栈中入栈到出栈的过程。Java虚拟机栈的内存不需要是连续的经常所说的栈内存(Stack)指的就是虚拟机栈，或者说是虚拟机栈中的局部变量表部分。局部变量表存放了编译期可知的各种基本数据类型(boolean、byte、char、short、int、float、long、double)、对象引用(reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置)和returnAddress类型(指向了一条字节码指令的地址)。其中64位长度的long和double类型的数据会占用2个局部变量空间(Slot)，其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 Java虚拟机栈存在以下两种异常状况：如果线程计算请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常。如果虚拟机栈可以动态扩展(当前大部分的Java虚拟机都可动态扩展)，并且尝试扩展时无法申请到足够的内存或者没有足够的内存可用于为新线程创建初始Java虚拟机栈时，将抛出OutOfMemoryError异常。 1.3 本地方法栈(Native Method Stack)本地方法栈与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法(也就是字节码)服务，而本地方法栈则为虚拟机使用到的native方法服务。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 1.4 堆(Heap)对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程所共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。Java堆是垃圾收集器管理的主要区域，因此也被称为“GC堆”。Java堆可以位于物理上不连续的内存空间中，只要逻辑上是连续的即可。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的(通过-Xmx和-Xms控制)。如果在堆中没有足够内存完成实例分配，并且堆也无法扩展时，将会抛出OutOfMemoryError异常。 1.5 方法区(Method Area)方法区是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息，例如运行时常量池、属性和方法的数据、方法和构造器的代码，以及类和接口初始化和实例初始化中使用的特殊方法。方法区不需要连续的内存，可以选择固定大小或者可扩展，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载。如果方法区的内存无法满足分配需求时，将抛出OutOfMemoryError异常。 1.6 运行时常量池(Run-Time Constant Pool)Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。每一个运行时常量池都从JVM方法区分配内存，类或接口的运行时常量池是在Java虚拟机创建类或接口时构建的。运行时常量池相对于Class文件常量池的一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中的常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的变量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。当创建类或接口时，如果无法从JVM方法区申请足够的内存来构造运行时常量池时，将抛出OutOfMemoryError异常。 重要总结：1. 永久代的变更到废除变更(字符串常量池移到了堆)：在JDK6以及其前期的JDK版本中，永久代用于存储类信息和字符串常量池。在JDK7中，永久代只用于存储类信息，字符串常量池在堆中存储。废弃(被Metaspace取代)：在JDK7以及其前期的JDK版本中，堆内存通常被分为两块区域，新生代(younggeneration)和老年代(old generation)：显示如下图：永久代(Permanent Generation forVM Matedata)和代码缓存区(code cache area)属于非堆内存。在JDK8中把存放元数据的永久代废弃，类信息存储到了在本地内存(native memory)中叫Metaspace的区域，JDK8中JVM堆内存结构就变成了如下：2. 方法区位置变化在JDK7以及之前的版本，方法区是永久代的一部分，在JDK8中方法区是Metaspace的一部分。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://maoyunfei.github.io/tags/JVM/"}]},{"title":"Hash冲突解决方案","slug":"other/Hash冲突解决方案","date":"2018-02-04T16:00:00.000Z","updated":"2018-12-06T06:31:38.028Z","comments":true,"path":"other/eebb0c54/","link":"","permalink":"https://maoyunfei.github.io/other/eebb0c54/","excerpt":"开放地址法(open addressing)","text":"开放地址法(open addressing)","categories":[{"name":"其他","slug":"other","permalink":"https://maoyunfei.github.io/categories/other/"}],"tags":[{"name":"hash","slug":"hash","permalink":"https://maoyunfei.github.io/tags/hash/"}]},{"title":"Java String Constant Pool (Java字符串常量池)","slug":"java/Java字符串常量池的概念和机制","date":"2018-02-03T16:00:00.000Z","updated":"2018-12-06T06:26:12.834Z","comments":true,"path":"java/e52216a2/","link":"","permalink":"https://maoyunfei.github.io/java/e52216a2/","excerpt":"当你在Java中声明一个新的字符串时，在这个场景下有一些有趣的事情发生。这是一个基本的字符串声明，我们创建了一个新的字符串变量employee并给它赋值。1String employee = \"Edgar Allen Poe\";","text":"当你在Java中声明一个新的字符串时，在这个场景下有一些有趣的事情发生。这是一个基本的字符串声明，我们创建了一个新的字符串变量employee并给它赋值。1String employee = \"Edgar Allen Poe\";Java不仅会创建变量employee，而且还会为内存中的字面值“Edgar Allen Poe”分配空间。内存中的这个区域被称为字符串常量池。它就像程序的其他部分可用的字符串值池。 重用字符串常量池中的值现在，如果你创建了另一个变量，比如employee2，并且还给了它一个“Edgar Allen Poe”的值，那么Java只是重用了已经在池中的值。1String employee2 = \"Edgar Allen Poe\";你会注意到字符串常量池位于内存的堆部分。 创建一个新的字符串实例如果你创建String类的新实例，则常量池的工作方式不同。让我们创建另一个变量employee3，并给它相同的字面值。但是，这次我们将创建一个String类的新实例：1String employee3 = new String(\"Edgar Allen Poe\");当这个代码被处理时，Java将会有所不同。而不是再次使用相同的字面值，它会在内存中创建一个新的值。在这种情况下，它不会在字符串常量池中创建它，而是在内存堆中创建它。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"}]},{"title":"java -jar启动命令","slug":"java/java -jar启动命令","date":"2018-02-02T16:00:00.000Z","updated":"2018-12-06T06:26:12.813Z","comments":true,"path":"java/309440ba/","link":"","permalink":"https://maoyunfei.github.io/java/309440ba/","excerpt":"以下是java启动命令的语法说明:（官方文档说明）","text":"以下是java启动命令的语法说明:（官方文档说明） 以下是[options]的说明以及一些常用的:1、Standard Options 所有运行环境都支持-D 用于设置系统变量，由于spring boot会从系统属性读取属性，所以使用@Value(&quot;myDir&quot;)即可获取。-jar 用于指定启动的jar文件，jar文件的manifest必须知道Main-Class2、Nonstandard Options 由Java HotSpot VMs默认提供-Xmn 设置新生代的大小-Xms 设置内存分配池的最小值，即初始值-Xmx 设置内存分配池的最大值对于服务器部署，-Xms和-Xmx通常设置为相同的值。 以下是[arguments]说明：语法为 –{name}={value}例如：java -jar app.jar --name=&quot;Spring&quot; 。由于spring boot会从command line argument读取属性，所以使用@Value(&quot;name&quot;)即可获取。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"}]},{"title":"Executor,ExecutorService和Executors间的不同","slug":"java/Executor，ExecutorService 和 Executors","date":"2018-02-01T16:00:00.000Z","updated":"2018-12-06T06:26:12.789Z","comments":true,"path":"java/8542269d/","link":"","permalink":"https://maoyunfei.github.io/java/8542269d/","excerpt":"文章摘录自博客java.util.concurrent.Executor, java.util.concurrent.ExecutorService, java.util.concurrent.Executors这三者均是 Java Executor 框架的一部分，用来提供线程池的功能。因为创建和管理线程非常心累，并且操作系统通常对线程数有限制，所以建议使用线程池来并发执行任务，而不是每次请求进来时创建一个线程。使用线程池不仅可以提高应用的响应时间，还可以避免&quot;java.lang.OutOfMemoryError: unable to create new native thread&quot;之类的错误。在 Java 1.5 时，开发者需要关心线程池的创建和管理，但在 Java 1.5 之后 Executor 框架提供了多种内置的线程池,例如：FixedThreadPool(包含固定数目的线程)，CachedThreadPool(可根据需要创建新的线程)等等。","text":"文章摘录自博客java.util.concurrent.Executor, java.util.concurrent.ExecutorService, java.util.concurrent.Executors这三者均是 Java Executor 框架的一部分，用来提供线程池的功能。因为创建和管理线程非常心累，并且操作系统通常对线程数有限制，所以建议使用线程池来并发执行任务，而不是每次请求进来时创建一个线程。使用线程池不仅可以提高应用的响应时间，还可以避免&quot;java.lang.OutOfMemoryError: unable to create new native thread&quot;之类的错误。在 Java 1.5 时，开发者需要关心线程池的创建和管理，但在 Java 1.5 之后 Executor 框架提供了多种内置的线程池,例如：FixedThreadPool(包含固定数目的线程)，CachedThreadPool(可根据需要创建新的线程)等等。 ExecutorExecutor，ExecutorService，和 Executors 最主要的区别是 Executor 是一个抽象层面的核心接口(大致代码如下)。123public interface Executor &#123; void execute(Runnable command);&#125;不同于java.lang.Thread类将任务和执行耦合在一起， Executor 将任务本身和执行任务分离，可以阅读 difference between Thread and Executor 来了解 Thread 和 Executor 间更多的不同。 ExecutorServiceExecutorService 接口 对 Executor 接口进行了扩展，提供了返回 Future 对象，终止，关闭线程池等方法。当调用shutDown方法时，线程池会停止接受新的任务，但会完成正在 pending 中的任务。Future 对象提供了异步执行，这意味着无需等待任务执行的完成，只要提交需要执行的任务，然后在需要时检查 Future 是否已经有了结果，如果任务已经执行完成，就可以通过 Future.get( ) 方法获得执行结果。需要注意的是，Future.get( ) 方法是一个阻塞式的方法，如果调用时任务还没有完成，会等待直到任务执行结束。通过 ExecutorService.submit( ) 方法返回的 Future 对象，还可以取消任务的执行。Future 提供了 cancel()方法用来取消执行 pending 中的任务。ExecutorService 部分代码如下：123456public interface ExecutorService extends Executor &#123; void shutdown(); &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;&#125; ExecutorsExecutors 是一个工具类，类似于 Collections。提供工厂方法来创建不同类型的线程池，比如 FixedThreadPool 或 CachedThreadPool。Executors 部分代码：123456789public class Executors &#123; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125;&#125; Executor vs ExecutorService vs Executors正如上面所说，这三者均是 Executor 框架中的一部分。Java 开发者很有必要学习和理解他们，以便更高效的使用 Java 提供的不同类型的线程池。总结一下这三者间的区别，以便大家更好的理解：Executor 和 ExecutorService 这两个接口主要的区别是：ExecutorService 接口继承了 Executor 接口，是 Executor 的子接口Executor 和 ExecutorService 第二个区别是：Executor 接口定义了 execute()方法用来接收一个Runnable接口的对象，而 ExecutorService 接口中的 submit()方法可以接受Runnable和Callable接口的对象。Executor 和 ExecutorService 接口第三个区别是 Executor 中的 execute()方法不返回任何结果，而 ExecutorService 中的 submit()方法可以通过一个 Future 对象返回运算结果。Executor 和 ExecutorService 接口第四个区别是除了允许客户端提交一个任务，ExecutorService 还提供用来控制线程池的方法。比如：调用 shutDown()方法终止线程池。可以通过 《Java Concurrency in Practice》 一书了解更多关于关闭线程池和如何处理 pending 的任务的知识。Executors 类提供工厂方法用来创建不同类型的线程池。比如: newSingleThreadExecutor()创建一个只有一个线程的线程池，newFixedThreadPool(int numOfThreads)来创建固定线程数的线程池，newCachedThreadPool()可以根据需要创建新的线程，但如果已有线程是空闲的会重用已有线程。 总结下表列出了 Executor 和 ExecutorService 的区别：ExecutorExecutorServiceExecutor 是 Java 线程池的核心接口，用来并发执行提交的任务ExecutorService 是 Executor 接口的扩展，提供了异步执行和关闭线程池的方法提供execute()方法用来提交任务提供submit()方法用来提交任务execute()方法无返回值submit()方法返回Future对象，可用来获取任务执行结果不能取消任务可以通过Future.cancel()取消pending中的任务没有提供和关闭线程池有关的方法提供了关闭线程池的方法 译者注个人觉得，利用 Executors 类提供的工厂方法来创建一个线程池是很方便，但对于需要根据实际情况自定义线程池某些参数的场景，就不太适用了。举个例子：当线程池中的线程均处于工作状态，并且线程数已达线程池允许的最大线程数时，就会采取指定的饱和策略来处理新提交的任务。总共有四种策略：AbortPolicy: 直接抛异常CallerRunsPolicy: 用调用者的线程来运行任务DiscardOldestPolicy: 丢弃线程队列里最近的一个任务，执行新提交的任务DiscardPolicy 直接将新任务丢弃如果使用 Executors 的工厂方法创建的线程池，那么饱和策略都是采用默认的 AbortPolicy，所以如果我们想当线程池已满的情况，使用调用者的线程来运行任务，就要自己创建线程池，指定想要的饱和策略，而不是使用 Executors 了。所以我们可以根据需要创建 ThreadPoolExecutor(ExecutorService接口的实现类) 对象，自定义一些参数，而不是调用 Executors 的工厂方法创建。当然，在使用 Spring 框架的项目中，也可以使用 Spring 提供的 ThreadPoolTaskExecutor 类来创建线程池。ThreadPoolTaskExecutor 与 ThreadPoolExecutor 类似，也提供了许多参数用来自定义线程池，比如：核心线程池大小，线程池最大数量，饱和策略，线程活动保持时间等等。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"}]},{"title":"equals()和hashCode()","slug":"java/equals()和hashCode()","date":"2018-01-31T16:00:00.000Z","updated":"2018-12-06T06:26:12.847Z","comments":true,"path":"java/554520e5/","link":"","permalink":"https://maoyunfei.github.io/java/554520e5/","excerpt":"原文链接默认情况下，Java超类java.lang.Object提供了两种比较对象的重要方法：equals()和hashCode()。在大型项目中实现多个类之间的交互时，这些方法变得非常有用。在本文中，我们将讨论这些方法之间的关系，它们的默认实现以及强制开发人员为每个方法提供自定义实现的情况。","text":"原文链接默认情况下，Java超类java.lang.Object提供了两种比较对象的重要方法：equals()和hashCode()。在大型项目中实现多个类之间的交互时，这些方法变得非常有用。在本文中，我们将讨论这些方法之间的关系，它们的默认实现以及强制开发人员为每个方法提供自定义实现的情况。 方法定义和默认实现123456789public class Object &#123; ... public boolean equals(Object obj) &#123; return (this == obj); &#125; ... public native int hashCode(); ...&#125;equal()方法：JDK提供的默认实现是基于内存位置的 - 当且仅当它们存储在同一个内存地址中时，两个对象是相等的。hashCode()方法：默认实现是个本地方法。需要满足三个约定：(1) 无论什么时间，在同一个应用内执行多次应该返回相同的值。(2) 如果两个对象的equals()方法返回true，那么它们的hashCode()必须相同。(3) 如果两个对象的equals()方法返回false，那么它们的hashCode()可以相同，也可以不同。 重写equals()实例：12345678910111213141516171819202122package com.programmer.gate.beans;public class Student &#123; private int id; private String name; public Student(int id, String name) &#123; this.name = name; this.id = id; &#125; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125;123456789@Overridepublic boolean equals(Object obj) &#123; if (obj == null) return false; if (!(obj instanceof Student)) return false; if (obj == this) return true; return this.getId() == ((Student) obj).getId();&#125; equals() With ArrayList123456789public class HashcodeEquals &#123; public static void main(String[] args) &#123; Student alex = new Student(1, \"Alex\"); List &lt; Student &gt; studentsLst = new ArrayList &lt; Student &gt; (); studentsLst.add(alex); System.out.println(\"Arraylist size = \" + studentsLst.size()); System.out.println(\"Arraylist contains Alex = \" + studentsLst.contains(new Student(1, \"Alex\"))); &#125;&#125;以上代码输出为：12Arraylist size = 1Arraylist contains Alex = true原因是ArrayList的contains()方法内部是调用的对象的equals()方法。 重写hashCode()1234@Overridepublic int hashCode() &#123; return id;&#125; equals() With HashSet1234567891011public class HashcodeEquals &#123; public static void main(String[] args) &#123; Student alex1 = new Student(1, \"Alex\"); Student alex2 = new Student(1, \"Alex\"); HashSet &lt; Student &gt; students = new HashSet &lt; Student &gt; (); students.add(alex1); students.add(alex2); System.out.println(\"HashSet size = \" + students.size()); System.out.println(\"HashSet contains Alex = \" + students.contains(new Student(1, \"Alex\"))); &#125;&#125;以上代码输出为：12HashSet size = 1HashSet contains Alex = trueHashSet将其元素存储在内存桶中。每个桶都链接到一个特定的哈希码。当调用students.add(alex1)时，Java在存储桶中存储alex1并将其链接到alex1.hashCode()的值。现在任何时候，一个具有相同散列码的元素被插入到集合中，它将会替换掉alex1。但是，由于alex2具有不同的散列码，它将被存储在一个单独的存储桶中，并被视为完全不同的对象。现在，当HashSet在其中搜索一个元素时，它首先生成元素的哈希码并查找与这个哈希码对应的一个桶。这同样适用于HashMap，HashTable或任何使用散列机制来存储元素的数据结构。hashCode()用于散列到桶，equals()用于判断对象是否相同。","categories":[{"name":"Java","slug":"java","permalink":"https://maoyunfei.github.io/categories/java/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://maoyunfei.github.io/tags/Java基础/"}]},{"title":"Understanding Eureka Peer to Peer Communication","slug":"spring/spring cloud/Understanding Eureka Peer to Peer Communication","date":"2018-01-14T16:00:00.000Z","updated":"2018-12-06T06:31:38.023Z","comments":true,"path":"spring/7b50bf88/","link":"","permalink":"https://maoyunfei.github.io/spring/7b50bf88/","excerpt":"原文链接Eureka client尝试去和相同zone的Eureka Server通信。如果相同zone的server不存在或者通信有问题，client就会转到其他zone的server。一旦服务器开始接收流量，在服务器上执行的所有操作都将被复制到服务器所知道的所有对等节点。如果某个操作由于某种原因而失败，那么该信息将在服务器之间下一次心跳时核对后复制。当Eureka server恢复，它尝试从邻居节点获取所有实例的注册信息。如果从一个节点获取信息存在问题，在它放弃之前，它将尝试所有的对等节点。如果Eureka server能够成功获取所有实例信息，则会根据该信息设置应该接收的“续约”阈值。如果任何时候，“续约”低于设置的该阈值百分比(在15分钟内低于85%),Eureka server停止过期实例来保护当前实例的注册信息。在Neflix,上面的保护称为“自我保护”模式，主要用在一组client和Eureka server之间存在网络分区的情况下的保护。在这种场景下，Eureka server尝试去保护已经拥有的信息。如果发生大规模的故障，在这种情况下，可能会导致client获得已经不存在的实例。client必须确保它们对于返回不存在或不响应的实例的Eureka server具有弹性。在这些情况下，最好的保护是快速超时并尝试其他服务器。在这种情况下，如果Eureka server无法从邻居节点获取注册表信息，则会等待几分钟（5分钟），以便客户端可以注册其信息。server尽量不提供部分信息给client，而是通过将流量倾斜到仅一组实例并会导致容量问题。如此处所述，Eureka server使用在Eureka client和server之间使用的相同机制相互通信。","text":"原文链接Eureka client尝试去和相同zone的Eureka Server通信。如果相同zone的server不存在或者通信有问题，client就会转到其他zone的server。一旦服务器开始接收流量，在服务器上执行的所有操作都将被复制到服务器所知道的所有对等节点。如果某个操作由于某种原因而失败，那么该信息将在服务器之间下一次心跳时核对后复制。当Eureka server恢复，它尝试从邻居节点获取所有实例的注册信息。如果从一个节点获取信息存在问题，在它放弃之前，它将尝试所有的对等节点。如果Eureka server能够成功获取所有实例信息，则会根据该信息设置应该接收的“续约”阈值。如果任何时候，“续约”低于设置的该阈值百分比(在15分钟内低于85%),Eureka server停止过期实例来保护当前实例的注册信息。在Neflix,上面的保护称为“自我保护”模式，主要用在一组client和Eureka server之间存在网络分区的情况下的保护。在这种场景下，Eureka server尝试去保护已经拥有的信息。如果发生大规模的故障，在这种情况下，可能会导致client获得已经不存在的实例。client必须确保它们对于返回不存在或不响应的实例的Eureka server具有弹性。在这些情况下，最好的保护是快速超时并尝试其他服务器。在这种情况下，如果Eureka server无法从邻居节点获取注册表信息，则会等待几分钟（5分钟），以便客户端可以注册其信息。server尽量不提供部分信息给client，而是通过将流量倾斜到仅一组实例并会导致容量问题。如此处所述，Eureka server使用在Eureka client和server之间使用的相同机制相互通信。 What happens during network outages between Peers? 在peers之间失去网络通信的情况下，下列事情将发生peers之间的心跳复制可能会失败，并且Eureka server检测到这种情况然后进入自我保护模式来保护当前状态。注册可能发生在孤立的Eureka server上，有些client可能会反映新的注册信息，而其他client可能不会。(备注：由于孤立的Eureka server无法与其他server共享注册信息)在网络连接恢复到稳定状态后，情况会自动更正。当peers能够正常通信时，注册信息会自动被传输到没有这些信息的Eureka server上。(备注：即网络恢复后，Eureka server之间会自动同步共享注册信息)最重要的是，在网络中断期间，Eureka server尝试尽可能地具有弹性，但在此期间，client可能会有不同的server视图。(备注：Eureka server存在网络分区时，多个server之间无法同步注册信息，导致每个server上的信息可能不同，所以client可能会看到不同的server视图)","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"Understanding eureka client server communication","slug":"spring/spring cloud/Understanding eureka client server communication","date":"2018-01-13T16:00:00.000Z","updated":"2018-12-06T06:31:37.929Z","comments":true,"path":"spring/55dcd732/","link":"","permalink":"https://maoyunfei.github.io/spring/55dcd732/","excerpt":"原文链接 About Instance Statuses默认的，Eureka client开始状态是 STARTING，这为了在实例能够提供服务之前，给它做应用初始化的时间。之后应用可以加入到可提供服务中通过将状态变更为 UP。ApplicationInfoManager.getInstance().setInstanceStatus(InstanceStatus.UP)应用也可以注册健康检查的callback，这可以选择性地将实例状态变为 DOWN。在Neflix中，还有一个 OUT_ OF_ SERVICE 状态,表明该实例不可提供服务中。","text":"原文链接 About Instance Statuses默认的，Eureka client开始状态是 STARTING，这为了在实例能够提供服务之前，给它做应用初始化的时间。之后应用可以加入到可提供服务中通过将状态变更为 UP。ApplicationInfoManager.getInstance().setInstanceStatus(InstanceStatus.UP)应用也可以注册健康检查的callback，这可以选择性地将实例状态变为 DOWN。在Neflix中，还有一个 OUT_ OF_ SERVICE 状态,表明该实例不可提供服务中。 Eureka Client OperationsEureka client首先尝试去和相同zone的Eureka Server连接，如果它不能发现服务端，它将转向其他zone。 Eureka client通过以下方式和服务端交互RegisterEurek Client向Eureka server注册运行实例的信息。注册发生在第一次心跳(在30秒之后)。RenewEureka client需要通过每30秒发送心跳来“续约”。“续约”信号告诉Eureka server该实例仍然是可用的。如果server在90秒没有收到“续约”，他将从注册列表移除该实例。不去改变“续约”周期是明智的，因为server使用这个信息去判断在client和server之间的通信是否有普遍的问题。(备注：例如网络分区问题)Fetch RegistryEureka client从server获取注册信息并缓存在本地。之后，client使用这个信息去发现其他的服务。注册信息被周期性的更新(每30秒)，通过获取上一个读取周期和当前读取周期之间的增量更新。增量信息在server中保持较长时间（约3分钟），因此增量提取可能会再次返回相同的实例。Eureka client会自动处理重复的信息。获取增量之后，Eureka client和server通过比较server返回的实例数量来比对信息，如果由于某些原因信息不匹配，整个注册信息将重新提取。Eureka server缓存压缩的增量payload、整个注册表，以及每个应用程序相同的未压缩信息。payload支持JSON和XML格式。Eureka client通过jersey apache client获取压缩的JSON格式的信息。CancelEureka client在shutdown时给Eureka server发送一个cancel请求。Eureka server将从服务的实例注册信息中移除该实例，这有效得将实例从负载中移除。(备注：通过linux命令 kill -15应用程序将收到shutdown通知，kill -9则收不到通知)当Eureka client shutdown时，应用应该保证去调用以下方法。1DiscoveryManager.getInstance().shutdownComponent()Time LagEureka client的所有操作会花费一定时间反映到Eureka server和其他的clients。这是因为Eureka server上有payload的缓存，它定期刷新以获取新的信息。Eureka client也会定期刷新增量信息。因此，这可能花费长达2分钟的时间去把变更传播到所有的Eureka client。Communication mechanism默认的，Eureka client使用Jersey,XStream技术和JSON 格式的payload去和Eureka Server交流。你也可以使用你选择的机制来覆盖默认的。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"Circuit Breaker--Hystrix","slug":"spring/spring cloud/Circuit Breaker--Hystrix","date":"2018-01-13T16:00:00.000Z","updated":"2018-12-06T06:31:38.048Z","comments":true,"path":"spring/da1cb016/","link":"","permalink":"https://maoyunfei.github.io/spring/da1cb016/","excerpt":"1. Hystrix Clients原文链接Netflix创建了一个实现了circuit breaker模式的叫做Hystrix的库。在一个微服务架构中通常有多层的服务调用，如下图。","text":"1. Hystrix Clients原文链接Netflix创建了一个实现了circuit breaker模式的叫做Hystrix的库。在一个微服务架构中通常有多层的服务调用，如下图。Microservice Graph一个底层的服务失败可以导致级联的直到用户的失败。在一个由 metrics.rollingStats.timeInMilliseconds(默认10秒)定义的默认窗口内，当请求一个指定的服务次数大于circuitBreaker.requestVolumeThreshold(默认20)并且失败率大于circuitBreaker.errorThresholdPercentage(默认50%)时，断路打开，请求不会发出。在发生错误或者短路时，开发者可以提供fallback。Hystrix fallback prevents cascading failures断路阻止了级联失败，并且允许高负载或者失败的服务有时间去恢复。fallback可以是另一个Hystrix保护的调用，静态数据或者空值。fallback可能是链式的，导致第一个fallback做的一些业务调用又回退到静态数据。 1.1 如何引入Hystrix1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;12345678910111213141516171819202122@SpringBootApplication@EnableCircuitBreakerpublic class Application &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125;@Componentpublic class StoreIntegration &#123; @HystrixCommand(fallbackMethod = &quot;defaultStores&quot;) public Object getStores(Map&lt;String, Object&gt; parameters) &#123; //do stuff that might fail &#125; public Object defaultStores(Map&lt;String, Object&gt; parameters) &#123; return /* something useful */; &#125;&#125;@HystrixCommand由一个名为“javanica”的Netflix contrib库提供。Spring Cloud自动将包含该注释的Spring bean包装在连接到Hystrix断路器的代理中。断路器计算何时打开和关闭电路，以及在发生故障时该怎么办。要配置@HystrixCommand，您可以使用带有@HystrixProperty注释列表的commandProperties属性。这里查看细节。Hystrix properties。 1.2 传播安全上下文或者使用Spring Scopes如果你想传播一些线程本地上下文到@HystrixCommand中，用默认声明是不起作用的，因为它在一个线程池中执行命令。当调用者使用一些配置或者直接在注解中让它去使用一个不同的隔离策略，你可以切换Hystrix去使用同一个线程。例如：123456@HystrixCommand(fallbackMethod = &quot;stubMyService&quot;, commandProperties = &#123; @HystrixProperty(name=&quot;execution.isolation.strategy&quot;, value=&quot;SEMAPHORE&quot;) &#125;)...如果使用@SessionScope或@RequestScope，则同样适用。你将知道何时需要执行此操作，因为一个运行时异常表示无法找到该scope内的上下文。你也可以设置hystrix.shareSecurityContext属性为true。这样会自动配置一个Hystrix并发策略插件，它将会把SecurityContext从你的主线程传递到Hystrix命令使用的线程。Hystrix不支持注册多个hystrix并发策略，所以可以通过声明你自己的HystrixConcurrencyStrategy bean来扩展。Spring cloud将在你的spring上下文中查找并把它封装进它自己的插件。 1.3 健康指标连接断路器的状态也暴露在应用程序的/health端点中。123456789&#123; &quot;hystrix&quot;: &#123; &quot;openCircuitBreakers&quot;: [ &quot;StoreIntegration::getStoresByLocationLink&quot; ], &quot;status&quot;: &quot;CIRCUIT_OPEN&quot; &#125;, &quot;status&quot;: &quot;UP&quot;&#125; 1.4 Hystrix指标流添加spring-boot-starter-actuator依赖来启用Hystrix指标流。这将暴露管理端点/hystrix.stream。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 2. Hystrix Dashboard原文链接Hystrix的主要优点之一就是它收集的关于每个HystrixCommand的指标集合。Hystrix仪表板以高效的方式显示每个断路器的运行状况。Hystrix Dashboard 3. Hystrix超时和Ribbon Client原文链接当使用Hystrix命令包装Ribbon client，你需要确保配置的Hystrix超时时间大于配置的Ribbon超时时间，包括任何潜在的重试。例如，如果你的ribbon连接超时是1秒，ribbon client可能重试3次，然后Hystrix超时应该略大于3秒。 3.1 如何引入Hystrix Dashboard1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-netflix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt;运行Hystrix Dashboard使用@EnableHystrixDashboard注释Spring Boot主类。然后访问/hystrix并将仪表板指向Hystrix客户端应用程序中的单个实例的/hystrix.stream端点。提示： 连接到使用HTTPS的/hystrix.stream端点时，服务器使用的证书必须由JVM信任。如果证书不可信，你必须将证书导入到JVM中，以便Hystrix仪表板能成功连接到流终端。 3.2 Turbine从单个实例来看，Hystrix数据在整个系统的健康状况方面并不是很有用。Turbine是一个应用程序，它将所有相关的/hystrix.stream端点汇总到一个用于Hystrix仪表板的组合/turbine.stream中。单个实例通过Eureka找到。运行Turbine与使用@EnableTurbine注释注释主类一样简单(例如，在classpath引入spring-cloud-starter-netflix-turbine)。来自Turbine 1 wiki的文档配置属性都适用。唯一的区别是turbine.instanceUrlSuffix不需要预先添加端口，因为这是自动处理的，除非turbine.instanceInsertPort=false。提示： 默认情况下，Turbine在注册实例上查找/hystrix.stream端点是通过在Eureka中查找其homePageUrl条目，然后将/hystrix.stream附加到上面。这意味着如果spring-boot-actuator在自己的端口上运行（这是默认的），对/hystrix.stream的调用将失败。要使Turbine在正确的端口找到Hystrix流，你需要将management.port添加到实例的metadata：1234eureka: instance: metadata-map: management.port: $&#123;management.port:8081&#125;配置turbine.appConfig是Turbine用于查找实例的Eureka中注册的serviceId的列表。Turbine stream然后在Hystrix仪表板中使用一个类似如下的url：http://my.turbine.sever:8080/turbine.stream?cluster=&lt;CLUSTERNAME&gt;(cluster参数可以被省略，如果名称是“default”)。cluster参数必须与turbine.aggregator.clusterConfig中的条目匹配。从Eureka返回的值是大写，因此，如果有一个名为“customers”的应用程序在Eureka注册，我们预计这个例子将起作用：1234turbine: aggregator: clusterConfig: CUSTOMERS appConfig: customersclusterName可以通过turb.clusterNameExpression中的SPEL表达式来定制，指定InstanceInfo的一个实例。默认值是appName，这意味着Eureka serviceId最终作为集群key(即customers的InstanceInfo具有“CUSTOMERS”的appName)。另一个示例是turb.clusterNameExpression=aSGName，它将从AWS ASG名称获取集群名称。另一个例子：12345turbine: aggregator: clusterConfig: SYSTEM,USER appConfig: customers,stores,ui,admin clusterNameExpression: metadata[&apos;cluster&apos;]在这种情况下，来自4个服务的集群名称将从其metadata映射中提取出来，预期包含“SYSTEM”和“USER”的值。要为所有应用程序使用“default”集群，你需要一个字符串文字表达式(使用单引号，如果使用YAML，则使用双引号进行转义):123turbine: appConfig: customers,stores clusterNameExpression: &quot;&apos;default&apos;&quot;Spring Cloud提供了一个spring-cloud-starter-netflix-turbine，它拥有运行Turbine服务器所需的所有依赖。只需创建一个Spring Boot应用程序并使用@EnableTurbine对其进行注释。提示： 默认情况下，Spring Cloud允许Turbine使用主机和端口来允许每个主机，每个集群使用多个进程。如果你希望Turbine中内置的本机Netflix行为不允许每个主机，每个集群（实例id的key是主机名）都有多个进程，那么请设置属性turbine.combineHostPort=false。 3.3 Turbine Stream在某些环境下（例如在PaaS设置中），从所有分布式Hystrix命令中提取指标的传统Turbine模型不起作用。在这种情况下，你可能希望让你的Hystrix命令将度量标准推送到Turbine，Spring Cloud通过消息传递来实现。你需要在客户端上执行的操作是添加依赖关系到你选择的spring-cloud-netflix-hystrix-stream和spring-cloud-starter-stream-*(有关broker和如何配置客户端凭据的详细信息，请参阅Spring Cloud Stream文档，但它应该为本地broker开箱即用)。在server端只需创建一个Spring Boot应用程序并使用@EnableTurbineStream对其进行注释，默认情况下它将在8989端口(将Hystrix仪表板指向该端口，任何路径)运行。你可以使用server.port或turbine.stream.port来自定义端口。如果在classpath中也有spring-boot-starter-web和spring-boot-starter-actuator，那么你可以通过提供一个不同的management.port，在单独的端口(默认情况下使用Tomcat)打开Actuator端点。然后你可以将Hystrix仪表板指向Turbine Stream Server，而不是单独的Hystrix流。如果Turbine Stream在myhost上的8989端口上运行，则将http:// myhost:8989放在Hystrix仪表板的流输入字段中。电路将以它们各自的serviceId为前缀，接着是一个点，然后是电路名称。Spring Cloud提供了一个spring-cloud-starter-netflix-turbine-stream，它拥有运行Turbine Stream server所需的所有依赖关系，只需添加你选择的Stream绑定程序，例如：spring-cloud-starter-stream-rabbit。你需要Java 8来运行应用程序，因为它是基于Netty的。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"Declarative REST Client--Feign","slug":"spring/spring cloud/Declarative REST Client--Feign","date":"2018-01-12T16:00:00.000Z","updated":"2018-12-06T06:31:37.862Z","comments":true,"path":"spring/2db5c206/","link":"","permalink":"https://maoyunfei.github.io/spring/2db5c206/","excerpt":"原文链接Feign是一个声明式的web服务client。它让编写web服务客户端更简单。使用Feign需要创建一个接口并在上面加注解。它有可插拔的注解支持，包括Feign的注解和JAX-RS的注解。Feign也支持可插拔式的编码器(encoder)和解码器(decoder)。Spring Cloud增加了对Spring MVC注解的支持，并且使用了Spring Web中默认使用的HttpMessageConverters。Spring Cloud整合Ribbon和Eureka，在使用Feign时提供负载均衡的http client。","text":"原文链接Feign是一个声明式的web服务client。它让编写web服务客户端更简单。使用Feign需要创建一个接口并在上面加注解。它有可插拔的注解支持，包括Feign的注解和JAX-RS的注解。Feign也支持可插拔式的编码器(encoder)和解码器(decoder)。Spring Cloud增加了对Spring MVC注解的支持，并且使用了Spring Web中默认使用的HttpMessageConverters。Spring Cloud整合Ribbon和Eureka，在使用Feign时提供负载均衡的http client。 1.1 如何引入Feignpom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt;Application.java12345678910@SpringBootApplication@EnableEurekaClient@EnableFeignClientspublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125;StoreClient.java12345678@FeignClient(&quot;stores&quot;)public interface StoreClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/stores&quot;) List&lt;Store&gt; getStores(); @RequestMapping(method = RequestMethod.POST, value = &quot;/stores/&#123;storeId&#125;&quot;, consumes = &quot;application/json&quot;) Store update(@PathVariable(&quot;storeId&quot;) Long storeId, Store store);&#125;在@FeignClient注解中的值“stores”是一个任意client name,被用来创建一个Ribbon负载均衡器。你也可以使用url属性来指定一个URL。在application context中的bean名称是这个接口的全限定名。你可以使用@FeignClient注解的qualifier属性来指定你自己的别名。上面的Ribbon client会去获取“stores”服务的物理地址。如果你的应用是一个Eureka client，它将解析在Eureka server注册的服务。如果你不想使用Eureka, 你可以在你的配置文件中额外配置一个服务列表。 1.2 覆盖Feign默认配置Spring Cloud Feign支持的一个重要概念是named client。每个Feign client都是集合的一部分，它们一起工作来连接远程服务.作为应用开发者，你使用@FeignClient注解来给这个集合一个名字。Spring Cloud使用FeignClientsConfiguration创建一个新的集合，作为每个指定客户端的ApplicationContext。这包括feign.Decoder,feign.Encoder,feign.Contract等。通过使用@FeignClient声明额外的配置（在FeignClientsConfiguration之上），Spring Cloud可让你完全控制Ribbon client。例如：1234@FeignClient(name = &quot;stores&quot;, configuration = FooConfiguration.class)public interface StoreClient &#123; //..&#125;在这种情况下，ribbon client由已经在FeignClientsConfiguration中的组件和FooConfiguration中的任何组件（后者将覆盖前者）组成。提示： FooConfiguration不需要@Configuraion注解。(备注：这一点和ribbon client完全相反，@RibbonClient的configuration必须被@Configuration注解。)它不能在应用上下文被@ComponentScan扫描到，否则它将被所有@FeignClient所共享。(备注：在这个特性上，和RibbonClient一样)name和url属性支持占位符,例如：1234@FeignClient(name = &quot;$&#123;feign.name&#125;&quot;, url = &quot;$&#123;feign.url&#125;&quot;)public interface StoreClient &#123; //..&#125;Spring Cloud Netflix默认提供以下bean (BeanType beanName：ClassName):Decoder feignDecoder: ResponseEntityDecoder(封装的SpringDecoder)Encoder feignEncoder: SpringEncoderLogger feignLogger: Slf4jLoggerContract feignContract: SpringMvcContractFeign.Builder feignBuilder: HystrixFeign.BuilderClient feignClient: 如果ribbon开启是LoadBalancerFeignClient, 否则是默认的feign client。通过设置feign.okhttp.enabled或feign.httpclient.enabled为true，可以使用OkHttpClient和ApacheHttpClient的feign client，并将它们放到classpath。Spring Cloud Netflix默认情况下不提供以下bean，但仍从应用程序上下文中查找这些类型的bean以创建feign client：Logger.LevelRetryerErrorDecoderRequest.OptionsCollection&lt;RequestInterceptor&gt;SetterFactory创建这些类型的bean并将其放入@FeignClient配置（例如上面的FooConfiguration）就能够覆盖所描述的每个bean。例如：123456789101112@Configurationpublic class FooConfiguration &#123; @Bean public Contract feignContract() &#123; return new feign.Contract.Default(); &#125; @Bean public BasicAuthRequestInterceptor basicAuthRequestInterceptor() &#123; return new BasicAuthRequestInterceptor(&quot;user&quot;, &quot;password&quot;); &#125;&#125;这用feign.Contract.Default代替了SpringMvcContract，并且将一个RequestInterceptor添加到RequestInterceptor的集合中。@FeignClient也可以使用配置属性进行配置。application.yml12345678910111213feign: client: config: feignName: connectTimeout: 5000 readTimeout: 5000 loggerLevel: full errorDecoder: com.example.SimpleErrorDecoder retryer: com.example.SimpleRetryer requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false默认配置可以在@EnableFeignClients属性defaultConfiguration中以与上述类似的方式指定。不同的是，这个配置将适用于所有的feign client。如果你更喜欢使用配置属性来配置所有@FeignClient，则可以使用default这个feign名称来创建配置属性。application.yml1234567feign: client: config: default: connectTimeout: 5000 readTimeout: 5000 loggerLevel: basic如果我们同时创建@Configuration bean和配置属性，配置属性将会胜出。它将覆盖@Configuration的值。但是如果你想改变@Configuration的优先级，你可以把feign.client.default-to-properties设为false。提示： 如果你需要在你的RequestInterceptor中使用ThreadLocal域变量，你要么把Hystrix的thread isolation strategy设为SEMAPHORE，要么在Feign中禁用Hystrix。application.yml123456789101112# To disable Hystrix in Feignfeign: hystrix: enabled: false# To set thread isolation to SEMAPHOREhystrix: command: default: execution: isolation: strategy: SEMAPHORE 1.3 手动创建Feign Client在某些情况下，可能需要在不方便使用以上方法的时自定义你的Feign Client。在这种情况下，你可以使用Feign Builder API创建client。下面是一个例子，它创建两个具有相同接口的Feign client，但用每个客户端配置了一个单独的请求拦截器。12345678910111213141516171819202122@Import(FeignClientsConfiguration.class)class FooController &#123; private FooClient fooClient; private FooClient adminClient; @Autowired public FooController( Decoder decoder, Encoder encoder, Client client) &#123; this.fooClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .requestInterceptor(new BasicAuthRequestInterceptor(&quot;user&quot;, &quot;user&quot;)) .target(FooClient.class, &quot;http://PROD-SVC&quot;); this.adminClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .requestInterceptor(new BasicAuthRequestInterceptor(&quot;admin&quot;, &quot;admin&quot;)) .target(FooClient.class, &quot;http://PROD-SVC&quot;); &#125;&#125;提示： 在上面的例子中，FeignClientsConfiguration.class是由Spring Cloud Netflix提供的默认配置。PROD-SVC是client要请求的服务的名称。 1.4 Feign的Hystrix支持如果Hystrix在classpath上并且feign.hystrix.enabled=true,那么Feign将用一个断路器来包装所有的方法。返回一个com.netflix.hystrix.HystrixCommand也是可以的。这将让你使用响应式模式(调用.toObservable()或.observe()或异步使用（调用.queue())要基于每个client禁用Hystrix支持，需要创建一个具有“prototype”范围的Feign.Builder，例如：12345678@Configurationpublic class FooConfiguration &#123; @Bean @Scope(&quot;prototype&quot;) public Feign.Builder feignBuilder() &#123; return Feign.builder(); &#125;&#125;警告： 在Spring Cloud Dalston发布之前，如果Hystrix在classpath上(备注：pom.xml中有spring-cloud-starter-hystrix依赖)，Feign默认情况下会将所有方法封装在断路器中。 Spring Cloud Dalston改变了这种默认行为，赞成采用选择加入的方式。(备注：Dalston前的版本中 feign.hystrix.enabled 默认值为true，Dalston及其之后的版本中 feign.hystrix.enabled 默认值为false) 1.5 Feign Hystrix FallbacksHystrix支持fallback的概念：一个默认的代码路径，在断路或出现错误时执行。为给定的@FeignClient启用fallback功能，将fallback属性设置为实现fallback的类名称。你还需要将你的实现声明为Spring bean。123456789101112@FeignClient(name = &quot;hello&quot;, fallback = HystrixClientFallback.class)protected interface HystrixClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/hello&quot;) Hello iFailSometimes();&#125;static class HystrixClientFallback implements HystrixClient &#123; @Override public Hello iFailSometimes() &#123; return new Hello(&quot;fallback&quot;); &#125;&#125;如果需要访问fallback触发的原因，则可以使用@FeignClient中的fallbackFactory属性。123456789101112131415161718@FeignClient(name = &quot;hello&quot;, fallbackFactory = HystrixClientFallbackFactory.class)protected interface HystrixClient &#123; @RequestMapping(method = RequestMethod.GET, value = &quot;/hello&quot;) Hello iFailSometimes();&#125;@Componentstatic class HystrixClientFallbackFactory implements FallbackFactory&lt;HystrixClient&gt; &#123; @Override public HystrixClient create(Throwable cause) &#123; return new HystrixClientWithFallBackFactory() &#123; @Override public Hello iFailSometimes() &#123; return new Hello(&quot;fallback; reason was: &quot; + cause.getMessage()); &#125; &#125;; &#125;&#125;警告： Feign的fallback和Hystrix的fallback工作有一个限制。fallback当前不支持返回类型为com.netflix.hystrix.HystrixCommand和rx.Observable的方法。 1.6 Feign和@Primary当使用Feign的Hystrix fallback时，ApplicationContext中有多个同一类型的Bean。这将会导致@Autowired不工作，因为没有一个确切的bean或者一个标记为primary的。要解决这个问题，Spring Cloud Netflix让所有的Feign实例为@Primary，所以Spring Framework将知道注入哪个bean。在一些情况下，这可能是不可取的。要关闭这个特性，设置@FeignClient的primary属性为false。1234@FeignClient(name = &quot;hello&quot;, primary = false)public interface HelloClient &#123; // methods here&#125; 1.7 Feign的继承支持Feign通过单继承接口支持样板apis。这允许将通用操作分组为方便的基础接口。UserService.java12345public interface UserService &#123; @RequestMapping(method = RequestMethod.GET, value =&quot;/users/&#123;id&#125;&quot;) User getUser(@PathVariable(&quot;id&quot;) long id);&#125;UserResource.java1234@RestControllerpublic class UserResource implements UserService &#123;&#125;UserClient.java123456package project.user;@FeignClient(&quot;users&quot;)public interface UserClient extends UserService &#123;&#125;提示： 一般不建议在server和client之间共享一个接口。它引入了紧密的耦合，而且实际上以当前的形式用于Spring MVC并不起作用（方法参数映射不被继承）。 1.8 Feign请求响应的压缩你可以考虑为你的Feign请求开启请求或响应的GZIP压缩。你可以通过开启以下属性来完成此操作：12eign.compression.request.enabled=truefeign.compression.response.enabled=trueFeign请求压缩为你提供了类似于设置Web服务器的设置：123feign.compression.request.enabled=truefeign.compression.request.mime-types=text/xml,application/xml,application/jsonfeign.compression.request.min-request-size=2048这些属性允许你选择压缩的media type和最小请求阈值长度。 1.9 Feign日志为每一个Feign client创建一个logger，logger默认的名字是用来创建Feign client的接口的全限定类名。Feign的日志只响应DEBUG级别。application.ymllogging.level.project.user.UserClient: DEBUG你可以为每一个client配置一个Logger.Level对象，告诉Feign去记录什么。有以下选择：NONE, 不记录 (默认).BASIC, 只记录请求方法、URL、响应状态码和执行时间。HEADERS, 记录请求头和响应头的基本信息。FULL, 记录请求和响应的headers、body和metadata。例如：以下将设置Logger.Level设为FULL:1234567@Configurationpublic class FooConfiguration &#123; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125;","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"客户端侧的负载均衡--Ribbon","slug":"spring/spring cloud/客户端侧的负载均衡--Ribbon","date":"2018-01-12T16:00:00.000Z","updated":"2018-12-06T06:31:38.005Z","comments":true,"path":"spring/d662598d/","link":"","permalink":"https://maoyunfei.github.io/spring/d662598d/","excerpt":"原文链接Ribbon是一个客户端负载均衡器，它可以让您对HTTP和TCP客户端的行为有很大的控制权。 Feign已经使用Ribbon，所以如果您使用的是@FeignClient，那么这个部分也适用。Ribbon中一个重要的概念是named client。Spring Cloud使用RibbonClientConfiguration根据需要为每个named client创建一个新的集合作为ApplicationContext，这包含（除其他外）ILoadBalancer，RestClient和ServerListFilter。","text":"原文链接Ribbon是一个客户端负载均衡器，它可以让您对HTTP和TCP客户端的行为有很大的控制权。 Feign已经使用Ribbon，所以如果您使用的是@FeignClient，那么这个部分也适用。Ribbon中一个重要的概念是named client。Spring Cloud使用RibbonClientConfiguration根据需要为每个named client创建一个新的集合作为ApplicationContext，这包含（除其他外）ILoadBalancer，RestClient和ServerListFilter。 1. 如何引入Ribbon1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 2. 自定义Ribbon Client你可以使用&lt;client&gt;.ribbon.*属性来配置ribbon client。Spring Cloud还允许你通过使用@RibbonClient声明其他配置（在RibbonClientConfiguration上）来完全控制客户端。例：1234@Configuration@RibbonClient(name = &quot;foo&quot;, configuration = FooConfiguration.class)public class TestConfiguration &#123;&#125;在这种情况下，ribbon client由已经在RibbonClientConfiguration中的组件和FooConfiguration中的任何组件（后者通常会覆盖前者）组成。(备注：使用RibbonClientConfiguration中的Bean和自定义的FooConfiguration中的Bean来配置ribbon client, FooConfiguration中的Bean会覆盖RibbonClientConfiguration中的Bean)注意： 上面的FooConfiguration必须用@Configuration，但是注意它不能在应用上下文被@ComponentScan扫描到，否则它将被所有@RibbonClient所共享。如果你使用@ComponentScan或者@SpringBootApplication,你需要避免它被包括在内(例如：把它放在一个单独的，不重叠的包或者在@ComponentScan中明确指定要扫描的包)。(备注：我是在src/main/java下新建一个package,将自定义的RibbonConfiguration配置Bean放在这个包下) Spring Cloud Netflix默认给ribbon提供以下的bean(BeanType beanName: ClassName):IClientConfig ribbonClientConfig: DefaultClientConfigImplIRule ribbonRule: ZoneAvoidanceRuleIPing ribbonPing: NoOpPingServerList&lt;Server&gt; ribbonServerList: ConfigurationBasedServerListServerListFilter&lt;Server&gt; ribbonServerListFilter: ZonePreferenceServerListFilterILoadBalancer ribbonLoadBalancer: ZoneAwareLoadBalancerServerListUpdater ribbonServerListUpdater: PollingServerListUpdater创建这些类型的bean并将其放置在@RibbonClient配置Bean（例如上面的FooConfiguration）中，可以覆盖所描述的每个bean。例：1234567@Configurationpublic class FooConfiguration &#123; @Bean public IPing ribbonPing(IClientConfig config) &#123; return new PingUrl(); &#125;&#125;这将用PingUrl代替NoOpPing。 3. 使用properties来自定义Ribbon ClientSpring Cloud Netflix现在支持使用properties来定制Ribbon client，以便与Ribbon文档兼容。这使你可以在不同的环境启动时更改行为。支持的属性如下所列，并应以&lt;clientName&gt;.ribbon为前缀：NFLoadBalancerClassName: should implement ILoadBalancerNFLoadBalancerRuleClassName: should implement IRuleNFLoadBalancerPingClassName: should implement IPingNIWSServerListClassName: should implement ServerListNIWSServerListFilterClassName: should implement ServerListFilter提示： 在这些属性中定义的类优先于使用@RibbonClient(configuration=MyRibbonConfig.class)定义的bean和Spring Cloud Netflix提供的默认类。要为一个名为users的服务设置IRule，可以如下设置：123users: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.WeightedResponseTimeRule 4. Ribbon和Eureka一起使用当Eureka和Ribbon一起使用(例如，二者都在classpath), ribbonServerList被DiscoveryEnabledNIWSServerList的一个扩展覆盖了，该扩展的server list来自于Eureka。同时用NIWSDiscoveryPing替代IPing,通过Eureka来判断服务状态是否为UP。默认安装的ServerList是一个DomainExtractingServerList，这样做的目的是在不使用AWS AMI metadata(这是Netflix所依赖的)的情况下为负载均衡器提供物理metadata。默认情况下，server list将使用实例metadata中提供的“zone”信息构建（所以在远程客户端上设置eureka.instance.metadataMap.zone）,如果没有设置zone，可以使用服务器hostname的域名作为zone的代理（如果设置了标志approximateZoneFromHostname）。一旦zone信息可用，就可以在ServerListFilter中使用。默认情况下，它将用于定位与client位于同一个zone的server，因为默认值是ZonePreferenceServerListFilter。默认地client的zone的确定方式与远程实例相同，即通过eureka.instance.metadataMap.zone。提示： 如果没有设置zone数据，则根据client配置（而不是实例配置）进行猜测。我们把eureka.client.availabilityZones(这是一个从region名称到zone列表的map)，并取出实例所在region的第一个zone（即eureka.client.region，默认为“us-east-1“，为了与本地Netflix的兼容性）。 5. Ribbon不和Eureka一起使用Eureka是一个远程服务发现的一个简便实现，所以你不需要在client端硬编码url，但是如果你不喜欢使用eureka，Ribbon和Feign仍然很合适。假设你已经为“stores”声明了@RibbonClient, 并且没有使用eureka。Ribbon client默认使用一个配置的server list,你可以像这样提供配置：application.yml123stores: ribbon: listOfServers: example.com,google.com 6. 在Ribbon中禁用Eureka设置属性ribbon.eureka.enabled = false将明确禁止在Ribbon中使用Eureka。application.yml123ribbon: eureka: enabled: false 7. 直接使用Ribbon API你可以直接使用LoadBalancerClient，例如：12345678910public class MyClass &#123; @Autowired private LoadBalancerClient loadBalancer; public void doStuff() &#123; ServiceInstance instance = loadBalancer.choose(&quot;stores&quot;); URI storesUri = URI.create(String.format(&quot;http://%s:%s&quot;, instance.getHost(), instance.getPort())); // ... do something with the URI &#125;&#125; 8. Ribbon的缓存配置每个named client的Ribbon都有一个Spring Cloud维护的对应子应用程序上下文,这个应用程序的上下文是当对named client第一次请求时懒加载的。可以将此延迟加载行为更改为在启动时立即加载这些子应用程序上下文，通过指定Ribbon client的名称来配置。application.yml1234ribbon: eager-load: enabled: true clients: client1, client2, client3","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"具有负载均衡功能的RestTemplate","slug":"spring/spring cloud/具有负载均衡功能的RestTemplate","date":"2018-01-11T16:00:00.000Z","updated":"2018-12-06T06:31:38.101Z","comments":true,"path":"spring/96993ac3/","link":"","permalink":"https://maoyunfei.github.io/spring/96993ac3/","excerpt":"原文链接通过@LoadBalanced和@Bean修饰可以生成一个具有负载均衡功能的RestTemplate。12345678@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;","text":"原文链接通过@LoadBalanced和@Bean修饰可以生成一个具有负载均衡功能的RestTemplate。12345678@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;提示： 从Spring Boot 1.4开始不再提供自动配置的RestTemplate Bean,你必须自己创建。 Retrying Failed RequestsRestTemplatede的失败重试,默认是不可用的，如果需要开启，需要设置spring.cloud.loadbalancer.retry.enabled=true并且添加Spring Retry依赖。1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt; &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&lt;/dependency&gt;具有负载均衡功能的RestTemplate将遵循Ribbon关于重试的配置，如client.ribbon.MaxAutoRetries，client.ribbon.MaxAutoRetriesNextServer，client.ribbon.OkToRetryOnAllOperations。Ribbon具体的配置。 Multiple RestTemplate objects原文链接如果需要同时使用具有负载均衡功能和普通的RestTemplate，可以如下配置：1234567891011121314151617181920212223242526272829303132@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate loadBalanced() &#123; return new RestTemplate(); &#125; @Primary @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;public class MyClass &#123; @Autowired private RestTemplate restTemplate; @Autowired @LoadBalanced private RestTemplate loadBalanced; public String doOtherStuff() &#123; return loadBalanced.getForObject(&quot;http://stores/stores&quot;, String.class); &#125; public String doStuff() &#123; return restTemplate.getForObject(&quot;http://example.com&quot;, String.class); &#125;&#125;RestTemplate bean上的@Primary注解表明当@Autowired时没有特殊修饰符时使用该实例。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"服务发现--Netflix Eureka","slug":"spring/spring cloud/服务发现--Netflix Eureka","date":"2018-01-10T16:00:00.000Z","updated":"2018-12-06T06:31:38.082Z","comments":true,"path":"spring/6213b905/","link":"","permalink":"https://maoyunfei.github.io/spring/6213b905/","excerpt":"Eureka Clients原文链接 如何引入Eureka Client1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt;","text":"Eureka Clients原文链接 如何引入Eureka Client1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; 注册到Eurake当一个client注册到Eureka，它提供自己的meta-data，例如host,port,health indicator URL,home page等。Eureka接受心跳信息从属于一个服务的每个实例。如果心跳在一个配置的时间内失败，实例将从注册中心移除。12345678@EnableEurekaClient@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125;application.yml1234eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/Authenticating with the Eureka Server在URLs中加上认证信息，如```http://user:password@localhost:8761/eureka```。12345678* Why is it so Slow to Register a Service?一个实例涉及和注册中心的周期性的心跳，默认周期为30s。一个服务不被客户端发现直到实例，服务端和客户端都在它们本地缓存有了相同的metadata。你可以用```eureka.instance.leaseRenewalIntervalInSeconds```来改变周期，这会加速client和其他server的连接进程。在生产环境最好遵守默认配置，因为在server有一些关于续约周期的内部计算。## &lt;span id=&quot;1.2&quot;&gt;Eureka Server[原文链接](http://cloud.spring.io/spring-cloud-static/Dalston.SR4/single/spring-cloud.html#spring-cloud-eureka-server)### 如何引入Eureka Serverorg.springframework.cloudspring-cloud-starter-eureka-server1### 如何运行一个Eureka Server@SpringBootApplication@EnableEurekaServerpublic class Application {public static void main(String[] args) { new SpringApplicationBuilder(Application.class).web(true).run(args); } }123456Eureka Server有一个UI主页来查看注册的服务信息，```/eureka/```。### Standalone Mode在单机模式下，更喜欢关闭client端的行为，如`registerWithEureka`，`fetchRegistry`，所以它不会试图去到达它的peers。*application.yml (Standalone Eureka Server)*server:port: 8761eureka:instance:hostname: localhostclient:registerWithEureka: falsefetchRegistry: falseserviceUrl:defaultZone: http://eureka.instance.hostname:{eureka.instance.hostname}:eureka.instance.hostname:{server.port}/eureka/123456注意`serverUrl`指向本地实例的host。### Peer AwarenessEureka可以变得高可用通过运行多个实例并让它们相互注册。事实上，这是默认的行为，所以我们只需要给peer添加一个有效的`serviceUrl`。*application.yml (Two Peer Aware Eureka Servers)*spring:profiles: peer1eureka:instance:hostname: peer1client:serviceUrl:defaultZone: http://peer2/eureka/spring:profiles: peer2eureka:instance:hostname: peer2client:serviceUrl:defaultZone: http://peer1/eureka/你可以添加多个peers到一个系统，只要它们互相至少有一边连接，它们将互相同步注册信息。如果peers存在物理分区，该系统原则上可能存在裂脑问题。 ### Prefer IP Address 通常，Eureka更喜欢暴露它的IP地址而不是它的hostname，设置`eureka.instance.preferIpAddress`为`true`,当注册时，它将使用它的IP地址而不是hostname。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://maoyunfei.github.io/tags/Spring-Cloud/"}]},{"title":"spring boot读取配置文件顺序","slug":"spring/spring boot/spring boot读取配置文件顺序","date":"2018-01-09T16:00:00.000Z","updated":"2018-12-06T06:31:37.879Z","comments":true,"path":"spring/5886b3b2/","link":"","permalink":"https://maoyunfei.github.io/spring/5886b3b2/","excerpt":"","text":"","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://maoyunfei.github.io/tags/Spring-Boot/"}]},{"title":"spring boot内嵌tomcat访问日志常用配置","slug":"spring/spring boot/spring boot内嵌tomcat访问日志常用配置","date":"2018-01-08T16:00:00.000Z","updated":"2018-12-06T06:31:38.040Z","comments":true,"path":"spring/76c7f26f/","link":"","permalink":"https://maoyunfei.github.io/spring/76c7f26f/","excerpt":"tomcat access log 常用配置123456789# tomcat access log configserver: tomcat: accesslog: enabled: true #是否开启日志 directory: /tmp/accesslogs/mobile-site #日志存储目录 pattern: &apos;%t %a %A %m %U%q %s %D %I %B&apos; #日志格式 prefix: access #日志文件前缀 rename-on-rotate: true #是否启用日志轮转","text":"tomcat access log 常用配置123456789# tomcat access log configserver: tomcat: accesslog: enabled: true #是否开启日志 directory: /tmp/accesslogs/mobile-site #日志存储目录 pattern: &apos;%t %a %A %m %U%q %s %D %I %B&apos; #日志格式 prefix: access #日志文件前缀 rename-on-rotate: true #是否启用日志轮转 pattern的配置：%a - Remote IP address，远程ip地址，注意不一定是原始ip地址，中间可能经过nginx等的转发%A - Local IP address，本地ip%b - Bytes sent, excluding HTTP headers, or ‘-’ if no bytes were sent%B - Bytes sent, excluding HTTP headers%h - Remote host name (or IP address if enableLookups for the connector is false)，远程主机名称(如果resolveHosts为false则展示IP)%H - Request protocol，请求协议%l - Remote logical username from identd (always returns ‘-’)%m - Request method，请求方法（GET，POST）%p - Local port，接受请求的本地端口%q - Query string (prepended with a ‘?’ if it exists, otherwise an empty string%r - First line of the request，HTTP请求的第一行（包括请求方法，请求的URI）%s - HTTP status code of the response，HTTP的响应代码，如：200,404%S - User session ID%t - Date and time, in Common Log Format format，日期和时间，Common Log Format格式%u - Remote user that was authenticated%U - Requested URL path%v - Local server name%D - Time taken to process the request, in millis，处理请求的时间，单位毫秒%T - Time taken to process the request, in seconds，处理请求的时间，单位秒%I - current Request thread name (can compare later with stacktraces)，当前请求的线程名，可以和打印的log对比查找问题","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://maoyunfei.github.io/tags/Spring-Boot/"}]},{"title":"@ConfigurationProperties和@EnableConfigurationProperties","slug":"spring/spring boot/@ConfigurationProperties和@EnableConfigurationProperties","date":"2018-01-07T16:00:00.000Z","updated":"2018-12-12T09:04:14.498Z","comments":true,"path":"spring/4b6e90e4/","link":"","permalink":"https://maoyunfei.github.io/spring/4b6e90e4/","excerpt":"在Spring Boot中使用 @ConfigurationProperties 注解开始创建一个@ConfigurationProperties bean:1234567891011121314151617@ConfigurationProperties(locations = \"classpath:mail.properties\", ignoreUnknownFields = false, prefix = \"mail\")public class MailProperties &#123; public static class Smtp &#123; private boolean auth; private boolean starttlsEnable; // ... getters and setters &#125; @NotBlank private String host; private int port; private String from; private String username; private String password; @NotNull private Smtp smtp; // ... getters and setters&#125;","text":"在Spring Boot中使用 @ConfigurationProperties 注解开始创建一个@ConfigurationProperties bean:1234567891011121314151617@ConfigurationProperties(locations = \"classpath:mail.properties\", ignoreUnknownFields = false, prefix = \"mail\")public class MailProperties &#123; public static class Smtp &#123; private boolean auth; private boolean starttlsEnable; // ... getters and setters &#125; @NotBlank private String host; private int port; private String from; private String username; private String password; @NotNull private Smtp smtp; // ... getters and setters&#125;…从如下属性中创建(mail.properties):1234567mail.host=localhostmail.port=25mail.smtp.auth=falsemail.smtp.starttls-enable=falsemail.from=me@localhostmail.username=mail.password= 方案一1234567891011121314151617181920212223@Configuration@ConfigurationProperties(locations = \"classpath:mail.properties\", prefix = \"mail\")public class MailConfiguration &#123; public static class Smtp &#123; private boolean auth; private boolean starttlsEnable; // ... getters and setters &#125; @NotBlank private String host; private int port; private String from; private String username; private String password; @NotNull private Smtp smtp; // ... getters and setters @Bean public JavaMailSender javaMailSender() &#123; // omitted for readability &#125;&#125; 方案二123456789@Configuration@EnableConfigurationProperties(MailProperties.class) public class MailConfiguration &#123; @Autowired private MailProperties mailProperties; @Bean public JavaMailSender javaMailSender() &#123; // omitted for readability &#125; &#125;注意: @EnableConfigurationProperties这个注解告诉Spring Boot能支持指定特定类型的@ConfigurationProperties。如果不指定会看到如下异常:1org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [demo.mail.MailProperties] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: &#123;@org.springframework.beans.factory.annotation.Autowired(required=true)&#125;方案一不使用@EnableConfigurationProperties注解，使用@Configuration或者@Component注解使其被component scan发现。方案二使用@EnableConfigurationProperties注解，使其指定的配置类被EnableConfigurationPropertiesImportSelector注册到应用上下文。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://maoyunfei.github.io/tags/Spring-Boot/"}]},{"title":"@Async注解的自定义Executor","slug":"spring/spring boot/@Async注解的自定义Executor","date":"2018-01-06T16:00:00.000Z","updated":"2018-12-12T09:05:55.693Z","comments":true,"path":"spring/555f9026/","link":"","permalink":"https://maoyunfei.github.io/spring/555f9026/","excerpt":"How To Do @Async in Spring默认情况下，Spring使用SimpleAsyncTaskExecutor来异步运行这些方法。默认值可以在两个级别重写 - 在应用程序级别或单个方法级别。","text":"How To Do @Async in Spring默认情况下，Spring使用SimpleAsyncTaskExecutor来异步运行这些方法。默认值可以在两个级别重写 - 在应用程序级别或单个方法级别。","categories":[{"name":"Spring","slug":"spring","permalink":"https://maoyunfei.github.io/categories/spring/"}],"tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://maoyunfei.github.io/tags/Spring-Boot/"}]},{"title":"Linux wc命令","slug":"linux/linux command/wc","date":"2018-01-05T16:00:00.000Z","updated":"2018-12-06T06:31:38.066Z","comments":true,"path":"linux/3bb57d1c/","link":"","permalink":"https://maoyunfei.github.io/linux/3bb57d1c/","excerpt":"Linux wc命令用于计算字数。利用wc指令我们可以计算文件的Byte数、字数、或是行数，若不指定文件名称、或是所给予的文件名为“-”，则wc指令会从标准输入设备读取数据。","text":"Linux wc命令用于计算字数。利用wc指令我们可以计算文件的Byte数、字数、或是行数，若不指定文件名称、或是所给予的文件名为“-”，则wc指令会从标准输入设备读取数据。 语法wc [-clw][--help][--version][文件...]参数：-c或–bytes或–chars 只显示Bytes数。-l或–lines 只显示行数。-w或–words 只显示字数。–help 在线帮助。–version 显示版本信息。 实例 统计单个文件在默认的情况下，wc将计算指定文件的行数、字数，以及字节数。使用的命令为：wc testfile先查看testfile文件的内容，可以看到：123456789$ cat testfile Linux networks are becoming more and more common, but scurity is often an overlooked issue. Unfortunately, in today’s environment all networks are potential hacker targets, fro0m tp-secret military research networks to small home LANs. Linux Network Securty focuses on securing Linux in a networked environment, where the security of the entire network needs to be considered rather than just isolated machines. It uses a mix of theory and practicl techniques to teach administrators how to install and use security applications, as well as how the applcations work and why they are necesary.使用wc统计，结果如下：123$ wc testfile # testfile文件的统计信息3 92 598 testfile # testfile文件的行数为3、单词数92、字节数598其中，3 个数字分别表示testfile文件的行数、单词数，以及该文件的字节数。 统计多个文件如果想同时统计多个文件的信息，例如同时统计testfile、testfile_1、testfile_2，可使用如下命令：wc testfile testfile_1 testfile_2 #统计三个文件的信息输出结果如下：123456$ wc testfile testfile_1 testfile_2 #统计三个文件的信息 3 92 598 testfile #第一个文件行数为3、单词数92、字节数598 9 18 78 testfile_1 #第二个文件的行数为9、单词数18、字节数78 3 6 32 testfile_2 #第三个文件的行数为3、单词数6、字节数32 15 116 708 总用量 #三个文件总共的行数为15、单词数116、字节数708 统计管道输出12ls -l | wc -lps -ef | grep java | wc -l","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux top命令","slug":"linux/linux command/top","date":"2018-01-04T16:00:00.000Z","updated":"2018-12-06T06:31:37.850Z","comments":true,"path":"linux/4c6cbbb6/","link":"","permalink":"https://maoyunfei.github.io/linux/4c6cbbb6/","excerpt":"Linux top命令用于实时显示 process 的动态。使用权限：所有使用者。","text":"Linux top命令用于实时显示 process 的动态。使用权限：所有使用者。 语法top [-] [d delay] [q] [c] [S] [s] [i] [n] [b]参数说明：d : 改变显示的更新速度，或是在交谈式指令列( interactive command)按 sq : 没有任何延迟的显示速度，如果使用者是有 superuser 的权限，则 top 将会以最高的优先序执行c : 切换显示模式，共有两种模式，一是只显示执行档的名称，另一种是显示完整的路径与名称S : 累积模式，会将己完成或消失的子行程 ( dead child process ) 的 CPU time 累积起来s : 安全模式，将交谈式指令取消, 避免潜在的危机i : 不显示任何闲置 (idle) 或无用 (zombie) 的行程n : 更新的次数，完成后将会退出 topb : 批次档模式，搭配 “n” 参数一起使用，可以用来将 top 的结果输出到档案内 实例显示进程信息# top显示完整命令# top -c以批处理模式显示程序信息# top -b以累积模式显示程序信息# top -S设置信息更新次数123top -n 2//表示更新两次后终止更新显示设置信息更新时间123# top -d 3//表示更新周期为3秒显示指定的进程信息123# top -p 139//显示进程号为139的进程信息，CPU、内存占用率等显示更新十次后退出top -n 10使用者将不能利用交谈式指令来对行程下命令top -s将更新显示二次的结果输入到名称为 top.log 的档案里top -n 2 -b &lt; top.log提示: 根据top命令显示的内容可以进一步根据pid查看具体是哪个进程，使用命令ps aux | grep {pid}","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux ps命令","slug":"linux/linux command/ps","date":"2018-01-03T16:00:00.000Z","updated":"2018-12-06T06:31:38.053Z","comments":true,"path":"linux/56aee8cb/","link":"","permalink":"https://maoyunfei.github.io/linux/56aee8cb/","excerpt":"Linux ps命令用于显示当前进程(process)的状态","text":"Linux ps命令用于显示当前进程(process)的状态 语法ps [options] [--help]参数ps 的参数非常多, 在此仅列出几个常用的参数并大略介绍含义-A 列出所有的行程-u 显示指定用户的进程-e 等于“-A”-f 以格式化显示a 显示所有涉及终端的进程信息u 显示面向用户的输出x 显示没有终端的进程au(x) 输出格式 :USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND 实例显示进程信息1234567891011121314# ps -A 显示进程信息PID TTY TIME CMD 1 ? 00:00:02 init 2 ? 00:00:00 kthreadd 3 ? 00:00:00 migration/0 4 ? 00:00:00 ksoftirqd/0 5 ? 00:00:00 watchdog/0……省略部分结果31160 ? 00:00:00 dhclient31211 ? 00:00:00 aptd31302 ? 00:00:00 sshd31374 pts/2 00:00:00 bash31396 pts/2 00:00:00 ps显示指定用户信息1234567891011121314# ps -u root 显示root进程用户信息 PID TTY TIME CMD 1 ? 00:00:02 init 2 ? 00:00:00 kthreadd 3 ? 00:00:00 migration/0 4 ? 00:00:00 ksoftirqd/0 5 ? 00:00:00 watchdog/0……省略部分结果 31160 ? 00:00:00 dhclient31211 ? 00:00:00 aptd31302 ? 00:00:00 sshd31374 pts/2 00:00:00 bash31397 pts/2 00:00:00 ps显示所有进程信息，连同命令行12345678910111213# ps -ef 显示所有命令，连带命令行UID PID PPID C STIME TTY TIME CMDroot 1 0 0 10:22 ? 00:00:02 /sbin/initroot 2 0 0 10:22 ? 00:00:00 [kthreadd]root 3 2 0 10:22 ? 00:00:00 [migration/0]root 4 2 0 10:22 ? 00:00:00 [ksoftirqd/0]root 5 2 0 10:22 ? 00:00:00 [watchdog/0]……省略部分结果root 31302 2095 0 17:42 ? 00:00:00 sshd: root@pts/2 root 31374 31302 0 17:42 pts/2 00:00:00 -bashroot 31400 1 0 17:46 ? 00:00:00 /usr/bin/python /usr/sbin/aptdroot 31407 31374 0 17:48 pts/2 00:00:00 ps -efps与grep常用组合用法，查找特定进程123456# ps -ef | grep sshUID PID PPID C STIME TTY TIME CMDroot 2720 1 0 Nov02 ? 00:00:00 /usr/sbin/sshdroot 17394 2720 0 14:58 ? 00:00:00 sshd: root@pts/0 root 17465 17398 0 15:57 pts/0 00:00:00 grep ssh列出目前所有的正在内存当中的程序123456789101112# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 10368 676 ? Ss Nov02 0:00 init [3] root 2 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/0]root 3 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/0]root 4 0.0 0.0 0 0 ? S&lt; Nov02 0:01 [migration/1]root 5 0.0 0.0 0 0 ? SN Nov02 0:00 [ksoftirqd/1]root 6 0.0 0.0 0 0 ? S&lt; Nov02 29:57 [events/0]root 7 0.0 0.0 0 0 ? S&lt; Nov02 0:00 [events/1]root 8 0.0 0.0 0 0 ? S&lt; Nov02 0:00 ……省略部分结果ps aux可以显示进程占用CPU和内存情况。","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux grep命令","slug":"linux/linux command/grep","date":"2018-01-02T16:00:00.000Z","updated":"2018-12-06T06:31:37.868Z","comments":true,"path":"linux/b177a18e/","link":"","permalink":"https://maoyunfei.github.io/linux/b177a18e/","excerpt":"Linux grep命令用于查找文件里符合条件的字符串。若不指定任何文件名称，或是所给予的文件名为“-”，则grep指令会从标准输入设备读取数据。","text":"Linux grep命令用于查找文件里符合条件的字符串。若不指定任何文件名称，或是所给予的文件名为“-”，则grep指令会从标准输入设备读取数据。 语法grep [-abcEFGhHilLnqrsvVwxy][-A&lt;显示列数&gt;][-B&lt;显示列数&gt;][-C&lt;显示列数&gt;][-d&lt;进行动作&gt;][-e&lt;范本样式&gt;][-f&lt;范本文件&gt;][--help][范本样式][文件或目录...]参数-a或–text 不要忽略二进制的数据。-A&lt;显示列数&gt;或–after-context=&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之后的内容。-b或–byte-offset 在显示符合范本样式的那一列之前，标示出该列第一个字符的位编号。-B&lt;显示列数&gt;或–before-context=&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前的内容。-c或–count 计算符合范本样式的列数。-C&lt;显示列数&gt;或–context=&lt;显示列数&gt;或-&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。-d&lt;进行动作&gt;或–directories=&lt;进行动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。-e&lt;范本样式&gt;或–regexp=&lt;范本样式&gt; 指定字符串做为查找文件内容的范本样式。-E或–extended-regexp 将范本样式为延伸的普通表示法来使用。-f&lt;范本文件&gt;或–file=&lt;范本文件&gt; 指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。-F或–fixed-regexp 将范本样式视为固定字符串的列表。-G或–basic-regexp 将范本样式视为普通的表示法来使用。-h或–no-filename 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。-H或–with-filename 在显示符合范本样式的那一列之前，表示该列所属的文件名称。-i或–ignore-case 忽略字符大小写的差别。-l或–file-with-matches 列出文件内容符合指定的范本样式的文件名称。-L或–files-without-match 列出文件内容不符合指定的范本样式的文件名称。-n或–line-number 在显示符合范本样式的那一列之前，标示出该列的列数编号。-o 输出每一行中所有符合条件的内容-q或–quiet或–silent 不显示任何信息。-r或–recursive 此参数的效果和指定&quot;-d recurse&quot;参数相同。-s或–no-messages 不显示错误信息。-v或–revert-match 反转查找。-V或–version 显示版本信息。-w或–word-regexp 只显示全字符合的列。-x或–line-regexp 只显示全列符合的列。-y 此参数的效果和指定&quot;-i&quot;参数相同。–help 在线帮助。 实例12345$ grep test test* #查找后缀有“test”的文件包含“test”字符串的文件 testfile1:This a Linux testfile! #列出testfile1 文件中包含test字符的行 testfile_2:This is a linux testfile! #列出testfile_2 文件中包含test字符的行 testfile_2:Linux test #列出testfile_2 文件中包含test字符的行1234567$ grep -r update /etc/acpi #以递归的方式查找“etc/acpi”下包含“update”的文件 /etc/acpi/ac.d/85-anacron.sh:# (Things like the slocate updatedb cause a lot of IO.) Rather than /etc/acpi/resume.d/85-anacron.sh:# (Things like the slocate updatedb cause a lot of IO.) Rather than /etc/acpi/events/thinkpad-cmos:action=/usr/sbin/thinkpad-keys--update12345678910$ grep -v test *test* #查找文件名中包含test 的文件中不包含test的行testfile1:helLinux! testfile1:Linis a free Unix-type operating system. testfile1:Lin testfile_1:HELLO LINUX! testfile_1:LINUX IS A FREE UNIX-TYPE OPTERATING SYSTEM. testfile_1:THIS IS A LINUX TESTFILE! testfile_2:HELLO LINUX! testfile_2:Linux is a free unix-type opterating system.","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux dig 命令","slug":"linux/linux command/dig","date":"2018-01-01T16:00:00.000Z","updated":"2018-12-06T06:31:37.949Z","comments":true,"path":"linux/152528eb/","link":"","permalink":"https://maoyunfei.github.io/linux/152528eb/","excerpt":"dig是域信息检索器的简称(Domain Information Groper)，可以执行查询域名相关的任务。","text":"dig是域信息检索器的简称(Domain Information Groper)，可以执行查询域名相关的任务。 语法dig [选项参数] {domian}示例一：dig www.baidu.com示例二：+short 输出精简答复dig www.baidu.com +short示例三：+trace 追踪DNS解析过程dig www.baidu.com +trace","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]},{"title":"Linux awk 命令","slug":"linux/linux command/awk","date":"2017-12-31T16:00:00.000Z","updated":"2018-12-06T06:31:37.988Z","comments":true,"path":"linux/c0a16f03/","link":"","permalink":"https://maoyunfei.github.io/linux/c0a16f03/","excerpt":"原文链接AWK是一种处理文本文件的语言，是一个强大的文本分析工具。之所以叫AWK是因为其取了三位创始人Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。","text":"原文链接AWK是一种处理文本文件的语言，是一个强大的文本分析工具。之所以叫AWK是因为其取了三位创始人Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。 语法123awk [选项参数] &apos;script&apos; var=value file(s)或awk [选项参数] -f scriptfile var=value file(s) 常用选项参数说明-F fs指定输入文件的分隔符，fs是一个字符串或者是一个正则表达式，如-F:。-V var=value赋值一个用户定义变量-f scripfile从脚本文件中读取awk命令。 基本用法log.txt文本内容如下：12342 this is a test3 Are you like awkThis&apos;s a test10 There are orange,apple,mongo 用法一awk ‘{[pattern] action}’ {filenames} # 行匹配语句 awk ‘’ 只能用单引号实例：123456789101112131415# 每行按空格或TAB分割，输出文本中的1、4项 $ awk &apos;&#123;print $1,$4&#125;&apos; log.txt --------------------------------------------- 2 a 3 like This&apos;s 10 orange,apple,mongo # 格式化输出 $ awk &apos;&#123;printf &quot;%-8s %-10s\\n&quot;,$1,$4&#125;&apos; log.txt --------------------------------------------- 2 a 3 like This&apos;s 10 orange,apple,mongo 用法二awk -F #-F相当于内置变量FS, 指定分割字符实例：1234567891011121314151617181920212223# 使用&quot;,&quot;分割 $ awk -F, &apos;&#123;print $1,$2&#125;&apos; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&apos;s a test 10 There are orange apple # 或者使用内建变量 $ awk &apos;BEGIN&#123;FS=&quot;,&quot;&#125; &#123;print $1,$2&#125;&apos; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&apos;s a test 10 There are orange apple # 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割 $ awk -F &apos;[ ,]&apos; &apos;&#123;print $1,$2,$5&#125;&apos; log.txt --------------------------------------------- 2 this test 3 Are awk This&apos;s a 10 There apple 用法三awk -v # 设置变量实例：12345678910111213$ awk -va=1 &apos;&#123;print $1,$1+a&#125;&apos; log.txt --------------------------------------------- 2 3 3 4 This&apos;s 1 10 11 $ awk -va=1 -vb=s &apos;&#123;print $1,$1+a,$1b&#125;&apos; log.txt --------------------------------------------- 2 3 2s 3 4 3s This&apos;s 1 This&apos;ss 10 11 10s 用法四awk -f {awk脚本} {文件名}实例：$ awk -f cal.awk log.txt 运算符运算符描述= += -= *= /= %= ^= **=赋值?:C条件表达式||逻辑或&amp;&amp;逻辑与~ ~!匹配正则表达式和不匹配正则表达式&lt; &lt;= &gt; &gt;= != ==关系运算符空格连接+ -加，减* / %乘，除与求余+ - !一元加，减和逻辑非^ ***求幂++ --增加或减少，作为前缀或后缀$字段引用in数组成员* 过滤第一列大于2的行12345$ awk &apos;$1&gt;2&apos; log.txt #命令#输出3 Are you like awkThis&apos;s a test10 There are orange,apple,mongo过滤第一列等于2的行123$ awk &apos;$1==2 &#123;print $1,$3&#125;&apos; log.txt #命令#输出2 is过滤第一列大于2并且第二列等于’Are’的行123$ awk &apos;$1&gt;2 &amp;&amp; $2==&quot;Are&quot; &#123;print $1,$2,$3&#125;&apos; log.txt #命令#输出3 Are you 内置变量变量描述\\$n当前记录的第n个字段，字段间由FS分隔\\$0完整的输入记录ARGC命令行参数的数目ARGIND命令行中当前文件的位置(从0开始算)ARGV包含命令行参数的数组CONVFMT数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组ERRNO最后一个系统错误的描述FIELDWIDTHS字段宽度列表(用空格键分隔)FILENAME当前文件名FNR各文件分别计数的行号FS字段分隔符(默认是任何空格)IGNORECASE如果为真，则进行忽略大小写的匹配NF输入字段分割符NR已经读出的记录数，就是行号，从1开始OFMT数字的输出格式(默认值是%.6g)OFS输出记录分隔符（输出换行符），输出时用指定的符号代替换行符ORS输出记录分隔符(默认值是一个换行符)RLENGTH由match函数所匹配的字符串的长度RS记录分隔符(默认是一个换行符)RSTART由match函数所匹配的字符串的第一个位置SUBSEP数组下标分隔符(默认值是/034)### 使用正则，字符串匹配1234# 输出第二列包含 &quot;th&quot;，并打印第二列与第四列$ awk &apos;$2 ~ /th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------this a~ 表示模式开始。//中是模式12345# 输出包含&quot;re&quot; 的行$ awk &apos;/re/ &apos; log.txt---------------------------------------------3 Are you like awk10 There are orange,apple,mongo 忽略大小写1234$ awk &apos;BEGIN&#123;IGNORECASE=1&#125; /this/&apos; log.txt---------------------------------------------2 this is a testThis&apos;s a test 模式取反1234567891011$ awk &apos;$2 !~ /th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongo$ awk &apos;!/th/ &#123;print $2,$4&#125;&apos; log.txt---------------------------------------------Are likeaThere orange,apple,mongo awk脚本关于awk脚本，我们需要注意两个关键词BEGIN和END。BEGIN{ 这里面放的是执行前的语句 }END {这里面放的是处理完所有的行后要执行的语句 }{这里面放的是处理每一行时要执行的语句}假设有这么一个文件（学生成绩表）：123456$ cat score.txtMarry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62我们的awk脚本如下：123456789101112131415161718192021222324$ cat cal.awk#!/bin/awk -f#运行前BEGIN &#123; math = 0 english = 0 computer = 0 printf &quot;NAME NO. MATH ENGLISH COMPUTER TOTAL\\n&quot; printf &quot;---------------------------------------------\\n&quot;&#125;#运行中&#123; math+=$3 english+=$4 computer+=$5 printf &quot;%-6s %-6s %4d %8d %8d %8d\\n&quot;, $1, $2, $3,$4,$5, $3+$4+$5&#125;#运行后END &#123; printf &quot;---------------------------------------------\\n&quot; printf &quot; TOTAL:%10d %8d %8d \\n&quot;, math, english, computer printf &quot;AVERAGE:%10.2f %8.2f %8.2f\\n&quot;, math/NR, english/NR, computer/NR&#125;我们来看一下执行结果：1234567891011$ awk -f cal.awk score.txtNAME NO. MATH ENGLISH COMPUTER TOTAL---------------------------------------------Marry 2143 78 84 77 239Jack 2321 66 78 45 189Tom 2122 48 77 71 196Mike 2537 87 97 95 279Bob 2415 40 57 62 159--------------------------------------------- TOTAL: 319 393 350AVERAGE: 63.80 78.60 70.00","categories":[{"name":"Linux","slug":"linux","permalink":"https://maoyunfei.github.io/categories/linux/"}],"tags":[{"name":"Linux命令","slug":"Linux命令","permalink":"https://maoyunfei.github.io/tags/Linux命令/"}]}]}